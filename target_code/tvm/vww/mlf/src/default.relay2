#[version = "0.0.5"]
def @main(%input_1_int8: Tensor[(1, 96, 96, 3), int8] /* ty=Tensor[(1, 96, 96, 3), int8] span=input_1_int8:0:0 */, %v_param_1: Tensor[(3, 3, 3, 8), int8] /* ty=Tensor[(3, 3, 3, 8), int8] span=model/conv2d/Conv2D:0:0 */, %v_param_2: Tensor[(8), int32] /* ty=Tensor[(8), int32] span=model/activation/Relu;model/batch_normalization/FusedBatchNormV3;model/conv2d/BiasAdd/ReadVariableOp/resource;model/conv2d/BiasAdd;model/depthwise_conv2d/depthwise;model/conv2d/Conv2D:0:0 */, %v_param_3: Tensor[(3, 3, 8, 1), int8] /* ty=Tensor[(3, 3, 8, 1), int8] span=model/batch_normalization_1/FusedBatchNormV3;model/depthwise_conv2d/depthwise;model/depthwise_conv2d/BiasAdd;model/depthwise_conv2d/BiasAdd/ReadVariableOp/resource:0:0 */, %v_param_4: Tensor[(8), int32] /* ty=Tensor[(8), int32] span=model/activation_1/Relu;model/batch_normalization_1/FusedBatchNormV3;model/depthwise_conv2d/depthwise;model/depthwise_conv2d/BiasAdd;model/depthwise_conv2d/BiasAdd/ReadVariableOp/resource:0:0 */, %v_param_5: Tensor[(1, 1, 8, 16), int8] /* ty=Tensor[(1, 1, 8, 16), int8] span=model/conv2d_1/Conv2D:0:0 */, %v_param_6: Tensor[(16), int32] /* ty=Tensor[(16), int32] span=model/activation_2/Relu;model/batch_normalization_2/FusedBatchNormV3;model/conv2d_1/BiasAdd/ReadVariableOp/resource;model/conv2d_1/BiasAdd;model/depthwise_conv2d_1/depthwise;model/conv2d_1/Conv2D:0:0 */, %v_param_7: Tensor[(3, 3, 16, 1), int8] /* ty=Tensor[(3, 3, 16, 1), int8] span=model/batch_normalization_3/FusedBatchNormV3;model/depthwise_conv2d_1/depthwise;model/depthwise_conv2d_1/BiasAdd;model/depthwise_conv2d_1/BiasAdd/ReadVariableOp/resource:0:0 */, %v_param_8: Tensor[(16), int32] /* ty=Tensor[(16), int32] span=model/activation_3/Relu;model/batch_normalization_3/FusedBatchNormV3;model/depthwise_conv2d_1/depthwise;model/depthwise_conv2d_1/BiasAdd;model/depthwise_conv2d_1/BiasAdd/ReadVariableOp/resource:0:0 */, %v_param_9: Tensor[(1, 1, 16, 32), int8] /* ty=Tensor[(1, 1, 16, 32), int8] span=model/conv2d_2/Conv2D:0:0 */, %v_param_10: Tensor[(32), int32] /* ty=Tensor[(32), int32] span=model/activation_4/Relu;model/batch_normalization_4/FusedBatchNormV3;model/conv2d_2/BiasAdd/ReadVariableOp/resource;model/conv2d_2/BiasAdd;model/depthwise_conv2d_3/depthwise;model/conv2d_2/Conv2D:0:0 */, %v_param_11: Tensor[(3, 3, 32, 1), int8] /* ty=Tensor[(3, 3, 32, 1), int8] span=model/batch_normalization_5/FusedBatchNormV3;model/depthwise_conv2d_2/depthwise;model/depthwise_conv2d_2/BiasAdd;model/depthwise_conv2d_3/depthwise;model/depthwise_conv2d_2/BiasAdd/ReadVariableOp/resource:0:0 */, %v_param_12: Tensor[(32), int32] /* ty=Tensor[(32), int32] span=model/activation_5/Relu;model/batch_normalization_5/FusedBatchNormV3;model/depthwise_conv2d_2/depthwise;model/depthwise_conv2d_2/BiasAdd;model/depthwise_conv2d_3/depthwise;model/depthwise_conv2d_2/BiasAdd/ReadVariableOp/resource:0:0 */, %v_param_13: Tensor[(1, 1, 32, 32), int8] /* ty=Tensor[(1, 1, 32, 32), int8] span=model/conv2d_3/Conv2D:0:0 */, %v_param_14: Tensor[(32), int32] /* ty=Tensor[(32), int32] span=model/activation_6/Relu;model/batch_normalization_6/FusedBatchNormV3;model/conv2d_3/BiasAdd/ReadVariableOp/resource;model/conv2d_3/BiasAdd;model/depthwise_conv2d_3/depthwise;model/conv2d_3/Conv2D:0:0 */, %v_param_15: Tensor[(3, 3, 32, 1), int8] /* ty=Tensor[(3, 3, 32, 1), int8] span=model/batch_normalization_7/FusedBatchNormV3;model/depthwise_conv2d_3/depthwise;model/depthwise_conv2d_3/BiasAdd;model/depthwise_conv2d_3/BiasAdd/ReadVariableOp/resource:0:0 */, %v_param_16: Tensor[(32), int32] /* ty=Tensor[(32), int32] span=model/activation_7/Relu;model/batch_normalization_7/FusedBatchNormV3;model/depthwise_conv2d_3/depthwise;model/depthwise_conv2d_3/BiasAdd;model/depthwise_conv2d_3/BiasAdd/ReadVariableOp/resource:0:0 */, %v_param_17: Tensor[(1, 1, 32, 64), int8] /* ty=Tensor[(1, 1, 32, 64), int8] span=model/conv2d_4/Conv2D:0:0 */, %v_param_18: Tensor[(64), int32] /* ty=Tensor[(64), int32] span=model/activation_8/Relu;model/batch_normalization_8/FusedBatchNormV3;model/conv2d_4/BiasAdd/ReadVariableOp/resource;model/conv2d_4/BiasAdd;model/depthwise_conv2d_5/depthwise;model/conv2d_4/Conv2D:0:0 */, %v_param_19: Tensor[(3, 3, 64, 1), int8] /* ty=Tensor[(3, 3, 64, 1), int8] span=model/batch_normalization_9/FusedBatchNormV3;model/depthwise_conv2d_4/depthwise;model/depthwise_conv2d_4/BiasAdd;model/depthwise_conv2d_5/depthwise;model/depthwise_conv2d_4/BiasAdd/ReadVariableOp/resource:0:0 */, %v_param_20: Tensor[(64), int32] /* ty=Tensor[(64), int32] span=model/activation_9/Relu;model/batch_normalization_9/FusedBatchNormV3;model/depthwise_conv2d_4/depthwise;model/depthwise_conv2d_4/BiasAdd;model/depthwise_conv2d_5/depthwise;model/depthwise_conv2d_4/BiasAdd/ReadVariableOp/resource:0:0 */, %v_param_21: Tensor[(1, 1, 64, 64), int8] /* ty=Tensor[(1, 1, 64, 64), int8] span=model/conv2d_5/Conv2D:0:0 */, %v_param_22: Tensor[(64), int32] /* ty=Tensor[(64), int32] span=model/activation_10/Relu;model/batch_normalization_10/FusedBatchNormV3;model/conv2d_5/BiasAdd/ReadVariableOp/resource;model/conv2d_5/BiasAdd;model/depthwise_conv2d_5/depthwise;model/conv2d_5/Conv2D:0:0 */, %v_param_23: Tensor[(3, 3, 64, 1), int8] /* ty=Tensor[(3, 3, 64, 1), int8] span=model/batch_normalization_11/FusedBatchNormV3;model/depthwise_conv2d_5/depthwise;model/depthwise_conv2d_5/BiasAdd;model/depthwise_conv2d_5/BiasAdd/ReadVariableOp/resource:0:0 */, %v_param_24: Tensor[(64), int32] /* ty=Tensor[(64), int32] span=model/activation_11/Relu;model/batch_normalization_11/FusedBatchNormV3;model/depthwise_conv2d_5/depthwise;model/depthwise_conv2d_5/BiasAdd;model/depthwise_conv2d_5/BiasAdd/ReadVariableOp/resource:0:0 */, %v_param_25: Tensor[(1, 1, 64, 128), int8] /* ty=Tensor[(1, 1, 64, 128), int8] span=model/conv2d_6/Conv2D:0:0 */, %v_param_26: Tensor[(128), int32] /* ty=Tensor[(128), int32] span=model/activation_12/Relu;model/batch_normalization_12/FusedBatchNormV3;model/conv2d_6/BiasAdd/ReadVariableOp/resource;model/conv2d_6/BiasAdd;model/depthwise_conv2d_11/depthwise;model/conv2d_6/Conv2D:0:0 */, %v_param_27: Tensor[(3, 3, 128, 1), int8] /* ty=Tensor[(3, 3, 128, 1), int8] span=model/batch_normalization_13/FusedBatchNormV3;model/depthwise_conv2d_6/depthwise;model/depthwise_conv2d_6/BiasAdd;model/depthwise_conv2d_11/depthwise;model/depthwise_conv2d_6/BiasAdd/ReadVariableOp/resource:0:0 */, %v_param_28: Tensor[(128), int32] /* ty=Tensor[(128), int32] span=model/activation_13/Relu;model/batch_normalization_13/FusedBatchNormV3;model/depthwise_conv2d_6/depthwise;model/depthwise_conv2d_6/BiasAdd;model/depthwise_conv2d_11/depthwise;model/depthwise_conv2d_6/BiasAdd/ReadVariableOp/resource:0:0 */, %v_param_29: Tensor[(1, 1, 128, 128), int8] /* ty=Tensor[(1, 1, 128, 128), int8] span=model/conv2d_7/Conv2D:0:0 */, %v_param_30: Tensor[(128), int32] /* ty=Tensor[(128), int32] span=model/activation_14/Relu;model/batch_normalization_14/FusedBatchNormV3;model/conv2d_7/BiasAdd/ReadVariableOp/resource;model/conv2d_7/BiasAdd;model/depthwise_conv2d_11/depthwise;model/conv2d_7/Conv2D:0:0 */, %v_param_31: Tensor[(3, 3, 128, 1), int8] /* ty=Tensor[(3, 3, 128, 1), int8] span=model/batch_normalization_15/FusedBatchNormV3;model/depthwise_conv2d_7/depthwise;model/depthwise_conv2d_7/BiasAdd;model/depthwise_conv2d_11/depthwise;model/depthwise_conv2d_7/BiasAdd/ReadVariableOp/resource:0:0 */, %v_param_32: Tensor[(128), int32] /* ty=Tensor[(128), int32] span=model/activation_15/Relu;model/batch_normalization_15/FusedBatchNormV3;model/depthwise_conv2d_7/depthwise;model/depthwise_conv2d_7/BiasAdd;model/depthwise_conv2d_11/depthwise;model/depthwise_conv2d_7/BiasAdd/ReadVariableOp/resource:0:0 */, %v_param_33: Tensor[(1, 1, 128, 128), int8] /* ty=Tensor[(1, 1, 128, 128), int8] span=model/conv2d_8/Conv2D:0:0 */, %v_param_34: Tensor[(128), int32] /* ty=Tensor[(128), int32] span=model/activation_16/Relu;model/batch_normalization_16/FusedBatchNormV3;model/conv2d_8/BiasAdd/ReadVariableOp/resource;model/conv2d_8/BiasAdd;model/depthwise_conv2d_11/depthwise;model/conv2d_8/Conv2D:0:0 */, %v_param_35: Tensor[(3, 3, 128, 1), int8] /* ty=Tensor[(3, 3, 128, 1), int8] span=model/batch_normalization_17/FusedBatchNormV3;model/depthwise_conv2d_8/depthwise;model/depthwise_conv2d_8/BiasAdd;model/depthwise_conv2d_11/depthwise;model/depthwise_conv2d_8/BiasAdd/ReadVariableOp/resource:0:0 */, %v_param_36: Tensor[(128), int32] /* ty=Tensor[(128), int32] span=model/activation_17/Relu;model/batch_normalization_17/FusedBatchNormV3;model/depthwise_conv2d_8/depthwise;model/depthwise_conv2d_8/BiasAdd;model/depthwise_conv2d_11/depthwise;model/depthwise_conv2d_8/BiasAdd/ReadVariableOp/resource:0:0 */, %v_param_37: Tensor[(1, 1, 128, 128), int8] /* ty=Tensor[(1, 1, 128, 128), int8] span=model/conv2d_9/Conv2D:0:0 */, %v_param_38: Tensor[(128), int32] /* ty=Tensor[(128), int32] span=model/activation_18/Relu;model/batch_normalization_18/FusedBatchNormV3;model/conv2d_9/BiasAdd/ReadVariableOp/resource;model/conv2d_9/BiasAdd;model/depthwise_conv2d_11/depthwise;model/conv2d_9/Conv2D:0:0 */, %v_param_39: Tensor[(3, 3, 128, 1), int8] /* ty=Tensor[(3, 3, 128, 1), int8] span=model/batch_normalization_19/FusedBatchNormV3;model/depthwise_conv2d_9/depthwise;model/depthwise_conv2d_9/BiasAdd;model/depthwise_conv2d_11/depthwise;model/depthwise_conv2d_9/BiasAdd/ReadVariableOp/resource:0:0 */, %v_param_40: Tensor[(128), int32] /* ty=Tensor[(128), int32] span=model/activation_19/Relu;model/batch_normalization_19/FusedBatchNormV3;model/depthwise_conv2d_9/depthwise;model/depthwise_conv2d_9/BiasAdd;model/depthwise_conv2d_11/depthwise;model/depthwise_conv2d_9/BiasAdd/ReadVariableOp/resource:0:0 */, %v_param_41: Tensor[(1, 1, 128, 128), int8] /* ty=Tensor[(1, 1, 128, 128), int8] span=model/conv2d_10/Conv2D:0:0 */, %v_param_42: Tensor[(128), int32] /* ty=Tensor[(128), int32] span=model/activation_20/Relu;model/batch_normalization_20/FusedBatchNormV3;model/conv2d_10/BiasAdd/ReadVariableOp/resource;model/conv2d_10/BiasAdd;model/depthwise_conv2d_11/depthwise;model/conv2d_10/Conv2D:0:0 */, %v_param_43: Tensor[(3, 3, 128, 1), int8] /* ty=Tensor[(3, 3, 128, 1), int8] span=model/batch_normalization_21/FusedBatchNormV3;model/depthwise_conv2d_10/depthwise;model/depthwise_conv2d_10/BiasAdd;model/depthwise_conv2d_11/depthwise;model/depthwise_conv2d_10/BiasAdd/ReadVariableOp/resource:0:0 */, %v_param_44: Tensor[(128), int32] /* ty=Tensor[(128), int32] span=model/activation_21/Relu;model/batch_normalization_21/FusedBatchNormV3;model/depthwise_conv2d_10/depthwise;model/depthwise_conv2d_10/BiasAdd;model/depthwise_conv2d_11/depthwise;model/depthwise_conv2d_10/BiasAdd/ReadVariableOp/resource:0:0 */, %v_param_45: Tensor[(1, 1, 128, 128), int8] /* ty=Tensor[(1, 1, 128, 128), int8] span=model/conv2d_11/Conv2D:0:0 */, %v_param_46: Tensor[(128), int32] /* ty=Tensor[(128), int32] span=model/activation_22/Relu;model/batch_normalization_22/FusedBatchNormV3;model/conv2d_11/BiasAdd/ReadVariableOp/resource;model/conv2d_11/BiasAdd;model/depthwise_conv2d_11/depthwise;model/conv2d_11/Conv2D:0:0 */, %v_param_47: Tensor[(3, 3, 128, 1), int8] /* ty=Tensor[(3, 3, 128, 1), int8] span=model/batch_normalization_23/FusedBatchNormV3;model/depthwise_conv2d_11/depthwise;model/depthwise_conv2d_11/BiasAdd;model/depthwise_conv2d_11/BiasAdd/ReadVariableOp/resource:0:0 */, %v_param_48: Tensor[(128), int32] /* ty=Tensor[(128), int32] span=model/activation_23/Relu;model/batch_normalization_23/FusedBatchNormV3;model/depthwise_conv2d_11/depthwise;model/depthwise_conv2d_11/BiasAdd;model/depthwise_conv2d_11/BiasAdd/ReadVariableOp/resource:0:0 */, %v_param_49: Tensor[(1, 1, 128, 256), int8] /* ty=Tensor[(1, 1, 128, 256), int8] span=model/conv2d_12/Conv2D:0:0 */, %v_param_50: Tensor[(256), int32] /* ty=Tensor[(256), int32] span=model/activation_24/Relu;model/batch_normalization_24/FusedBatchNormV3;model/conv2d_12/BiasAdd/ReadVariableOp/resource;model/conv2d_12/BiasAdd;model/conv2d_13/Conv2D;model/conv2d_12/Conv2D:0:0 */, %v_param_51: Tensor[(3, 3, 256, 1), int8] /* ty=Tensor[(3, 3, 256, 1), int8] span=model/batch_normalization_25/FusedBatchNormV3;model/depthwise_conv2d_12/depthwise;model/depthwise_conv2d_12/BiasAdd;model/conv2d_13/Conv2D;model/depthwise_conv2d_12/BiasAdd/ReadVariableOp/resource:0:0 */, %v_param_52: Tensor[(256), int32] /* ty=Tensor[(256), int32] span=model/activation_25/Relu;model/batch_normalization_25/FusedBatchNormV3;model/depthwise_conv2d_12/depthwise;model/depthwise_conv2d_12/BiasAdd;model/conv2d_13/Conv2D;model/depthwise_conv2d_12/BiasAdd/ReadVariableOp/resource:0:0 */, %v_param_53: Tensor[(1, 1, 256, 256), int8] /* ty=Tensor[(1, 1, 256, 256), int8] span=model/conv2d_13/Conv2D:0:0 */, %v_param_54: Tensor[(256), int32] /* ty=Tensor[(256), int32] span=model/activation_26/Relu;model/batch_normalization_26/FusedBatchNormV3;model/conv2d_13/BiasAdd/ReadVariableOp/resource;model/conv2d_13/BiasAdd;model/conv2d_13/Conv2D:0:0 */, %v_param_55: Tensor[(2, 256), int8] /* ty=Tensor[(2, 256), int8] span=model/dense/MatMul:0:0 */, %v_param_56: Tensor[(2), int32] /* ty=Tensor[(2), int32] span=model/dense/BiasAdd/ReadVariableOp/resource:0:0 */, output_tensor_names=["Identity_int8"]) -> Tensor[(1, 2), int8] {
  %0 = qnn.conv2d(%input_1_int8, %v_param_1, -128 /* ty=int32 span=model/activation/Relu;model/batch_normalization/FusedBatchNormV3;model/conv2d/BiasAdd/ReadVariableOp/resource;model/conv2d/BiasAdd;model/depthwise_conv2d/depthwise;model/conv2d/Conv2D1:0:0 */, 0 /* ty=int32 span=model/activation/Relu;model/batch_normalization/FusedBatchNormV3;model/conv2d/BiasAdd/ReadVariableOp/resource;model/conv2d/BiasAdd;model/depthwise_conv2d/depthwise;model/conv2d/Conv2D1:0:0 */, 0.00392157f /* ty=float32 span=model/activation/Relu;model/batch_normalization/FusedBatchNormV3;model/conv2d/BiasAdd/ReadVariableOp/resource;model/conv2d/BiasAdd;model/depthwise_conv2d/depthwise;model/conv2d/Conv2D1:0:0 */, meta[relay.Constant][0] /* ty=Tensor[(8), float32] span=model/activation/Relu;model/batch_normalization/FusedBatchNormV3;model/conv2d/BiasAdd/ReadVariableOp/resource;model/conv2d/BiasAdd;model/depthwise_conv2d/depthwise;model/conv2d/Conv2D1:0:0 */, strides=[2, 2], padding=[0, 0, 1, 1], channels=8, kernel_size=[3, 3], data_layout="NHWC", kernel_layout="HWIO", out_dtype="int32") /* ty=Tensor[(1, 48, 48, 8), int32] span=model/activation/Relu;model/batch_normalization/FusedBatchNormV3;model/conv2d/BiasAdd/ReadVariableOp/resource;model/conv2d/BiasAdd;model/depthwise_conv2d/depthwise;model/conv2d/Conv2D1:0:0 */;
  %1 = nn.bias_add(%0, %v_param_2, axis=3) /* ty=Tensor[(1, 48, 48, 8), int32] span=model/activation/Relu;model/batch_normalization/FusedBatchNormV3;model/conv2d/BiasAdd/ReadVariableOp/resource;model/conv2d/BiasAdd;model/depthwise_conv2d/depthwise;model/conv2d/Conv2D1:0:0 */;
  %2 = qnn.requantize(%1, meta[relay.Constant][1] /* ty=Tensor[(8), float32] span=model/activation/Relu;model/batch_normalization/FusedBatchNormV3;model/conv2d/BiasAdd/ReadVariableOp/resource;model/conv2d/BiasAdd;model/depthwise_conv2d/depthwise;model/conv2d/Conv2D1:0:0 */, 0 /* ty=int32 span=model/activation/Relu;model/batch_normalization/FusedBatchNormV3;model/conv2d/BiasAdd/ReadVariableOp/resource;model/conv2d/BiasAdd;model/depthwise_conv2d/depthwise;model/conv2d/Conv2D1:0:0 */, 0.01497f /* ty=float32 span=model/activation/Relu;model/batch_normalization/FusedBatchNormV3;model/conv2d/BiasAdd/ReadVariableOp/resource;model/conv2d/BiasAdd;model/depthwise_conv2d/depthwise;model/conv2d/Conv2D1:0:0 */, -128 /* ty=int32 span=model/activation/Relu;model/batch_normalization/FusedBatchNormV3;model/conv2d/BiasAdd/ReadVariableOp/resource;model/conv2d/BiasAdd;model/depthwise_conv2d/depthwise;model/conv2d/Conv2D1:0:0 */, axis=3, rounding="UPWARD", compute_dtype="int64", out_dtype="int8") /* ty=Tensor[(1, 48, 48, 8), int8] span=model/activation/Relu;model/batch_normalization/FusedBatchNormV3;model/conv2d/BiasAdd/ReadVariableOp/resource;model/conv2d/BiasAdd;model/depthwise_conv2d/depthwise;model/conv2d/Conv2D1:0:0 */;
  %3 = clip(%2, a_min=-128f, a_max=127f) /* ty=Tensor[(1, 48, 48, 8), int8] span=model/activation/Relu;model/batch_normalization/FusedBatchNormV3;model/conv2d/BiasAdd/ReadVariableOp/resource;model/conv2d/BiasAdd;model/depthwise_conv2d/depthwise;model/conv2d/Conv2D1:0:0 */;
  %4 = qnn.conv2d(%3, %v_param_3, -128 /* ty=int32 span=model/activation_1/Relu;model/batch_normalization_1/FusedBatchNormV3;model/depthwise_conv2d/depthwise;model/depthwise_conv2d/BiasAdd;model/depthwise_conv2d/BiasAdd/ReadVariableOp/resource1:0:0 */, 0 /* ty=int32 span=model/activation_1/Relu;model/batch_normalization_1/FusedBatchNormV3;model/depthwise_conv2d/depthwise;model/depthwise_conv2d/BiasAdd;model/depthwise_conv2d/BiasAdd/ReadVariableOp/resource1:0:0 */, 0.01497f /* ty=float32 span=model/activation_1/Relu;model/batch_normalization_1/FusedBatchNormV3;model/depthwise_conv2d/depthwise;model/depthwise_conv2d/BiasAdd;model/depthwise_conv2d/BiasAdd/ReadVariableOp/resource1:0:0 */, meta[relay.Constant][2] /* ty=Tensor[(8), float32] span=model/activation_1/Relu;model/batch_normalization_1/FusedBatchNormV3;model/depthwise_conv2d/depthwise;model/depthwise_conv2d/BiasAdd;model/depthwise_conv2d/BiasAdd/ReadVariableOp/resource1:0:0 */, padding=[1, 1, 1, 1], groups=8, channels=8, kernel_size=[3, 3], data_layout="NHWC", kernel_layout="HWOI", out_dtype="int32") /* ty=Tensor[(1, 48, 48, 8), int32] span=model/activation_1/Relu;model/batch_normalization_1/FusedBatchNormV3;model/depthwise_conv2d/depthwise;model/depthwise_conv2d/BiasAdd;model/depthwise_conv2d/BiasAdd/ReadVariableOp/resource1:0:0 */;
  %5 = nn.bias_add(%4, %v_param_4, axis=3) /* ty=Tensor[(1, 48, 48, 8), int32] span=model/activation_1/Relu;model/batch_normalization_1/FusedBatchNormV3;model/depthwise_conv2d/depthwise;model/depthwise_conv2d/BiasAdd;model/depthwise_conv2d/BiasAdd/ReadVariableOp/resource1:0:0 */;
  %6 = qnn.requantize(%5, meta[relay.Constant][3] /* ty=Tensor[(8), float32] span=model/activation_1/Relu;model/batch_normalization_1/FusedBatchNormV3;model/depthwise_conv2d/depthwise;model/depthwise_conv2d/BiasAdd;model/depthwise_conv2d/BiasAdd/ReadVariableOp/resource1:0:0 */, 0 /* ty=int32 span=model/activation_1/Relu;model/batch_normalization_1/FusedBatchNormV3;model/depthwise_conv2d/depthwise;model/depthwise_conv2d/BiasAdd;model/depthwise_conv2d/BiasAdd/ReadVariableOp/resource1:0:0 */, 0.0483876f /* ty=float32 span=model/activation_1/Relu;model/batch_normalization_1/FusedBatchNormV3;model/depthwise_conv2d/depthwise;model/depthwise_conv2d/BiasAdd;model/depthwise_conv2d/BiasAdd/ReadVariableOp/resource1:0:0 */, -128 /* ty=int32 span=model/activation_1/Relu;model/batch_normalization_1/FusedBatchNormV3;model/depthwise_conv2d/depthwise;model/depthwise_conv2d/BiasAdd;model/depthwise_conv2d/BiasAdd/ReadVariableOp/resource1:0:0 */, axis=3, rounding="UPWARD", compute_dtype="int64", out_dtype="int8") /* ty=Tensor[(1, 48, 48, 8), int8] span=model/activation_1/Relu;model/batch_normalization_1/FusedBatchNormV3;model/depthwise_conv2d/depthwise;model/depthwise_conv2d/BiasAdd;model/depthwise_conv2d/BiasAdd/ReadVariableOp/resource1:0:0 */;
  %7 = clip(%6, a_min=-128f, a_max=127f) /* ty=Tensor[(1, 48, 48, 8), int8] span=model/activation_1/Relu;model/batch_normalization_1/FusedBatchNormV3;model/depthwise_conv2d/depthwise;model/depthwise_conv2d/BiasAdd;model/depthwise_conv2d/BiasAdd/ReadVariableOp/resource1:0:0 */;
  %8 = qnn.conv2d(%7, %v_param_5, -128 /* ty=int32 span=model/activation_2/Relu;model/batch_normalization_2/FusedBatchNormV3;model/conv2d_1/BiasAdd/ReadVariableOp/resource;model/conv2d_1/BiasAdd;model/depthwise_conv2d_1/depthwise;model/conv2d_1/Conv2D1:0:0 */, 0 /* ty=int32 span=model/activation_2/Relu;model/batch_normalization_2/FusedBatchNormV3;model/conv2d_1/BiasAdd/ReadVariableOp/resource;model/conv2d_1/BiasAdd;model/depthwise_conv2d_1/depthwise;model/conv2d_1/Conv2D1:0:0 */, 0.0483876f /* ty=float32 span=model/activation_2/Relu;model/batch_normalization_2/FusedBatchNormV3;model/conv2d_1/BiasAdd/ReadVariableOp/resource;model/conv2d_1/BiasAdd;model/depthwise_conv2d_1/depthwise;model/conv2d_1/Conv2D1:0:0 */, meta[relay.Constant][4] /* ty=Tensor[(16), float32] span=model/activation_2/Relu;model/batch_normalization_2/FusedBatchNormV3;model/conv2d_1/BiasAdd/ReadVariableOp/resource;model/conv2d_1/BiasAdd;model/depthwise_conv2d_1/depthwise;model/conv2d_1/Conv2D1:0:0 */, padding=[0, 0, 0, 0], channels=16, kernel_size=[1, 1], data_layout="NHWC", kernel_layout="HWIO", out_dtype="int32") /* ty=Tensor[(1, 48, 48, 16), int32] span=model/activation_2/Relu;model/batch_normalization_2/FusedBatchNormV3;model/conv2d_1/BiasAdd/ReadVariableOp/resource;model/conv2d_1/BiasAdd;model/depthwise_conv2d_1/depthwise;model/conv2d_1/Conv2D1:0:0 */;
  %9 = nn.bias_add(%8, %v_param_6, axis=3) /* ty=Tensor[(1, 48, 48, 16), int32] span=model/activation_2/Relu;model/batch_normalization_2/FusedBatchNormV3;model/conv2d_1/BiasAdd/ReadVariableOp/resource;model/conv2d_1/BiasAdd;model/depthwise_conv2d_1/depthwise;model/conv2d_1/Conv2D1:0:0 */;
  %10 = qnn.requantize(%9, meta[relay.Constant][5] /* ty=Tensor[(16), float32] span=model/activation_2/Relu;model/batch_normalization_2/FusedBatchNormV3;model/conv2d_1/BiasAdd/ReadVariableOp/resource;model/conv2d_1/BiasAdd;model/depthwise_conv2d_1/depthwise;model/conv2d_1/Conv2D1:0:0 */, 0 /* ty=int32 span=model/activation_2/Relu;model/batch_normalization_2/FusedBatchNormV3;model/conv2d_1/BiasAdd/ReadVariableOp/resource;model/conv2d_1/BiasAdd;model/depthwise_conv2d_1/depthwise;model/conv2d_1/Conv2D1:0:0 */, 0.0341311f /* ty=float32 span=model/activation_2/Relu;model/batch_normalization_2/FusedBatchNormV3;model/conv2d_1/BiasAdd/ReadVariableOp/resource;model/conv2d_1/BiasAdd;model/depthwise_conv2d_1/depthwise;model/conv2d_1/Conv2D1:0:0 */, -128 /* ty=int32 span=model/activation_2/Relu;model/batch_normalization_2/FusedBatchNormV3;model/conv2d_1/BiasAdd/ReadVariableOp/resource;model/conv2d_1/BiasAdd;model/depthwise_conv2d_1/depthwise;model/conv2d_1/Conv2D1:0:0 */, axis=3, rounding="UPWARD", compute_dtype="int64", out_dtype="int8") /* ty=Tensor[(1, 48, 48, 16), int8] span=model/activation_2/Relu;model/batch_normalization_2/FusedBatchNormV3;model/conv2d_1/BiasAdd/ReadVariableOp/resource;model/conv2d_1/BiasAdd;model/depthwise_conv2d_1/depthwise;model/conv2d_1/Conv2D1:0:0 */;
  %11 = clip(%10, a_min=-128f, a_max=127f) /* ty=Tensor[(1, 48, 48, 16), int8] span=model/activation_2/Relu;model/batch_normalization_2/FusedBatchNormV3;model/conv2d_1/BiasAdd/ReadVariableOp/resource;model/conv2d_1/BiasAdd;model/depthwise_conv2d_1/depthwise;model/conv2d_1/Conv2D1:0:0 */;
  %12 = qnn.conv2d(%11, %v_param_7, -128 /* ty=int32 span=model/activation_3/Relu;model/batch_normalization_3/FusedBatchNormV3;model/depthwise_conv2d_1/depthwise;model/depthwise_conv2d_1/BiasAdd;model/depthwise_conv2d_1/BiasAdd/ReadVariableOp/resource1:0:0 */, 0 /* ty=int32 span=model/activation_3/Relu;model/batch_normalization_3/FusedBatchNormV3;model/depthwise_conv2d_1/depthwise;model/depthwise_conv2d_1/BiasAdd;model/depthwise_conv2d_1/BiasAdd/ReadVariableOp/resource1:0:0 */, 0.0341311f /* ty=float32 span=model/activation_3/Relu;model/batch_normalization_3/FusedBatchNormV3;model/depthwise_conv2d_1/depthwise;model/depthwise_conv2d_1/BiasAdd;model/depthwise_conv2d_1/BiasAdd/ReadVariableOp/resource1:0:0 */, meta[relay.Constant][6] /* ty=Tensor[(16), float32] span=model/activation_3/Relu;model/batch_normalization_3/FusedBatchNormV3;model/depthwise_conv2d_1/depthwise;model/depthwise_conv2d_1/BiasAdd;model/depthwise_conv2d_1/BiasAdd/ReadVariableOp/resource1:0:0 */, strides=[2, 2], padding=[0, 0, 1, 1], groups=16, channels=16, kernel_size=[3, 3], data_layout="NHWC", kernel_layout="HWOI", out_dtype="int32") /* ty=Tensor[(1, 24, 24, 16), int32] span=model/activation_3/Relu;model/batch_normalization_3/FusedBatchNormV3;model/depthwise_conv2d_1/depthwise;model/depthwise_conv2d_1/BiasAdd;model/depthwise_conv2d_1/BiasAdd/ReadVariableOp/resource1:0:0 */;
  %13 = nn.bias_add(%12, %v_param_8, axis=3) /* ty=Tensor[(1, 24, 24, 16), int32] span=model/activation_3/Relu;model/batch_normalization_3/FusedBatchNormV3;model/depthwise_conv2d_1/depthwise;model/depthwise_conv2d_1/BiasAdd;model/depthwise_conv2d_1/BiasAdd/ReadVariableOp/resource1:0:0 */;
  %14 = qnn.requantize(%13, meta[relay.Constant][7] /* ty=Tensor[(16), float32] span=model/activation_3/Relu;model/batch_normalization_3/FusedBatchNormV3;model/depthwise_conv2d_1/depthwise;model/depthwise_conv2d_1/BiasAdd;model/depthwise_conv2d_1/BiasAdd/ReadVariableOp/resource1:0:0 */, 0 /* ty=int32 span=model/activation_3/Relu;model/batch_normalization_3/FusedBatchNormV3;model/depthwise_conv2d_1/depthwise;model/depthwise_conv2d_1/BiasAdd;model/depthwise_conv2d_1/BiasAdd/ReadVariableOp/resource1:0:0 */, 0.0304951f /* ty=float32 span=model/activation_3/Relu;model/batch_normalization_3/FusedBatchNormV3;model/depthwise_conv2d_1/depthwise;model/depthwise_conv2d_1/BiasAdd;model/depthwise_conv2d_1/BiasAdd/ReadVariableOp/resource1:0:0 */, -128 /* ty=int32 span=model/activation_3/Relu;model/batch_normalization_3/FusedBatchNormV3;model/depthwise_conv2d_1/depthwise;model/depthwise_conv2d_1/BiasAdd;model/depthwise_conv2d_1/BiasAdd/ReadVariableOp/resource1:0:0 */, axis=3, rounding="UPWARD", compute_dtype="int64", out_dtype="int8") /* ty=Tensor[(1, 24, 24, 16), int8] span=model/activation_3/Relu;model/batch_normalization_3/FusedBatchNormV3;model/depthwise_conv2d_1/depthwise;model/depthwise_conv2d_1/BiasAdd;model/depthwise_conv2d_1/BiasAdd/ReadVariableOp/resource1:0:0 */;
  %15 = clip(%14, a_min=-128f, a_max=127f) /* ty=Tensor[(1, 24, 24, 16), int8] span=model/activation_3/Relu;model/batch_normalization_3/FusedBatchNormV3;model/depthwise_conv2d_1/depthwise;model/depthwise_conv2d_1/BiasAdd;model/depthwise_conv2d_1/BiasAdd/ReadVariableOp/resource1:0:0 */;
  %16 = qnn.conv2d(%15, %v_param_9, -128 /* ty=int32 span=model/activation_4/Relu;model/batch_normalization_4/FusedBatchNormV3;model/conv2d_2/BiasAdd/ReadVariableOp/resource;model/conv2d_2/BiasAdd;model/depthwise_conv2d_3/depthwise;model/conv2d_2/Conv2D1:0:0 */, 0 /* ty=int32 span=model/activation_4/Relu;model/batch_normalization_4/FusedBatchNormV3;model/conv2d_2/BiasAdd/ReadVariableOp/resource;model/conv2d_2/BiasAdd;model/depthwise_conv2d_3/depthwise;model/conv2d_2/Conv2D1:0:0 */, 0.0304951f /* ty=float32 span=model/activation_4/Relu;model/batch_normalization_4/FusedBatchNormV3;model/conv2d_2/BiasAdd/ReadVariableOp/resource;model/conv2d_2/BiasAdd;model/depthwise_conv2d_3/depthwise;model/conv2d_2/Conv2D1:0:0 */, meta[relay.Constant][8] /* ty=Tensor[(32), float32] span=model/activation_4/Relu;model/batch_normalization_4/FusedBatchNormV3;model/conv2d_2/BiasAdd/ReadVariableOp/resource;model/conv2d_2/BiasAdd;model/depthwise_conv2d_3/depthwise;model/conv2d_2/Conv2D1:0:0 */, padding=[0, 0, 0, 0], channels=32, kernel_size=[1, 1], data_layout="NHWC", kernel_layout="HWIO", out_dtype="int32") /* ty=Tensor[(1, 24, 24, 32), int32] span=model/activation_4/Relu;model/batch_normalization_4/FusedBatchNormV3;model/conv2d_2/BiasAdd/ReadVariableOp/resource;model/conv2d_2/BiasAdd;model/depthwise_conv2d_3/depthwise;model/conv2d_2/Conv2D1:0:0 */;
  %17 = nn.bias_add(%16, %v_param_10, axis=3) /* ty=Tensor[(1, 24, 24, 32), int32] span=model/activation_4/Relu;model/batch_normalization_4/FusedBatchNormV3;model/conv2d_2/BiasAdd/ReadVariableOp/resource;model/conv2d_2/BiasAdd;model/depthwise_conv2d_3/depthwise;model/conv2d_2/Conv2D1:0:0 */;
  %18 = qnn.requantize(%17, meta[relay.Constant][9] /* ty=Tensor[(32), float32] span=model/activation_4/Relu;model/batch_normalization_4/FusedBatchNormV3;model/conv2d_2/BiasAdd/ReadVariableOp/resource;model/conv2d_2/BiasAdd;model/depthwise_conv2d_3/depthwise;model/conv2d_2/Conv2D1:0:0 */, 0 /* ty=int32 span=model/activation_4/Relu;model/batch_normalization_4/FusedBatchNormV3;model/conv2d_2/BiasAdd/ReadVariableOp/resource;model/conv2d_2/BiasAdd;model/depthwise_conv2d_3/depthwise;model/conv2d_2/Conv2D1:0:0 */, 0.0323921f /* ty=float32 span=model/activation_4/Relu;model/batch_normalization_4/FusedBatchNormV3;model/conv2d_2/BiasAdd/ReadVariableOp/resource;model/conv2d_2/BiasAdd;model/depthwise_conv2d_3/depthwise;model/conv2d_2/Conv2D1:0:0 */, -128 /* ty=int32 span=model/activation_4/Relu;model/batch_normalization_4/FusedBatchNormV3;model/conv2d_2/BiasAdd/ReadVariableOp/resource;model/conv2d_2/BiasAdd;model/depthwise_conv2d_3/depthwise;model/conv2d_2/Conv2D1:0:0 */, axis=3, rounding="UPWARD", compute_dtype="int64", out_dtype="int8") /* ty=Tensor[(1, 24, 24, 32), int8] span=model/activation_4/Relu;model/batch_normalization_4/FusedBatchNormV3;model/conv2d_2/BiasAdd/ReadVariableOp/resource;model/conv2d_2/BiasAdd;model/depthwise_conv2d_3/depthwise;model/conv2d_2/Conv2D1:0:0 */;
  %19 = clip(%18, a_min=-128f, a_max=127f) /* ty=Tensor[(1, 24, 24, 32), int8] span=model/activation_4/Relu;model/batch_normalization_4/FusedBatchNormV3;model/conv2d_2/BiasAdd/ReadVariableOp/resource;model/conv2d_2/BiasAdd;model/depthwise_conv2d_3/depthwise;model/conv2d_2/Conv2D1:0:0 */;
  %20 = qnn.conv2d(%19, %v_param_11, -128 /* ty=int32 span=model/activation_5/Relu;model/batch_normalization_5/FusedBatchNormV3;model/depthwise_conv2d_2/depthwise;model/depthwise_conv2d_2/BiasAdd;model/depthwise_conv2d_3/depthwise;model/depthwise_conv2d_2/BiasAdd/ReadVariableOp/resource1:0:0 */, 0 /* ty=int32 span=model/activation_5/Relu;model/batch_normalization_5/FusedBatchNormV3;model/depthwise_conv2d_2/depthwise;model/depthwise_conv2d_2/BiasAdd;model/depthwise_conv2d_3/depthwise;model/depthwise_conv2d_2/BiasAdd/ReadVariableOp/resource1:0:0 */, 0.0323921f /* ty=float32 span=model/activation_5/Relu;model/batch_normalization_5/FusedBatchNormV3;model/depthwise_conv2d_2/depthwise;model/depthwise_conv2d_2/BiasAdd;model/depthwise_conv2d_3/depthwise;model/depthwise_conv2d_2/BiasAdd/ReadVariableOp/resource1:0:0 */, meta[relay.Constant][10] /* ty=Tensor[(32), float32] span=model/activation_5/Relu;model/batch_normalization_5/FusedBatchNormV3;model/depthwise_conv2d_2/depthwise;model/depthwise_conv2d_2/BiasAdd;model/depthwise_conv2d_3/depthwise;model/depthwise_conv2d_2/BiasAdd/ReadVariableOp/resource1:0:0 */, padding=[1, 1, 1, 1], groups=32, channels=32, kernel_size=[3, 3], data_layout="NHWC", kernel_layout="HWOI", out_dtype="int32") /* ty=Tensor[(1, 24, 24, 32), int32] span=model/activation_5/Relu;model/batch_normalization_5/FusedBatchNormV3;model/depthwise_conv2d_2/depthwise;model/depthwise_conv2d_2/BiasAdd;model/depthwise_conv2d_3/depthwise;model/depthwise_conv2d_2/BiasAdd/ReadVariableOp/resource1:0:0 */;
  %21 = nn.bias_add(%20, %v_param_12, axis=3) /* ty=Tensor[(1, 24, 24, 32), int32] span=model/activation_5/Relu;model/batch_normalization_5/FusedBatchNormV3;model/depthwise_conv2d_2/depthwise;model/depthwise_conv2d_2/BiasAdd;model/depthwise_conv2d_3/depthwise;model/depthwise_conv2d_2/BiasAdd/ReadVariableOp/resource1:0:0 */;
  %22 = qnn.requantize(%21, meta[relay.Constant][11] /* ty=Tensor[(32), float32] span=model/activation_5/Relu;model/batch_normalization_5/FusedBatchNormV3;model/depthwise_conv2d_2/depthwise;model/depthwise_conv2d_2/BiasAdd;model/depthwise_conv2d_3/depthwise;model/depthwise_conv2d_2/BiasAdd/ReadVariableOp/resource1:0:0 */, 0 /* ty=int32 span=model/activation_5/Relu;model/batch_normalization_5/FusedBatchNormV3;model/depthwise_conv2d_2/depthwise;model/depthwise_conv2d_2/BiasAdd;model/depthwise_conv2d_3/depthwise;model/depthwise_conv2d_2/BiasAdd/ReadVariableOp/resource1:0:0 */, 0.0403331f /* ty=float32 span=model/activation_5/Relu;model/batch_normalization_5/FusedBatchNormV3;model/depthwise_conv2d_2/depthwise;model/depthwise_conv2d_2/BiasAdd;model/depthwise_conv2d_3/depthwise;model/depthwise_conv2d_2/BiasAdd/ReadVariableOp/resource1:0:0 */, -128 /* ty=int32 span=model/activation_5/Relu;model/batch_normalization_5/FusedBatchNormV3;model/depthwise_conv2d_2/depthwise;model/depthwise_conv2d_2/BiasAdd;model/depthwise_conv2d_3/depthwise;model/depthwise_conv2d_2/BiasAdd/ReadVariableOp/resource1:0:0 */, axis=3, rounding="UPWARD", compute_dtype="int64", out_dtype="int8") /* ty=Tensor[(1, 24, 24, 32), int8] span=model/activation_5/Relu;model/batch_normalization_5/FusedBatchNormV3;model/depthwise_conv2d_2/depthwise;model/depthwise_conv2d_2/BiasAdd;model/depthwise_conv2d_3/depthwise;model/depthwise_conv2d_2/BiasAdd/ReadVariableOp/resource1:0:0 */;
  %23 = clip(%22, a_min=-128f, a_max=127f) /* ty=Tensor[(1, 24, 24, 32), int8] span=model/activation_5/Relu;model/batch_normalization_5/FusedBatchNormV3;model/depthwise_conv2d_2/depthwise;model/depthwise_conv2d_2/BiasAdd;model/depthwise_conv2d_3/depthwise;model/depthwise_conv2d_2/BiasAdd/ReadVariableOp/resource1:0:0 */;
  %24 = qnn.conv2d(%23, %v_param_13, -128 /* ty=int32 span=model/activation_6/Relu;model/batch_normalization_6/FusedBatchNormV3;model/conv2d_3/BiasAdd/ReadVariableOp/resource;model/conv2d_3/BiasAdd;model/depthwise_conv2d_3/depthwise;model/conv2d_3/Conv2D1:0:0 */, 0 /* ty=int32 span=model/activation_6/Relu;model/batch_normalization_6/FusedBatchNormV3;model/conv2d_3/BiasAdd/ReadVariableOp/resource;model/conv2d_3/BiasAdd;model/depthwise_conv2d_3/depthwise;model/conv2d_3/Conv2D1:0:0 */, 0.0403331f /* ty=float32 span=model/activation_6/Relu;model/batch_normalization_6/FusedBatchNormV3;model/conv2d_3/BiasAdd/ReadVariableOp/resource;model/conv2d_3/BiasAdd;model/depthwise_conv2d_3/depthwise;model/conv2d_3/Conv2D1:0:0 */, meta[relay.Constant][12] /* ty=Tensor[(32), float32] span=model/activation_6/Relu;model/batch_normalization_6/FusedBatchNormV3;model/conv2d_3/BiasAdd/ReadVariableOp/resource;model/conv2d_3/BiasAdd;model/depthwise_conv2d_3/depthwise;model/conv2d_3/Conv2D1:0:0 */, padding=[0, 0, 0, 0], channels=32, kernel_size=[1, 1], data_layout="NHWC", kernel_layout="HWIO", out_dtype="int32") /* ty=Tensor[(1, 24, 24, 32), int32] span=model/activation_6/Relu;model/batch_normalization_6/FusedBatchNormV3;model/conv2d_3/BiasAdd/ReadVariableOp/resource;model/conv2d_3/BiasAdd;model/depthwise_conv2d_3/depthwise;model/conv2d_3/Conv2D1:0:0 */;
  %25 = nn.bias_add(%24, %v_param_14, axis=3) /* ty=Tensor[(1, 24, 24, 32), int32] span=model/activation_6/Relu;model/batch_normalization_6/FusedBatchNormV3;model/conv2d_3/BiasAdd/ReadVariableOp/resource;model/conv2d_3/BiasAdd;model/depthwise_conv2d_3/depthwise;model/conv2d_3/Conv2D1:0:0 */;
  %26 = qnn.requantize(%25, meta[relay.Constant][13] /* ty=Tensor[(32), float32] span=model/activation_6/Relu;model/batch_normalization_6/FusedBatchNormV3;model/conv2d_3/BiasAdd/ReadVariableOp/resource;model/conv2d_3/BiasAdd;model/depthwise_conv2d_3/depthwise;model/conv2d_3/Conv2D1:0:0 */, 0 /* ty=int32 span=model/activation_6/Relu;model/batch_normalization_6/FusedBatchNormV3;model/conv2d_3/BiasAdd/ReadVariableOp/resource;model/conv2d_3/BiasAdd;model/depthwise_conv2d_3/depthwise;model/conv2d_3/Conv2D1:0:0 */, 0.0409983f /* ty=float32 span=model/activation_6/Relu;model/batch_normalization_6/FusedBatchNormV3;model/conv2d_3/BiasAdd/ReadVariableOp/resource;model/conv2d_3/BiasAdd;model/depthwise_conv2d_3/depthwise;model/conv2d_3/Conv2D1:0:0 */, -128 /* ty=int32 span=model/activation_6/Relu;model/batch_normalization_6/FusedBatchNormV3;model/conv2d_3/BiasAdd/ReadVariableOp/resource;model/conv2d_3/BiasAdd;model/depthwise_conv2d_3/depthwise;model/conv2d_3/Conv2D1:0:0 */, axis=3, rounding="UPWARD", compute_dtype="int64", out_dtype="int8") /* ty=Tensor[(1, 24, 24, 32), int8] span=model/activation_6/Relu;model/batch_normalization_6/FusedBatchNormV3;model/conv2d_3/BiasAdd/ReadVariableOp/resource;model/conv2d_3/BiasAdd;model/depthwise_conv2d_3/depthwise;model/conv2d_3/Conv2D1:0:0 */;
  %27 = clip(%26, a_min=-128f, a_max=127f) /* ty=Tensor[(1, 24, 24, 32), int8] span=model/activation_6/Relu;model/batch_normalization_6/FusedBatchNormV3;model/conv2d_3/BiasAdd/ReadVariableOp/resource;model/conv2d_3/BiasAdd;model/depthwise_conv2d_3/depthwise;model/conv2d_3/Conv2D1:0:0 */;
  %28 = qnn.conv2d(%27, %v_param_15, -128 /* ty=int32 span=model/activation_7/Relu;model/batch_normalization_7/FusedBatchNormV3;model/depthwise_conv2d_3/depthwise;model/depthwise_conv2d_3/BiasAdd;model/depthwise_conv2d_3/BiasAdd/ReadVariableOp/resource1:0:0 */, 0 /* ty=int32 span=model/activation_7/Relu;model/batch_normalization_7/FusedBatchNormV3;model/depthwise_conv2d_3/depthwise;model/depthwise_conv2d_3/BiasAdd;model/depthwise_conv2d_3/BiasAdd/ReadVariableOp/resource1:0:0 */, 0.0409983f /* ty=float32 span=model/activation_7/Relu;model/batch_normalization_7/FusedBatchNormV3;model/depthwise_conv2d_3/depthwise;model/depthwise_conv2d_3/BiasAdd;model/depthwise_conv2d_3/BiasAdd/ReadVariableOp/resource1:0:0 */, meta[relay.Constant][14] /* ty=Tensor[(32), float32] span=model/activation_7/Relu;model/batch_normalization_7/FusedBatchNormV3;model/depthwise_conv2d_3/depthwise;model/depthwise_conv2d_3/BiasAdd;model/depthwise_conv2d_3/BiasAdd/ReadVariableOp/resource1:0:0 */, strides=[2, 2], padding=[0, 0, 1, 1], groups=32, channels=32, kernel_size=[3, 3], data_layout="NHWC", kernel_layout="HWOI", out_dtype="int32") /* ty=Tensor[(1, 12, 12, 32), int32] span=model/activation_7/Relu;model/batch_normalization_7/FusedBatchNormV3;model/depthwise_conv2d_3/depthwise;model/depthwise_conv2d_3/BiasAdd;model/depthwise_conv2d_3/BiasAdd/ReadVariableOp/resource1:0:0 */;
  %29 = nn.bias_add(%28, %v_param_16, axis=3) /* ty=Tensor[(1, 12, 12, 32), int32] span=model/activation_7/Relu;model/batch_normalization_7/FusedBatchNormV3;model/depthwise_conv2d_3/depthwise;model/depthwise_conv2d_3/BiasAdd;model/depthwise_conv2d_3/BiasAdd/ReadVariableOp/resource1:0:0 */;
  %30 = qnn.requantize(%29, meta[relay.Constant][15] /* ty=Tensor[(32), float32] span=model/activation_7/Relu;model/batch_normalization_7/FusedBatchNormV3;model/depthwise_conv2d_3/depthwise;model/depthwise_conv2d_3/BiasAdd;model/depthwise_conv2d_3/BiasAdd/ReadVariableOp/resource1:0:0 */, 0 /* ty=int32 span=model/activation_7/Relu;model/batch_normalization_7/FusedBatchNormV3;model/depthwise_conv2d_3/depthwise;model/depthwise_conv2d_3/BiasAdd;model/depthwise_conv2d_3/BiasAdd/ReadVariableOp/resource1:0:0 */, 0.028606f /* ty=float32 span=model/activation_7/Relu;model/batch_normalization_7/FusedBatchNormV3;model/depthwise_conv2d_3/depthwise;model/depthwise_conv2d_3/BiasAdd;model/depthwise_conv2d_3/BiasAdd/ReadVariableOp/resource1:0:0 */, -128 /* ty=int32 span=model/activation_7/Relu;model/batch_normalization_7/FusedBatchNormV3;model/depthwise_conv2d_3/depthwise;model/depthwise_conv2d_3/BiasAdd;model/depthwise_conv2d_3/BiasAdd/ReadVariableOp/resource1:0:0 */, axis=3, rounding="UPWARD", compute_dtype="int64", out_dtype="int8") /* ty=Tensor[(1, 12, 12, 32), int8] span=model/activation_7/Relu;model/batch_normalization_7/FusedBatchNormV3;model/depthwise_conv2d_3/depthwise;model/depthwise_conv2d_3/BiasAdd;model/depthwise_conv2d_3/BiasAdd/ReadVariableOp/resource1:0:0 */;
  %31 = clip(%30, a_min=-128f, a_max=127f) /* ty=Tensor[(1, 12, 12, 32), int8] span=model/activation_7/Relu;model/batch_normalization_7/FusedBatchNormV3;model/depthwise_conv2d_3/depthwise;model/depthwise_conv2d_3/BiasAdd;model/depthwise_conv2d_3/BiasAdd/ReadVariableOp/resource1:0:0 */;
  %32 = qnn.conv2d(%31, %v_param_17, -128 /* ty=int32 span=model/activation_8/Relu;model/batch_normalization_8/FusedBatchNormV3;model/conv2d_4/BiasAdd/ReadVariableOp/resource;model/conv2d_4/BiasAdd;model/depthwise_conv2d_5/depthwise;model/conv2d_4/Conv2D1:0:0 */, 0 /* ty=int32 span=model/activation_8/Relu;model/batch_normalization_8/FusedBatchNormV3;model/conv2d_4/BiasAdd/ReadVariableOp/resource;model/conv2d_4/BiasAdd;model/depthwise_conv2d_5/depthwise;model/conv2d_4/Conv2D1:0:0 */, 0.028606f /* ty=float32 span=model/activation_8/Relu;model/batch_normalization_8/FusedBatchNormV3;model/conv2d_4/BiasAdd/ReadVariableOp/resource;model/conv2d_4/BiasAdd;model/depthwise_conv2d_5/depthwise;model/conv2d_4/Conv2D1:0:0 */, meta[relay.Constant][16] /* ty=Tensor[(64), float32] span=model/activation_8/Relu;model/batch_normalization_8/FusedBatchNormV3;model/conv2d_4/BiasAdd/ReadVariableOp/resource;model/conv2d_4/BiasAdd;model/depthwise_conv2d_5/depthwise;model/conv2d_4/Conv2D1:0:0 */, padding=[0, 0, 0, 0], channels=64, kernel_size=[1, 1], data_layout="NHWC", kernel_layout="HWIO", out_dtype="int32") /* ty=Tensor[(1, 12, 12, 64), int32] span=model/activation_8/Relu;model/batch_normalization_8/FusedBatchNormV3;model/conv2d_4/BiasAdd/ReadVariableOp/resource;model/conv2d_4/BiasAdd;model/depthwise_conv2d_5/depthwise;model/conv2d_4/Conv2D1:0:0 */;
  %33 = nn.bias_add(%32, %v_param_18, axis=3) /* ty=Tensor[(1, 12, 12, 64), int32] span=model/activation_8/Relu;model/batch_normalization_8/FusedBatchNormV3;model/conv2d_4/BiasAdd/ReadVariableOp/resource;model/conv2d_4/BiasAdd;model/depthwise_conv2d_5/depthwise;model/conv2d_4/Conv2D1:0:0 */;
  %34 = qnn.requantize(%33, meta[relay.Constant][17] /* ty=Tensor[(64), float32] span=model/activation_8/Relu;model/batch_normalization_8/FusedBatchNormV3;model/conv2d_4/BiasAdd/ReadVariableOp/resource;model/conv2d_4/BiasAdd;model/depthwise_conv2d_5/depthwise;model/conv2d_4/Conv2D1:0:0 */, 0 /* ty=int32 span=model/activation_8/Relu;model/batch_normalization_8/FusedBatchNormV3;model/conv2d_4/BiasAdd/ReadVariableOp/resource;model/conv2d_4/BiasAdd;model/depthwise_conv2d_5/depthwise;model/conv2d_4/Conv2D1:0:0 */, 0.0312282f /* ty=float32 span=model/activation_8/Relu;model/batch_normalization_8/FusedBatchNormV3;model/conv2d_4/BiasAdd/ReadVariableOp/resource;model/conv2d_4/BiasAdd;model/depthwise_conv2d_5/depthwise;model/conv2d_4/Conv2D1:0:0 */, -128 /* ty=int32 span=model/activation_8/Relu;model/batch_normalization_8/FusedBatchNormV3;model/conv2d_4/BiasAdd/ReadVariableOp/resource;model/conv2d_4/BiasAdd;model/depthwise_conv2d_5/depthwise;model/conv2d_4/Conv2D1:0:0 */, axis=3, rounding="UPWARD", compute_dtype="int64", out_dtype="int8") /* ty=Tensor[(1, 12, 12, 64), int8] span=model/activation_8/Relu;model/batch_normalization_8/FusedBatchNormV3;model/conv2d_4/BiasAdd/ReadVariableOp/resource;model/conv2d_4/BiasAdd;model/depthwise_conv2d_5/depthwise;model/conv2d_4/Conv2D1:0:0 */;
  %35 = clip(%34, a_min=-128f, a_max=127f) /* ty=Tensor[(1, 12, 12, 64), int8] span=model/activation_8/Relu;model/batch_normalization_8/FusedBatchNormV3;model/conv2d_4/BiasAdd/ReadVariableOp/resource;model/conv2d_4/BiasAdd;model/depthwise_conv2d_5/depthwise;model/conv2d_4/Conv2D1:0:0 */;
  %36 = qnn.conv2d(%35, %v_param_19, -128 /* ty=int32 span=model/activation_9/Relu;model/batch_normalization_9/FusedBatchNormV3;model/depthwise_conv2d_4/depthwise;model/depthwise_conv2d_4/BiasAdd;model/depthwise_conv2d_5/depthwise;model/depthwise_conv2d_4/BiasAdd/ReadVariableOp/resource1:0:0 */, 0 /* ty=int32 span=model/activation_9/Relu;model/batch_normalization_9/FusedBatchNormV3;model/depthwise_conv2d_4/depthwise;model/depthwise_conv2d_4/BiasAdd;model/depthwise_conv2d_5/depthwise;model/depthwise_conv2d_4/BiasAdd/ReadVariableOp/resource1:0:0 */, 0.0312282f /* ty=float32 span=model/activation_9/Relu;model/batch_normalization_9/FusedBatchNormV3;model/depthwise_conv2d_4/depthwise;model/depthwise_conv2d_4/BiasAdd;model/depthwise_conv2d_5/depthwise;model/depthwise_conv2d_4/BiasAdd/ReadVariableOp/resource1:0:0 */, meta[relay.Constant][18] /* ty=Tensor[(64), float32] span=model/activation_9/Relu;model/batch_normalization_9/FusedBatchNormV3;model/depthwise_conv2d_4/depthwise;model/depthwise_conv2d_4/BiasAdd;model/depthwise_conv2d_5/depthwise;model/depthwise_conv2d_4/BiasAdd/ReadVariableOp/resource1:0:0 */, padding=[1, 1, 1, 1], groups=64, channels=64, kernel_size=[3, 3], data_layout="NHWC", kernel_layout="HWOI", out_dtype="int32") /* ty=Tensor[(1, 12, 12, 64), int32] span=model/activation_9/Relu;model/batch_normalization_9/FusedBatchNormV3;model/depthwise_conv2d_4/depthwise;model/depthwise_conv2d_4/BiasAdd;model/depthwise_conv2d_5/depthwise;model/depthwise_conv2d_4/BiasAdd/ReadVariableOp/resource1:0:0 */;
  %37 = nn.bias_add(%36, %v_param_20, axis=3) /* ty=Tensor[(1, 12, 12, 64), int32] span=model/activation_9/Relu;model/batch_normalization_9/FusedBatchNormV3;model/depthwise_conv2d_4/depthwise;model/depthwise_conv2d_4/BiasAdd;model/depthwise_conv2d_5/depthwise;model/depthwise_conv2d_4/BiasAdd/ReadVariableOp/resource1:0:0 */;
  %38 = qnn.requantize(%37, meta[relay.Constant][19] /* ty=Tensor[(64), float32] span=model/activation_9/Relu;model/batch_normalization_9/FusedBatchNormV3;model/depthwise_conv2d_4/depthwise;model/depthwise_conv2d_4/BiasAdd;model/depthwise_conv2d_5/depthwise;model/depthwise_conv2d_4/BiasAdd/ReadVariableOp/resource1:0:0 */, 0 /* ty=int32 span=model/activation_9/Relu;model/batch_normalization_9/FusedBatchNormV3;model/depthwise_conv2d_4/depthwise;model/depthwise_conv2d_4/BiasAdd;model/depthwise_conv2d_5/depthwise;model/depthwise_conv2d_4/BiasAdd/ReadVariableOp/resource1:0:0 */, 0.0315622f /* ty=float32 span=model/activation_9/Relu;model/batch_normalization_9/FusedBatchNormV3;model/depthwise_conv2d_4/depthwise;model/depthwise_conv2d_4/BiasAdd;model/depthwise_conv2d_5/depthwise;model/depthwise_conv2d_4/BiasAdd/ReadVariableOp/resource1:0:0 */, -128 /* ty=int32 span=model/activation_9/Relu;model/batch_normalization_9/FusedBatchNormV3;model/depthwise_conv2d_4/depthwise;model/depthwise_conv2d_4/BiasAdd;model/depthwise_conv2d_5/depthwise;model/depthwise_conv2d_4/BiasAdd/ReadVariableOp/resource1:0:0 */, axis=3, rounding="UPWARD", compute_dtype="int64", out_dtype="int8") /* ty=Tensor[(1, 12, 12, 64), int8] span=model/activation_9/Relu;model/batch_normalization_9/FusedBatchNormV3;model/depthwise_conv2d_4/depthwise;model/depthwise_conv2d_4/BiasAdd;model/depthwise_conv2d_5/depthwise;model/depthwise_conv2d_4/BiasAdd/ReadVariableOp/resource1:0:0 */;
  %39 = clip(%38, a_min=-128f, a_max=127f) /* ty=Tensor[(1, 12, 12, 64), int8] span=model/activation_9/Relu;model/batch_normalization_9/FusedBatchNormV3;model/depthwise_conv2d_4/depthwise;model/depthwise_conv2d_4/BiasAdd;model/depthwise_conv2d_5/depthwise;model/depthwise_conv2d_4/BiasAdd/ReadVariableOp/resource1:0:0 */;
  %40 = qnn.conv2d(%39, %v_param_21, -128 /* ty=int32 span=model/activation_10/Relu;model/batch_normalization_10/FusedBatchNormV3;model/conv2d_5/BiasAdd/ReadVariableOp/resource;model/conv2d_5/BiasAdd;model/depthwise_conv2d_5/depthwise;model/conv2d_5/Conv2D1:0:0 */, 0 /* ty=int32 span=model/activation_10/Relu;model/batch_normalization_10/FusedBatchNormV3;model/conv2d_5/BiasAdd/ReadVariableOp/resource;model/conv2d_5/BiasAdd;model/depthwise_conv2d_5/depthwise;model/conv2d_5/Conv2D1:0:0 */, 0.0315622f /* ty=float32 span=model/activation_10/Relu;model/batch_normalization_10/FusedBatchNormV3;model/conv2d_5/BiasAdd/ReadVariableOp/resource;model/conv2d_5/BiasAdd;model/depthwise_conv2d_5/depthwise;model/conv2d_5/Conv2D1:0:0 */, meta[relay.Constant][20] /* ty=Tensor[(64), float32] span=model/activation_10/Relu;model/batch_normalization_10/FusedBatchNormV3;model/conv2d_5/BiasAdd/ReadVariableOp/resource;model/conv2d_5/BiasAdd;model/depthwise_conv2d_5/depthwise;model/conv2d_5/Conv2D1:0:0 */, padding=[0, 0, 0, 0], channels=64, kernel_size=[1, 1], data_layout="NHWC", kernel_layout="HWIO", out_dtype="int32") /* ty=Tensor[(1, 12, 12, 64), int32] span=model/activation_10/Relu;model/batch_normalization_10/FusedBatchNormV3;model/conv2d_5/BiasAdd/ReadVariableOp/resource;model/conv2d_5/BiasAdd;model/depthwise_conv2d_5/depthwise;model/conv2d_5/Conv2D1:0:0 */;
  %41 = nn.bias_add(%40, %v_param_22, axis=3) /* ty=Tensor[(1, 12, 12, 64), int32] span=model/activation_10/Relu;model/batch_normalization_10/FusedBatchNormV3;model/conv2d_5/BiasAdd/ReadVariableOp/resource;model/conv2d_5/BiasAdd;model/depthwise_conv2d_5/depthwise;model/conv2d_5/Conv2D1:0:0 */;
  %42 = qnn.requantize(%41, meta[relay.Constant][21] /* ty=Tensor[(64), float32] span=model/activation_10/Relu;model/batch_normalization_10/FusedBatchNormV3;model/conv2d_5/BiasAdd/ReadVariableOp/resource;model/conv2d_5/BiasAdd;model/depthwise_conv2d_5/depthwise;model/conv2d_5/Conv2D1:0:0 */, 0 /* ty=int32 span=model/activation_10/Relu;model/batch_normalization_10/FusedBatchNormV3;model/conv2d_5/BiasAdd/ReadVariableOp/resource;model/conv2d_5/BiasAdd;model/depthwise_conv2d_5/depthwise;model/conv2d_5/Conv2D1:0:0 */, 0.0296601f /* ty=float32 span=model/activation_10/Relu;model/batch_normalization_10/FusedBatchNormV3;model/conv2d_5/BiasAdd/ReadVariableOp/resource;model/conv2d_5/BiasAdd;model/depthwise_conv2d_5/depthwise;model/conv2d_5/Conv2D1:0:0 */, -128 /* ty=int32 span=model/activation_10/Relu;model/batch_normalization_10/FusedBatchNormV3;model/conv2d_5/BiasAdd/ReadVariableOp/resource;model/conv2d_5/BiasAdd;model/depthwise_conv2d_5/depthwise;model/conv2d_5/Conv2D1:0:0 */, axis=3, rounding="UPWARD", compute_dtype="int64", out_dtype="int8") /* ty=Tensor[(1, 12, 12, 64), int8] span=model/activation_10/Relu;model/batch_normalization_10/FusedBatchNormV3;model/conv2d_5/BiasAdd/ReadVariableOp/resource;model/conv2d_5/BiasAdd;model/depthwise_conv2d_5/depthwise;model/conv2d_5/Conv2D1:0:0 */;
  %43 = clip(%42, a_min=-128f, a_max=127f) /* ty=Tensor[(1, 12, 12, 64), int8] span=model/activation_10/Relu;model/batch_normalization_10/FusedBatchNormV3;model/conv2d_5/BiasAdd/ReadVariableOp/resource;model/conv2d_5/BiasAdd;model/depthwise_conv2d_5/depthwise;model/conv2d_5/Conv2D1:0:0 */;
  %44 = qnn.conv2d(%43, %v_param_23, -128 /* ty=int32 span=model/activation_11/Relu;model/batch_normalization_11/FusedBatchNormV3;model/depthwise_conv2d_5/depthwise;model/depthwise_conv2d_5/BiasAdd;model/depthwise_conv2d_5/BiasAdd/ReadVariableOp/resource1:0:0 */, 0 /* ty=int32 span=model/activation_11/Relu;model/batch_normalization_11/FusedBatchNormV3;model/depthwise_conv2d_5/depthwise;model/depthwise_conv2d_5/BiasAdd;model/depthwise_conv2d_5/BiasAdd/ReadVariableOp/resource1:0:0 */, 0.0296601f /* ty=float32 span=model/activation_11/Relu;model/batch_normalization_11/FusedBatchNormV3;model/depthwise_conv2d_5/depthwise;model/depthwise_conv2d_5/BiasAdd;model/depthwise_conv2d_5/BiasAdd/ReadVariableOp/resource1:0:0 */, meta[relay.Constant][22] /* ty=Tensor[(64), float32] span=model/activation_11/Relu;model/batch_normalization_11/FusedBatchNormV3;model/depthwise_conv2d_5/depthwise;model/depthwise_conv2d_5/BiasAdd;model/depthwise_conv2d_5/BiasAdd/ReadVariableOp/resource1:0:0 */, strides=[2, 2], padding=[0, 0, 1, 1], groups=64, channels=64, kernel_size=[3, 3], data_layout="NHWC", kernel_layout="HWOI", out_dtype="int32") /* ty=Tensor[(1, 6, 6, 64), int32] span=model/activation_11/Relu;model/batch_normalization_11/FusedBatchNormV3;model/depthwise_conv2d_5/depthwise;model/depthwise_conv2d_5/BiasAdd;model/depthwise_conv2d_5/BiasAdd/ReadVariableOp/resource1:0:0 */;
  %45 = nn.bias_add(%44, %v_param_24, axis=3) /* ty=Tensor[(1, 6, 6, 64), int32] span=model/activation_11/Relu;model/batch_normalization_11/FusedBatchNormV3;model/depthwise_conv2d_5/depthwise;model/depthwise_conv2d_5/BiasAdd;model/depthwise_conv2d_5/BiasAdd/ReadVariableOp/resource1:0:0 */;
  %46 = qnn.requantize(%45, meta[relay.Constant][23] /* ty=Tensor[(64), float32] span=model/activation_11/Relu;model/batch_normalization_11/FusedBatchNormV3;model/depthwise_conv2d_5/depthwise;model/depthwise_conv2d_5/BiasAdd;model/depthwise_conv2d_5/BiasAdd/ReadVariableOp/resource1:0:0 */, 0 /* ty=int32 span=model/activation_11/Relu;model/batch_normalization_11/FusedBatchNormV3;model/depthwise_conv2d_5/depthwise;model/depthwise_conv2d_5/BiasAdd;model/depthwise_conv2d_5/BiasAdd/ReadVariableOp/resource1:0:0 */, 0.0324266f /* ty=float32 span=model/activation_11/Relu;model/batch_normalization_11/FusedBatchNormV3;model/depthwise_conv2d_5/depthwise;model/depthwise_conv2d_5/BiasAdd;model/depthwise_conv2d_5/BiasAdd/ReadVariableOp/resource1:0:0 */, -128 /* ty=int32 span=model/activation_11/Relu;model/batch_normalization_11/FusedBatchNormV3;model/depthwise_conv2d_5/depthwise;model/depthwise_conv2d_5/BiasAdd;model/depthwise_conv2d_5/BiasAdd/ReadVariableOp/resource1:0:0 */, axis=3, rounding="UPWARD", compute_dtype="int64", out_dtype="int8") /* ty=Tensor[(1, 6, 6, 64), int8] span=model/activation_11/Relu;model/batch_normalization_11/FusedBatchNormV3;model/depthwise_conv2d_5/depthwise;model/depthwise_conv2d_5/BiasAdd;model/depthwise_conv2d_5/BiasAdd/ReadVariableOp/resource1:0:0 */;
  %47 = clip(%46, a_min=-128f, a_max=127f) /* ty=Tensor[(1, 6, 6, 64), int8] span=model/activation_11/Relu;model/batch_normalization_11/FusedBatchNormV3;model/depthwise_conv2d_5/depthwise;model/depthwise_conv2d_5/BiasAdd;model/depthwise_conv2d_5/BiasAdd/ReadVariableOp/resource1:0:0 */;
  %48 = qnn.conv2d(%47, %v_param_25, -128 /* ty=int32 span=model/activation_12/Relu;model/batch_normalization_12/FusedBatchNormV3;model/conv2d_6/BiasAdd/ReadVariableOp/resource;model/conv2d_6/BiasAdd;model/depthwise_conv2d_11/depthwise;model/conv2d_6/Conv2D1:0:0 */, 0 /* ty=int32 span=model/activation_12/Relu;model/batch_normalization_12/FusedBatchNormV3;model/conv2d_6/BiasAdd/ReadVariableOp/resource;model/conv2d_6/BiasAdd;model/depthwise_conv2d_11/depthwise;model/conv2d_6/Conv2D1:0:0 */, 0.0324266f /* ty=float32 span=model/activation_12/Relu;model/batch_normalization_12/FusedBatchNormV3;model/conv2d_6/BiasAdd/ReadVariableOp/resource;model/conv2d_6/BiasAdd;model/depthwise_conv2d_11/depthwise;model/conv2d_6/Conv2D1:0:0 */, meta[relay.Constant][24] /* ty=Tensor[(128), float32] span=model/activation_12/Relu;model/batch_normalization_12/FusedBatchNormV3;model/conv2d_6/BiasAdd/ReadVariableOp/resource;model/conv2d_6/BiasAdd;model/depthwise_conv2d_11/depthwise;model/conv2d_6/Conv2D1:0:0 */, padding=[0, 0, 0, 0], channels=128, kernel_size=[1, 1], data_layout="NHWC", kernel_layout="HWIO", out_dtype="int32") /* ty=Tensor[(1, 6, 6, 128), int32] span=model/activation_12/Relu;model/batch_normalization_12/FusedBatchNormV3;model/conv2d_6/BiasAdd/ReadVariableOp/resource;model/conv2d_6/BiasAdd;model/depthwise_conv2d_11/depthwise;model/conv2d_6/Conv2D1:0:0 */;
  %49 = nn.bias_add(%48, %v_param_26, axis=3) /* ty=Tensor[(1, 6, 6, 128), int32] span=model/activation_12/Relu;model/batch_normalization_12/FusedBatchNormV3;model/conv2d_6/BiasAdd/ReadVariableOp/resource;model/conv2d_6/BiasAdd;model/depthwise_conv2d_11/depthwise;model/conv2d_6/Conv2D1:0:0 */;
  %50 = qnn.requantize(%49, meta[relay.Constant][25] /* ty=Tensor[(128), float32] span=model/activation_12/Relu;model/batch_normalization_12/FusedBatchNormV3;model/conv2d_6/BiasAdd/ReadVariableOp/resource;model/conv2d_6/BiasAdd;model/depthwise_conv2d_11/depthwise;model/conv2d_6/Conv2D1:0:0 */, 0 /* ty=int32 span=model/activation_12/Relu;model/batch_normalization_12/FusedBatchNormV3;model/conv2d_6/BiasAdd/ReadVariableOp/resource;model/conv2d_6/BiasAdd;model/depthwise_conv2d_11/depthwise;model/conv2d_6/Conv2D1:0:0 */, 0.030614f /* ty=float32 span=model/activation_12/Relu;model/batch_normalization_12/FusedBatchNormV3;model/conv2d_6/BiasAdd/ReadVariableOp/resource;model/conv2d_6/BiasAdd;model/depthwise_conv2d_11/depthwise;model/conv2d_6/Conv2D1:0:0 */, -128 /* ty=int32 span=model/activation_12/Relu;model/batch_normalization_12/FusedBatchNormV3;model/conv2d_6/BiasAdd/ReadVariableOp/resource;model/conv2d_6/BiasAdd;model/depthwise_conv2d_11/depthwise;model/conv2d_6/Conv2D1:0:0 */, axis=3, rounding="UPWARD", compute_dtype="int64", out_dtype="int8") /* ty=Tensor[(1, 6, 6, 128), int8] span=model/activation_12/Relu;model/batch_normalization_12/FusedBatchNormV3;model/conv2d_6/BiasAdd/ReadVariableOp/resource;model/conv2d_6/BiasAdd;model/depthwise_conv2d_11/depthwise;model/conv2d_6/Conv2D1:0:0 */;
  %51 = clip(%50, a_min=-128f, a_max=127f) /* ty=Tensor[(1, 6, 6, 128), int8] span=model/activation_12/Relu;model/batch_normalization_12/FusedBatchNormV3;model/conv2d_6/BiasAdd/ReadVariableOp/resource;model/conv2d_6/BiasAdd;model/depthwise_conv2d_11/depthwise;model/conv2d_6/Conv2D1:0:0 */;
  %52 = qnn.conv2d(%51, %v_param_27, -128 /* ty=int32 span=model/activation_13/Relu;model/batch_normalization_13/FusedBatchNormV3;model/depthwise_conv2d_6/depthwise;model/depthwise_conv2d_6/BiasAdd;model/depthwise_conv2d_11/depthwise;model/depthwise_conv2d_6/BiasAdd/ReadVariableOp/resource1:0:0 */, 0 /* ty=int32 span=model/activation_13/Relu;model/batch_normalization_13/FusedBatchNormV3;model/depthwise_conv2d_6/depthwise;model/depthwise_conv2d_6/BiasAdd;model/depthwise_conv2d_11/depthwise;model/depthwise_conv2d_6/BiasAdd/ReadVariableOp/resource1:0:0 */, 0.030614f /* ty=float32 span=model/activation_13/Relu;model/batch_normalization_13/FusedBatchNormV3;model/depthwise_conv2d_6/depthwise;model/depthwise_conv2d_6/BiasAdd;model/depthwise_conv2d_11/depthwise;model/depthwise_conv2d_6/BiasAdd/ReadVariableOp/resource1:0:0 */, meta[relay.Constant][26] /* ty=Tensor[(128), float32] span=model/activation_13/Relu;model/batch_normalization_13/FusedBatchNormV3;model/depthwise_conv2d_6/depthwise;model/depthwise_conv2d_6/BiasAdd;model/depthwise_conv2d_11/depthwise;model/depthwise_conv2d_6/BiasAdd/ReadVariableOp/resource1:0:0 */, padding=[1, 1, 1, 1], groups=128, channels=128, kernel_size=[3, 3], data_layout="NHWC", kernel_layout="HWOI", out_dtype="int32") /* ty=Tensor[(1, 6, 6, 128), int32] span=model/activation_13/Relu;model/batch_normalization_13/FusedBatchNormV3;model/depthwise_conv2d_6/depthwise;model/depthwise_conv2d_6/BiasAdd;model/depthwise_conv2d_11/depthwise;model/depthwise_conv2d_6/BiasAdd/ReadVariableOp/resource1:0:0 */;
  %53 = nn.bias_add(%52, %v_param_28, axis=3) /* ty=Tensor[(1, 6, 6, 128), int32] span=model/activation_13/Relu;model/batch_normalization_13/FusedBatchNormV3;model/depthwise_conv2d_6/depthwise;model/depthwise_conv2d_6/BiasAdd;model/depthwise_conv2d_11/depthwise;model/depthwise_conv2d_6/BiasAdd/ReadVariableOp/resource1:0:0 */;
  %54 = qnn.requantize(%53, meta[relay.Constant][27] /* ty=Tensor[(128), float32] span=model/activation_13/Relu;model/batch_normalization_13/FusedBatchNormV3;model/depthwise_conv2d_6/depthwise;model/depthwise_conv2d_6/BiasAdd;model/depthwise_conv2d_11/depthwise;model/depthwise_conv2d_6/BiasAdd/ReadVariableOp/resource1:0:0 */, 0 /* ty=int32 span=model/activation_13/Relu;model/batch_normalization_13/FusedBatchNormV3;model/depthwise_conv2d_6/depthwise;model/depthwise_conv2d_6/BiasAdd;model/depthwise_conv2d_11/depthwise;model/depthwise_conv2d_6/BiasAdd/ReadVariableOp/resource1:0:0 */, 0.0296805f /* ty=float32 span=model/activation_13/Relu;model/batch_normalization_13/FusedBatchNormV3;model/depthwise_conv2d_6/depthwise;model/depthwise_conv2d_6/BiasAdd;model/depthwise_conv2d_11/depthwise;model/depthwise_conv2d_6/BiasAdd/ReadVariableOp/resource1:0:0 */, -128 /* ty=int32 span=model/activation_13/Relu;model/batch_normalization_13/FusedBatchNormV3;model/depthwise_conv2d_6/depthwise;model/depthwise_conv2d_6/BiasAdd;model/depthwise_conv2d_11/depthwise;model/depthwise_conv2d_6/BiasAdd/ReadVariableOp/resource1:0:0 */, axis=3, rounding="UPWARD", compute_dtype="int64", out_dtype="int8") /* ty=Tensor[(1, 6, 6, 128), int8] span=model/activation_13/Relu;model/batch_normalization_13/FusedBatchNormV3;model/depthwise_conv2d_6/depthwise;model/depthwise_conv2d_6/BiasAdd;model/depthwise_conv2d_11/depthwise;model/depthwise_conv2d_6/BiasAdd/ReadVariableOp/resource1:0:0 */;
  %55 = clip(%54, a_min=-128f, a_max=127f) /* ty=Tensor[(1, 6, 6, 128), int8] span=model/activation_13/Relu;model/batch_normalization_13/FusedBatchNormV3;model/depthwise_conv2d_6/depthwise;model/depthwise_conv2d_6/BiasAdd;model/depthwise_conv2d_11/depthwise;model/depthwise_conv2d_6/BiasAdd/ReadVariableOp/resource1:0:0 */;
  %56 = qnn.conv2d(%55, %v_param_29, -128 /* ty=int32 span=model/activation_14/Relu;model/batch_normalization_14/FusedBatchNormV3;model/conv2d_7/BiasAdd/ReadVariableOp/resource;model/conv2d_7/BiasAdd;model/depthwise_conv2d_11/depthwise;model/conv2d_7/Conv2D1:0:0 */, 0 /* ty=int32 span=model/activation_14/Relu;model/batch_normalization_14/FusedBatchNormV3;model/conv2d_7/BiasAdd/ReadVariableOp/resource;model/conv2d_7/BiasAdd;model/depthwise_conv2d_11/depthwise;model/conv2d_7/Conv2D1:0:0 */, 0.0296805f /* ty=float32 span=model/activation_14/Relu;model/batch_normalization_14/FusedBatchNormV3;model/conv2d_7/BiasAdd/ReadVariableOp/resource;model/conv2d_7/BiasAdd;model/depthwise_conv2d_11/depthwise;model/conv2d_7/Conv2D1:0:0 */, meta[relay.Constant][28] /* ty=Tensor[(128), float32] span=model/activation_14/Relu;model/batch_normalization_14/FusedBatchNormV3;model/conv2d_7/BiasAdd/ReadVariableOp/resource;model/conv2d_7/BiasAdd;model/depthwise_conv2d_11/depthwise;model/conv2d_7/Conv2D1:0:0 */, padding=[0, 0, 0, 0], channels=128, kernel_size=[1, 1], data_layout="NHWC", kernel_layout="HWIO", out_dtype="int32") /* ty=Tensor[(1, 6, 6, 128), int32] span=model/activation_14/Relu;model/batch_normalization_14/FusedBatchNormV3;model/conv2d_7/BiasAdd/ReadVariableOp/resource;model/conv2d_7/BiasAdd;model/depthwise_conv2d_11/depthwise;model/conv2d_7/Conv2D1:0:0 */;
  %57 = nn.bias_add(%56, %v_param_30, axis=3) /* ty=Tensor[(1, 6, 6, 128), int32] span=model/activation_14/Relu;model/batch_normalization_14/FusedBatchNormV3;model/conv2d_7/BiasAdd/ReadVariableOp/resource;model/conv2d_7/BiasAdd;model/depthwise_conv2d_11/depthwise;model/conv2d_7/Conv2D1:0:0 */;
  %58 = qnn.requantize(%57, meta[relay.Constant][29] /* ty=Tensor[(128), float32] span=model/activation_14/Relu;model/batch_normalization_14/FusedBatchNormV3;model/conv2d_7/BiasAdd/ReadVariableOp/resource;model/conv2d_7/BiasAdd;model/depthwise_conv2d_11/depthwise;model/conv2d_7/Conv2D1:0:0 */, 0 /* ty=int32 span=model/activation_14/Relu;model/batch_normalization_14/FusedBatchNormV3;model/conv2d_7/BiasAdd/ReadVariableOp/resource;model/conv2d_7/BiasAdd;model/depthwise_conv2d_11/depthwise;model/conv2d_7/Conv2D1:0:0 */, 0.0238827f /* ty=float32 span=model/activation_14/Relu;model/batch_normalization_14/FusedBatchNormV3;model/conv2d_7/BiasAdd/ReadVariableOp/resource;model/conv2d_7/BiasAdd;model/depthwise_conv2d_11/depthwise;model/conv2d_7/Conv2D1:0:0 */, -128 /* ty=int32 span=model/activation_14/Relu;model/batch_normalization_14/FusedBatchNormV3;model/conv2d_7/BiasAdd/ReadVariableOp/resource;model/conv2d_7/BiasAdd;model/depthwise_conv2d_11/depthwise;model/conv2d_7/Conv2D1:0:0 */, axis=3, rounding="UPWARD", compute_dtype="int64", out_dtype="int8") /* ty=Tensor[(1, 6, 6, 128), int8] span=model/activation_14/Relu;model/batch_normalization_14/FusedBatchNormV3;model/conv2d_7/BiasAdd/ReadVariableOp/resource;model/conv2d_7/BiasAdd;model/depthwise_conv2d_11/depthwise;model/conv2d_7/Conv2D1:0:0 */;
  %59 = clip(%58, a_min=-128f, a_max=127f) /* ty=Tensor[(1, 6, 6, 128), int8] span=model/activation_14/Relu;model/batch_normalization_14/FusedBatchNormV3;model/conv2d_7/BiasAdd/ReadVariableOp/resource;model/conv2d_7/BiasAdd;model/depthwise_conv2d_11/depthwise;model/conv2d_7/Conv2D1:0:0 */;
  %60 = qnn.conv2d(%59, %v_param_31, -128 /* ty=int32 span=model/activation_15/Relu;model/batch_normalization_15/FusedBatchNormV3;model/depthwise_conv2d_7/depthwise;model/depthwise_conv2d_7/BiasAdd;model/depthwise_conv2d_11/depthwise;model/depthwise_conv2d_7/BiasAdd/ReadVariableOp/resource1:0:0 */, 0 /* ty=int32 span=model/activation_15/Relu;model/batch_normalization_15/FusedBatchNormV3;model/depthwise_conv2d_7/depthwise;model/depthwise_conv2d_7/BiasAdd;model/depthwise_conv2d_11/depthwise;model/depthwise_conv2d_7/BiasAdd/ReadVariableOp/resource1:0:0 */, 0.0238827f /* ty=float32 span=model/activation_15/Relu;model/batch_normalization_15/FusedBatchNormV3;model/depthwise_conv2d_7/depthwise;model/depthwise_conv2d_7/BiasAdd;model/depthwise_conv2d_11/depthwise;model/depthwise_conv2d_7/BiasAdd/ReadVariableOp/resource1:0:0 */, meta[relay.Constant][30] /* ty=Tensor[(128), float32] span=model/activation_15/Relu;model/batch_normalization_15/FusedBatchNormV3;model/depthwise_conv2d_7/depthwise;model/depthwise_conv2d_7/BiasAdd;model/depthwise_conv2d_11/depthwise;model/depthwise_conv2d_7/BiasAdd/ReadVariableOp/resource1:0:0 */, padding=[1, 1, 1, 1], groups=128, channels=128, kernel_size=[3, 3], data_layout="NHWC", kernel_layout="HWOI", out_dtype="int32") /* ty=Tensor[(1, 6, 6, 128), int32] span=model/activation_15/Relu;model/batch_normalization_15/FusedBatchNormV3;model/depthwise_conv2d_7/depthwise;model/depthwise_conv2d_7/BiasAdd;model/depthwise_conv2d_11/depthwise;model/depthwise_conv2d_7/BiasAdd/ReadVariableOp/resource1:0:0 */;
  %61 = nn.bias_add(%60, %v_param_32, axis=3) /* ty=Tensor[(1, 6, 6, 128), int32] span=model/activation_15/Relu;model/batch_normalization_15/FusedBatchNormV3;model/depthwise_conv2d_7/depthwise;model/depthwise_conv2d_7/BiasAdd;model/depthwise_conv2d_11/depthwise;model/depthwise_conv2d_7/BiasAdd/ReadVariableOp/resource1:0:0 */;
  %62 = qnn.requantize(%61, meta[relay.Constant][31] /* ty=Tensor[(128), float32] span=model/activation_15/Relu;model/batch_normalization_15/FusedBatchNormV3;model/depthwise_conv2d_7/depthwise;model/depthwise_conv2d_7/BiasAdd;model/depthwise_conv2d_11/depthwise;model/depthwise_conv2d_7/BiasAdd/ReadVariableOp/resource1:0:0 */, 0 /* ty=int32 span=model/activation_15/Relu;model/batch_normalization_15/FusedBatchNormV3;model/depthwise_conv2d_7/depthwise;model/depthwise_conv2d_7/BiasAdd;model/depthwise_conv2d_11/depthwise;model/depthwise_conv2d_7/BiasAdd/ReadVariableOp/resource1:0:0 */, 0.0365413f /* ty=float32 span=model/activation_15/Relu;model/batch_normalization_15/FusedBatchNormV3;model/depthwise_conv2d_7/depthwise;model/depthwise_conv2d_7/BiasAdd;model/depthwise_conv2d_11/depthwise;model/depthwise_conv2d_7/BiasAdd/ReadVariableOp/resource1:0:0 */, -128 /* ty=int32 span=model/activation_15/Relu;model/batch_normalization_15/FusedBatchNormV3;model/depthwise_conv2d_7/depthwise;model/depthwise_conv2d_7/BiasAdd;model/depthwise_conv2d_11/depthwise;model/depthwise_conv2d_7/BiasAdd/ReadVariableOp/resource1:0:0 */, axis=3, rounding="UPWARD", compute_dtype="int64", out_dtype="int8") /* ty=Tensor[(1, 6, 6, 128), int8] span=model/activation_15/Relu;model/batch_normalization_15/FusedBatchNormV3;model/depthwise_conv2d_7/depthwise;model/depthwise_conv2d_7/BiasAdd;model/depthwise_conv2d_11/depthwise;model/depthwise_conv2d_7/BiasAdd/ReadVariableOp/resource1:0:0 */;
  %63 = clip(%62, a_min=-128f, a_max=127f) /* ty=Tensor[(1, 6, 6, 128), int8] span=model/activation_15/Relu;model/batch_normalization_15/FusedBatchNormV3;model/depthwise_conv2d_7/depthwise;model/depthwise_conv2d_7/BiasAdd;model/depthwise_conv2d_11/depthwise;model/depthwise_conv2d_7/BiasAdd/ReadVariableOp/resource1:0:0 */;
  %64 = qnn.conv2d(%63, %v_param_33, -128 /* ty=int32 span=model/activation_16/Relu;model/batch_normalization_16/FusedBatchNormV3;model/conv2d_8/BiasAdd/ReadVariableOp/resource;model/conv2d_8/BiasAdd;model/depthwise_conv2d_11/depthwise;model/conv2d_8/Conv2D1:0:0 */, 0 /* ty=int32 span=model/activation_16/Relu;model/batch_normalization_16/FusedBatchNormV3;model/conv2d_8/BiasAdd/ReadVariableOp/resource;model/conv2d_8/BiasAdd;model/depthwise_conv2d_11/depthwise;model/conv2d_8/Conv2D1:0:0 */, 0.0365413f /* ty=float32 span=model/activation_16/Relu;model/batch_normalization_16/FusedBatchNormV3;model/conv2d_8/BiasAdd/ReadVariableOp/resource;model/conv2d_8/BiasAdd;model/depthwise_conv2d_11/depthwise;model/conv2d_8/Conv2D1:0:0 */, meta[relay.Constant][32] /* ty=Tensor[(128), float32] span=model/activation_16/Relu;model/batch_normalization_16/FusedBatchNormV3;model/conv2d_8/BiasAdd/ReadVariableOp/resource;model/conv2d_8/BiasAdd;model/depthwise_conv2d_11/depthwise;model/conv2d_8/Conv2D1:0:0 */, padding=[0, 0, 0, 0], channels=128, kernel_size=[1, 1], data_layout="NHWC", kernel_layout="HWIO", out_dtype="int32") /* ty=Tensor[(1, 6, 6, 128), int32] span=model/activation_16/Relu;model/batch_normalization_16/FusedBatchNormV3;model/conv2d_8/BiasAdd/ReadVariableOp/resource;model/conv2d_8/BiasAdd;model/depthwise_conv2d_11/depthwise;model/conv2d_8/Conv2D1:0:0 */;
  %65 = nn.bias_add(%64, %v_param_34, axis=3) /* ty=Tensor[(1, 6, 6, 128), int32] span=model/activation_16/Relu;model/batch_normalization_16/FusedBatchNormV3;model/conv2d_8/BiasAdd/ReadVariableOp/resource;model/conv2d_8/BiasAdd;model/depthwise_conv2d_11/depthwise;model/conv2d_8/Conv2D1:0:0 */;
  %66 = qnn.requantize(%65, meta[relay.Constant][33] /* ty=Tensor[(128), float32] span=model/activation_16/Relu;model/batch_normalization_16/FusedBatchNormV3;model/conv2d_8/BiasAdd/ReadVariableOp/resource;model/conv2d_8/BiasAdd;model/depthwise_conv2d_11/depthwise;model/conv2d_8/Conv2D1:0:0 */, 0 /* ty=int32 span=model/activation_16/Relu;model/batch_normalization_16/FusedBatchNormV3;model/conv2d_8/BiasAdd/ReadVariableOp/resource;model/conv2d_8/BiasAdd;model/depthwise_conv2d_11/depthwise;model/conv2d_8/Conv2D1:0:0 */, 0.0365f /* ty=float32 span=model/activation_16/Relu;model/batch_normalization_16/FusedBatchNormV3;model/conv2d_8/BiasAdd/ReadVariableOp/resource;model/conv2d_8/BiasAdd;model/depthwise_conv2d_11/depthwise;model/conv2d_8/Conv2D1:0:0 */, -128 /* ty=int32 span=model/activation_16/Relu;model/batch_normalization_16/FusedBatchNormV3;model/conv2d_8/BiasAdd/ReadVariableOp/resource;model/conv2d_8/BiasAdd;model/depthwise_conv2d_11/depthwise;model/conv2d_8/Conv2D1:0:0 */, axis=3, rounding="UPWARD", compute_dtype="int64", out_dtype="int8") /* ty=Tensor[(1, 6, 6, 128), int8] span=model/activation_16/Relu;model/batch_normalization_16/FusedBatchNormV3;model/conv2d_8/BiasAdd/ReadVariableOp/resource;model/conv2d_8/BiasAdd;model/depthwise_conv2d_11/depthwise;model/conv2d_8/Conv2D1:0:0 */;
  %67 = clip(%66, a_min=-128f, a_max=127f) /* ty=Tensor[(1, 6, 6, 128), int8] span=model/activation_16/Relu;model/batch_normalization_16/FusedBatchNormV3;model/conv2d_8/BiasAdd/ReadVariableOp/resource;model/conv2d_8/BiasAdd;model/depthwise_conv2d_11/depthwise;model/conv2d_8/Conv2D1:0:0 */;
  %68 = qnn.conv2d(%67, %v_param_35, -128 /* ty=int32 span=model/activation_17/Relu;model/batch_normalization_17/FusedBatchNormV3;model/depthwise_conv2d_8/depthwise;model/depthwise_conv2d_8/BiasAdd;model/depthwise_conv2d_11/depthwise;model/depthwise_conv2d_8/BiasAdd/ReadVariableOp/resource1:0:0 */, 0 /* ty=int32 span=model/activation_17/Relu;model/batch_normalization_17/FusedBatchNormV3;model/depthwise_conv2d_8/depthwise;model/depthwise_conv2d_8/BiasAdd;model/depthwise_conv2d_11/depthwise;model/depthwise_conv2d_8/BiasAdd/ReadVariableOp/resource1:0:0 */, 0.0365f /* ty=float32 span=model/activation_17/Relu;model/batch_normalization_17/FusedBatchNormV3;model/depthwise_conv2d_8/depthwise;model/depthwise_conv2d_8/BiasAdd;model/depthwise_conv2d_11/depthwise;model/depthwise_conv2d_8/BiasAdd/ReadVariableOp/resource1:0:0 */, meta[relay.Constant][34] /* ty=Tensor[(128), float32] span=model/activation_17/Relu;model/batch_normalization_17/FusedBatchNormV3;model/depthwise_conv2d_8/depthwise;model/depthwise_conv2d_8/BiasAdd;model/depthwise_conv2d_11/depthwise;model/depthwise_conv2d_8/BiasAdd/ReadVariableOp/resource1:0:0 */, padding=[1, 1, 1, 1], groups=128, channels=128, kernel_size=[3, 3], data_layout="NHWC", kernel_layout="HWOI", out_dtype="int32") /* ty=Tensor[(1, 6, 6, 128), int32] span=model/activation_17/Relu;model/batch_normalization_17/FusedBatchNormV3;model/depthwise_conv2d_8/depthwise;model/depthwise_conv2d_8/BiasAdd;model/depthwise_conv2d_11/depthwise;model/depthwise_conv2d_8/BiasAdd/ReadVariableOp/resource1:0:0 */;
  %69 = nn.bias_add(%68, %v_param_36, axis=3) /* ty=Tensor[(1, 6, 6, 128), int32] span=model/activation_17/Relu;model/batch_normalization_17/FusedBatchNormV3;model/depthwise_conv2d_8/depthwise;model/depthwise_conv2d_8/BiasAdd;model/depthwise_conv2d_11/depthwise;model/depthwise_conv2d_8/BiasAdd/ReadVariableOp/resource1:0:0 */;
  %70 = qnn.requantize(%69, meta[relay.Constant][35] /* ty=Tensor[(128), float32] span=model/activation_17/Relu;model/batch_normalization_17/FusedBatchNormV3;model/depthwise_conv2d_8/depthwise;model/depthwise_conv2d_8/BiasAdd;model/depthwise_conv2d_11/depthwise;model/depthwise_conv2d_8/BiasAdd/ReadVariableOp/resource1:0:0 */, 0 /* ty=int32 span=model/activation_17/Relu;model/batch_normalization_17/FusedBatchNormV3;model/depthwise_conv2d_8/depthwise;model/depthwise_conv2d_8/BiasAdd;model/depthwise_conv2d_11/depthwise;model/depthwise_conv2d_8/BiasAdd/ReadVariableOp/resource1:0:0 */, 0.0378104f /* ty=float32 span=model/activation_17/Relu;model/batch_normalization_17/FusedBatchNormV3;model/depthwise_conv2d_8/depthwise;model/depthwise_conv2d_8/BiasAdd;model/depthwise_conv2d_11/depthwise;model/depthwise_conv2d_8/BiasAdd/ReadVariableOp/resource1:0:0 */, -128 /* ty=int32 span=model/activation_17/Relu;model/batch_normalization_17/FusedBatchNormV3;model/depthwise_conv2d_8/depthwise;model/depthwise_conv2d_8/BiasAdd;model/depthwise_conv2d_11/depthwise;model/depthwise_conv2d_8/BiasAdd/ReadVariableOp/resource1:0:0 */, axis=3, rounding="UPWARD", compute_dtype="int64", out_dtype="int8") /* ty=Tensor[(1, 6, 6, 128), int8] span=model/activation_17/Relu;model/batch_normalization_17/FusedBatchNormV3;model/depthwise_conv2d_8/depthwise;model/depthwise_conv2d_8/BiasAdd;model/depthwise_conv2d_11/depthwise;model/depthwise_conv2d_8/BiasAdd/ReadVariableOp/resource1:0:0 */;
  %71 = clip(%70, a_min=-128f, a_max=127f) /* ty=Tensor[(1, 6, 6, 128), int8] span=model/activation_17/Relu;model/batch_normalization_17/FusedBatchNormV3;model/depthwise_conv2d_8/depthwise;model/depthwise_conv2d_8/BiasAdd;model/depthwise_conv2d_11/depthwise;model/depthwise_conv2d_8/BiasAdd/ReadVariableOp/resource1:0:0 */;
  %72 = qnn.conv2d(%71, %v_param_37, -128 /* ty=int32 span=model/activation_18/Relu;model/batch_normalization_18/FusedBatchNormV3;model/conv2d_9/BiasAdd/ReadVariableOp/resource;model/conv2d_9/BiasAdd;model/depthwise_conv2d_11/depthwise;model/conv2d_9/Conv2D1:0:0 */, 0 /* ty=int32 span=model/activation_18/Relu;model/batch_normalization_18/FusedBatchNormV3;model/conv2d_9/BiasAdd/ReadVariableOp/resource;model/conv2d_9/BiasAdd;model/depthwise_conv2d_11/depthwise;model/conv2d_9/Conv2D1:0:0 */, 0.0378104f /* ty=float32 span=model/activation_18/Relu;model/batch_normalization_18/FusedBatchNormV3;model/conv2d_9/BiasAdd/ReadVariableOp/resource;model/conv2d_9/BiasAdd;model/depthwise_conv2d_11/depthwise;model/conv2d_9/Conv2D1:0:0 */, meta[relay.Constant][36] /* ty=Tensor[(128), float32] span=model/activation_18/Relu;model/batch_normalization_18/FusedBatchNormV3;model/conv2d_9/BiasAdd/ReadVariableOp/resource;model/conv2d_9/BiasAdd;model/depthwise_conv2d_11/depthwise;model/conv2d_9/Conv2D1:0:0 */, padding=[0, 0, 0, 0], channels=128, kernel_size=[1, 1], data_layout="NHWC", kernel_layout="HWIO", out_dtype="int32") /* ty=Tensor[(1, 6, 6, 128), int32] span=model/activation_18/Relu;model/batch_normalization_18/FusedBatchNormV3;model/conv2d_9/BiasAdd/ReadVariableOp/resource;model/conv2d_9/BiasAdd;model/depthwise_conv2d_11/depthwise;model/conv2d_9/Conv2D1:0:0 */;
  %73 = nn.bias_add(%72, %v_param_38, axis=3) /* ty=Tensor[(1, 6, 6, 128), int32] span=model/activation_18/Relu;model/batch_normalization_18/FusedBatchNormV3;model/conv2d_9/BiasAdd/ReadVariableOp/resource;model/conv2d_9/BiasAdd;model/depthwise_conv2d_11/depthwise;model/conv2d_9/Conv2D1:0:0 */;
  %74 = qnn.requantize(%73, meta[relay.Constant][37] /* ty=Tensor[(128), float32] span=model/activation_18/Relu;model/batch_normalization_18/FusedBatchNormV3;model/conv2d_9/BiasAdd/ReadVariableOp/resource;model/conv2d_9/BiasAdd;model/depthwise_conv2d_11/depthwise;model/conv2d_9/Conv2D1:0:0 */, 0 /* ty=int32 span=model/activation_18/Relu;model/batch_normalization_18/FusedBatchNormV3;model/conv2d_9/BiasAdd/ReadVariableOp/resource;model/conv2d_9/BiasAdd;model/depthwise_conv2d_11/depthwise;model/conv2d_9/Conv2D1:0:0 */, 0.0206044f /* ty=float32 span=model/activation_18/Relu;model/batch_normalization_18/FusedBatchNormV3;model/conv2d_9/BiasAdd/ReadVariableOp/resource;model/conv2d_9/BiasAdd;model/depthwise_conv2d_11/depthwise;model/conv2d_9/Conv2D1:0:0 */, -128 /* ty=int32 span=model/activation_18/Relu;model/batch_normalization_18/FusedBatchNormV3;model/conv2d_9/BiasAdd/ReadVariableOp/resource;model/conv2d_9/BiasAdd;model/depthwise_conv2d_11/depthwise;model/conv2d_9/Conv2D1:0:0 */, axis=3, rounding="UPWARD", compute_dtype="int64", out_dtype="int8") /* ty=Tensor[(1, 6, 6, 128), int8] span=model/activation_18/Relu;model/batch_normalization_18/FusedBatchNormV3;model/conv2d_9/BiasAdd/ReadVariableOp/resource;model/conv2d_9/BiasAdd;model/depthwise_conv2d_11/depthwise;model/conv2d_9/Conv2D1:0:0 */;
  %75 = clip(%74, a_min=-128f, a_max=127f) /* ty=Tensor[(1, 6, 6, 128), int8] span=model/activation_18/Relu;model/batch_normalization_18/FusedBatchNormV3;model/conv2d_9/BiasAdd/ReadVariableOp/resource;model/conv2d_9/BiasAdd;model/depthwise_conv2d_11/depthwise;model/conv2d_9/Conv2D1:0:0 */;
  %76 = qnn.conv2d(%75, %v_param_39, -128 /* ty=int32 span=model/activation_19/Relu;model/batch_normalization_19/FusedBatchNormV3;model/depthwise_conv2d_9/depthwise;model/depthwise_conv2d_9/BiasAdd;model/depthwise_conv2d_11/depthwise;model/depthwise_conv2d_9/BiasAdd/ReadVariableOp/resource1:0:0 */, 0 /* ty=int32 span=model/activation_19/Relu;model/batch_normalization_19/FusedBatchNormV3;model/depthwise_conv2d_9/depthwise;model/depthwise_conv2d_9/BiasAdd;model/depthwise_conv2d_11/depthwise;model/depthwise_conv2d_9/BiasAdd/ReadVariableOp/resource1:0:0 */, 0.0206044f /* ty=float32 span=model/activation_19/Relu;model/batch_normalization_19/FusedBatchNormV3;model/depthwise_conv2d_9/depthwise;model/depthwise_conv2d_9/BiasAdd;model/depthwise_conv2d_11/depthwise;model/depthwise_conv2d_9/BiasAdd/ReadVariableOp/resource1:0:0 */, meta[relay.Constant][38] /* ty=Tensor[(128), float32] span=model/activation_19/Relu;model/batch_normalization_19/FusedBatchNormV3;model/depthwise_conv2d_9/depthwise;model/depthwise_conv2d_9/BiasAdd;model/depthwise_conv2d_11/depthwise;model/depthwise_conv2d_9/BiasAdd/ReadVariableOp/resource1:0:0 */, padding=[1, 1, 1, 1], groups=128, channels=128, kernel_size=[3, 3], data_layout="NHWC", kernel_layout="HWOI", out_dtype="int32") /* ty=Tensor[(1, 6, 6, 128), int32] span=model/activation_19/Relu;model/batch_normalization_19/FusedBatchNormV3;model/depthwise_conv2d_9/depthwise;model/depthwise_conv2d_9/BiasAdd;model/depthwise_conv2d_11/depthwise;model/depthwise_conv2d_9/BiasAdd/ReadVariableOp/resource1:0:0 */;
  %77 = nn.bias_add(%76, %v_param_40, axis=3) /* ty=Tensor[(1, 6, 6, 128), int32] span=model/activation_19/Relu;model/batch_normalization_19/FusedBatchNormV3;model/depthwise_conv2d_9/depthwise;model/depthwise_conv2d_9/BiasAdd;model/depthwise_conv2d_11/depthwise;model/depthwise_conv2d_9/BiasAdd/ReadVariableOp/resource1:0:0 */;
  %78 = qnn.requantize(%77, meta[relay.Constant][39] /* ty=Tensor[(128), float32] span=model/activation_19/Relu;model/batch_normalization_19/FusedBatchNormV3;model/depthwise_conv2d_9/depthwise;model/depthwise_conv2d_9/BiasAdd;model/depthwise_conv2d_11/depthwise;model/depthwise_conv2d_9/BiasAdd/ReadVariableOp/resource1:0:0 */, 0 /* ty=int32 span=model/activation_19/Relu;model/batch_normalization_19/FusedBatchNormV3;model/depthwise_conv2d_9/depthwise;model/depthwise_conv2d_9/BiasAdd;model/depthwise_conv2d_11/depthwise;model/depthwise_conv2d_9/BiasAdd/ReadVariableOp/resource1:0:0 */, 0.0332261f /* ty=float32 span=model/activation_19/Relu;model/batch_normalization_19/FusedBatchNormV3;model/depthwise_conv2d_9/depthwise;model/depthwise_conv2d_9/BiasAdd;model/depthwise_conv2d_11/depthwise;model/depthwise_conv2d_9/BiasAdd/ReadVariableOp/resource1:0:0 */, -128 /* ty=int32 span=model/activation_19/Relu;model/batch_normalization_19/FusedBatchNormV3;model/depthwise_conv2d_9/depthwise;model/depthwise_conv2d_9/BiasAdd;model/depthwise_conv2d_11/depthwise;model/depthwise_conv2d_9/BiasAdd/ReadVariableOp/resource1:0:0 */, axis=3, rounding="UPWARD", compute_dtype="int64", out_dtype="int8") /* ty=Tensor[(1, 6, 6, 128), int8] span=model/activation_19/Relu;model/batch_normalization_19/FusedBatchNormV3;model/depthwise_conv2d_9/depthwise;model/depthwise_conv2d_9/BiasAdd;model/depthwise_conv2d_11/depthwise;model/depthwise_conv2d_9/BiasAdd/ReadVariableOp/resource1:0:0 */;
  %79 = clip(%78, a_min=-128f, a_max=127f) /* ty=Tensor[(1, 6, 6, 128), int8] span=model/activation_19/Relu;model/batch_normalization_19/FusedBatchNormV3;model/depthwise_conv2d_9/depthwise;model/depthwise_conv2d_9/BiasAdd;model/depthwise_conv2d_11/depthwise;model/depthwise_conv2d_9/BiasAdd/ReadVariableOp/resource1:0:0 */;
  %80 = qnn.conv2d(%79, %v_param_41, -128 /* ty=int32 span=model/activation_20/Relu;model/batch_normalization_20/FusedBatchNormV3;model/conv2d_10/BiasAdd/ReadVariableOp/resource;model/conv2d_10/BiasAdd;model/depthwise_conv2d_11/depthwise;model/conv2d_10/Conv2D1:0:0 */, 0 /* ty=int32 span=model/activation_20/Relu;model/batch_normalization_20/FusedBatchNormV3;model/conv2d_10/BiasAdd/ReadVariableOp/resource;model/conv2d_10/BiasAdd;model/depthwise_conv2d_11/depthwise;model/conv2d_10/Conv2D1:0:0 */, 0.0332261f /* ty=float32 span=model/activation_20/Relu;model/batch_normalization_20/FusedBatchNormV3;model/conv2d_10/BiasAdd/ReadVariableOp/resource;model/conv2d_10/BiasAdd;model/depthwise_conv2d_11/depthwise;model/conv2d_10/Conv2D1:0:0 */, meta[relay.Constant][40] /* ty=Tensor[(128), float32] span=model/activation_20/Relu;model/batch_normalization_20/FusedBatchNormV3;model/conv2d_10/BiasAdd/ReadVariableOp/resource;model/conv2d_10/BiasAdd;model/depthwise_conv2d_11/depthwise;model/conv2d_10/Conv2D1:0:0 */, padding=[0, 0, 0, 0], channels=128, kernel_size=[1, 1], data_layout="NHWC", kernel_layout="HWIO", out_dtype="int32") /* ty=Tensor[(1, 6, 6, 128), int32] span=model/activation_20/Relu;model/batch_normalization_20/FusedBatchNormV3;model/conv2d_10/BiasAdd/ReadVariableOp/resource;model/conv2d_10/BiasAdd;model/depthwise_conv2d_11/depthwise;model/conv2d_10/Conv2D1:0:0 */;
  %81 = nn.bias_add(%80, %v_param_42, axis=3) /* ty=Tensor[(1, 6, 6, 128), int32] span=model/activation_20/Relu;model/batch_normalization_20/FusedBatchNormV3;model/conv2d_10/BiasAdd/ReadVariableOp/resource;model/conv2d_10/BiasAdd;model/depthwise_conv2d_11/depthwise;model/conv2d_10/Conv2D1:0:0 */;
  %82 = qnn.requantize(%81, meta[relay.Constant][41] /* ty=Tensor[(128), float32] span=model/activation_20/Relu;model/batch_normalization_20/FusedBatchNormV3;model/conv2d_10/BiasAdd/ReadVariableOp/resource;model/conv2d_10/BiasAdd;model/depthwise_conv2d_11/depthwise;model/conv2d_10/Conv2D1:0:0 */, 0 /* ty=int32 span=model/activation_20/Relu;model/batch_normalization_20/FusedBatchNormV3;model/conv2d_10/BiasAdd/ReadVariableOp/resource;model/conv2d_10/BiasAdd;model/depthwise_conv2d_11/depthwise;model/conv2d_10/Conv2D1:0:0 */, 0.018733f /* ty=float32 span=model/activation_20/Relu;model/batch_normalization_20/FusedBatchNormV3;model/conv2d_10/BiasAdd/ReadVariableOp/resource;model/conv2d_10/BiasAdd;model/depthwise_conv2d_11/depthwise;model/conv2d_10/Conv2D1:0:0 */, -128 /* ty=int32 span=model/activation_20/Relu;model/batch_normalization_20/FusedBatchNormV3;model/conv2d_10/BiasAdd/ReadVariableOp/resource;model/conv2d_10/BiasAdd;model/depthwise_conv2d_11/depthwise;model/conv2d_10/Conv2D1:0:0 */, axis=3, rounding="UPWARD", compute_dtype="int64", out_dtype="int8") /* ty=Tensor[(1, 6, 6, 128), int8] span=model/activation_20/Relu;model/batch_normalization_20/FusedBatchNormV3;model/conv2d_10/BiasAdd/ReadVariableOp/resource;model/conv2d_10/BiasAdd;model/depthwise_conv2d_11/depthwise;model/conv2d_10/Conv2D1:0:0 */;
  %83 = clip(%82, a_min=-128f, a_max=127f) /* ty=Tensor[(1, 6, 6, 128), int8] span=model/activation_20/Relu;model/batch_normalization_20/FusedBatchNormV3;model/conv2d_10/BiasAdd/ReadVariableOp/resource;model/conv2d_10/BiasAdd;model/depthwise_conv2d_11/depthwise;model/conv2d_10/Conv2D1:0:0 */;
  %84 = qnn.conv2d(%83, %v_param_43, -128 /* ty=int32 span=model/activation_21/Relu;model/batch_normalization_21/FusedBatchNormV3;model/depthwise_conv2d_10/depthwise;model/depthwise_conv2d_10/BiasAdd;model/depthwise_conv2d_11/depthwise;model/depthwise_conv2d_10/BiasAdd/ReadVariableOp/resource1:0:0 */, 0 /* ty=int32 span=model/activation_21/Relu;model/batch_normalization_21/FusedBatchNormV3;model/depthwise_conv2d_10/depthwise;model/depthwise_conv2d_10/BiasAdd;model/depthwise_conv2d_11/depthwise;model/depthwise_conv2d_10/BiasAdd/ReadVariableOp/resource1:0:0 */, 0.018733f /* ty=float32 span=model/activation_21/Relu;model/batch_normalization_21/FusedBatchNormV3;model/depthwise_conv2d_10/depthwise;model/depthwise_conv2d_10/BiasAdd;model/depthwise_conv2d_11/depthwise;model/depthwise_conv2d_10/BiasAdd/ReadVariableOp/resource1:0:0 */, meta[relay.Constant][42] /* ty=Tensor[(128), float32] span=model/activation_21/Relu;model/batch_normalization_21/FusedBatchNormV3;model/depthwise_conv2d_10/depthwise;model/depthwise_conv2d_10/BiasAdd;model/depthwise_conv2d_11/depthwise;model/depthwise_conv2d_10/BiasAdd/ReadVariableOp/resource1:0:0 */, padding=[1, 1, 1, 1], groups=128, channels=128, kernel_size=[3, 3], data_layout="NHWC", kernel_layout="HWOI", out_dtype="int32") /* ty=Tensor[(1, 6, 6, 128), int32] span=model/activation_21/Relu;model/batch_normalization_21/FusedBatchNormV3;model/depthwise_conv2d_10/depthwise;model/depthwise_conv2d_10/BiasAdd;model/depthwise_conv2d_11/depthwise;model/depthwise_conv2d_10/BiasAdd/ReadVariableOp/resource1:0:0 */;
  %85 = nn.bias_add(%84, %v_param_44, axis=3) /* ty=Tensor[(1, 6, 6, 128), int32] span=model/activation_21/Relu;model/batch_normalization_21/FusedBatchNormV3;model/depthwise_conv2d_10/depthwise;model/depthwise_conv2d_10/BiasAdd;model/depthwise_conv2d_11/depthwise;model/depthwise_conv2d_10/BiasAdd/ReadVariableOp/resource1:0:0 */;
  %86 = qnn.requantize(%85, meta[relay.Constant][43] /* ty=Tensor[(128), float32] span=model/activation_21/Relu;model/batch_normalization_21/FusedBatchNormV3;model/depthwise_conv2d_10/depthwise;model/depthwise_conv2d_10/BiasAdd;model/depthwise_conv2d_11/depthwise;model/depthwise_conv2d_10/BiasAdd/ReadVariableOp/resource1:0:0 */, 0 /* ty=int32 span=model/activation_21/Relu;model/batch_normalization_21/FusedBatchNormV3;model/depthwise_conv2d_10/depthwise;model/depthwise_conv2d_10/BiasAdd;model/depthwise_conv2d_11/depthwise;model/depthwise_conv2d_10/BiasAdd/ReadVariableOp/resource1:0:0 */, 0.0341283f /* ty=float32 span=model/activation_21/Relu;model/batch_normalization_21/FusedBatchNormV3;model/depthwise_conv2d_10/depthwise;model/depthwise_conv2d_10/BiasAdd;model/depthwise_conv2d_11/depthwise;model/depthwise_conv2d_10/BiasAdd/ReadVariableOp/resource1:0:0 */, -128 /* ty=int32 span=model/activation_21/Relu;model/batch_normalization_21/FusedBatchNormV3;model/depthwise_conv2d_10/depthwise;model/depthwise_conv2d_10/BiasAdd;model/depthwise_conv2d_11/depthwise;model/depthwise_conv2d_10/BiasAdd/ReadVariableOp/resource1:0:0 */, axis=3, rounding="UPWARD", compute_dtype="int64", out_dtype="int8") /* ty=Tensor[(1, 6, 6, 128), int8] span=model/activation_21/Relu;model/batch_normalization_21/FusedBatchNormV3;model/depthwise_conv2d_10/depthwise;model/depthwise_conv2d_10/BiasAdd;model/depthwise_conv2d_11/depthwise;model/depthwise_conv2d_10/BiasAdd/ReadVariableOp/resource1:0:0 */;
  %87 = clip(%86, a_min=-128f, a_max=127f) /* ty=Tensor[(1, 6, 6, 128), int8] span=model/activation_21/Relu;model/batch_normalization_21/FusedBatchNormV3;model/depthwise_conv2d_10/depthwise;model/depthwise_conv2d_10/BiasAdd;model/depthwise_conv2d_11/depthwise;model/depthwise_conv2d_10/BiasAdd/ReadVariableOp/resource1:0:0 */;
  %88 = qnn.conv2d(%87, %v_param_45, -128 /* ty=int32 span=model/activation_22/Relu;model/batch_normalization_22/FusedBatchNormV3;model/conv2d_11/BiasAdd/ReadVariableOp/resource;model/conv2d_11/BiasAdd;model/depthwise_conv2d_11/depthwise;model/conv2d_11/Conv2D1:0:0 */, 0 /* ty=int32 span=model/activation_22/Relu;model/batch_normalization_22/FusedBatchNormV3;model/conv2d_11/BiasAdd/ReadVariableOp/resource;model/conv2d_11/BiasAdd;model/depthwise_conv2d_11/depthwise;model/conv2d_11/Conv2D1:0:0 */, 0.0341283f /* ty=float32 span=model/activation_22/Relu;model/batch_normalization_22/FusedBatchNormV3;model/conv2d_11/BiasAdd/ReadVariableOp/resource;model/conv2d_11/BiasAdd;model/depthwise_conv2d_11/depthwise;model/conv2d_11/Conv2D1:0:0 */, meta[relay.Constant][44] /* ty=Tensor[(128), float32] span=model/activation_22/Relu;model/batch_normalization_22/FusedBatchNormV3;model/conv2d_11/BiasAdd/ReadVariableOp/resource;model/conv2d_11/BiasAdd;model/depthwise_conv2d_11/depthwise;model/conv2d_11/Conv2D1:0:0 */, padding=[0, 0, 0, 0], channels=128, kernel_size=[1, 1], data_layout="NHWC", kernel_layout="HWIO", out_dtype="int32") /* ty=Tensor[(1, 6, 6, 128), int32] span=model/activation_22/Relu;model/batch_normalization_22/FusedBatchNormV3;model/conv2d_11/BiasAdd/ReadVariableOp/resource;model/conv2d_11/BiasAdd;model/depthwise_conv2d_11/depthwise;model/conv2d_11/Conv2D1:0:0 */;
  %89 = nn.bias_add(%88, %v_param_46, axis=3) /* ty=Tensor[(1, 6, 6, 128), int32] span=model/activation_22/Relu;model/batch_normalization_22/FusedBatchNormV3;model/conv2d_11/BiasAdd/ReadVariableOp/resource;model/conv2d_11/BiasAdd;model/depthwise_conv2d_11/depthwise;model/conv2d_11/Conv2D1:0:0 */;
  %90 = qnn.requantize(%89, meta[relay.Constant][45] /* ty=Tensor[(128), float32] span=model/activation_22/Relu;model/batch_normalization_22/FusedBatchNormV3;model/conv2d_11/BiasAdd/ReadVariableOp/resource;model/conv2d_11/BiasAdd;model/depthwise_conv2d_11/depthwise;model/conv2d_11/Conv2D1:0:0 */, 0 /* ty=int32 span=model/activation_22/Relu;model/batch_normalization_22/FusedBatchNormV3;model/conv2d_11/BiasAdd/ReadVariableOp/resource;model/conv2d_11/BiasAdd;model/depthwise_conv2d_11/depthwise;model/conv2d_11/Conv2D1:0:0 */, 0.0188816f /* ty=float32 span=model/activation_22/Relu;model/batch_normalization_22/FusedBatchNormV3;model/conv2d_11/BiasAdd/ReadVariableOp/resource;model/conv2d_11/BiasAdd;model/depthwise_conv2d_11/depthwise;model/conv2d_11/Conv2D1:0:0 */, -128 /* ty=int32 span=model/activation_22/Relu;model/batch_normalization_22/FusedBatchNormV3;model/conv2d_11/BiasAdd/ReadVariableOp/resource;model/conv2d_11/BiasAdd;model/depthwise_conv2d_11/depthwise;model/conv2d_11/Conv2D1:0:0 */, axis=3, rounding="UPWARD", compute_dtype="int64", out_dtype="int8") /* ty=Tensor[(1, 6, 6, 128), int8] span=model/activation_22/Relu;model/batch_normalization_22/FusedBatchNormV3;model/conv2d_11/BiasAdd/ReadVariableOp/resource;model/conv2d_11/BiasAdd;model/depthwise_conv2d_11/depthwise;model/conv2d_11/Conv2D1:0:0 */;
  %91 = clip(%90, a_min=-128f, a_max=127f) /* ty=Tensor[(1, 6, 6, 128), int8] span=model/activation_22/Relu;model/batch_normalization_22/FusedBatchNormV3;model/conv2d_11/BiasAdd/ReadVariableOp/resource;model/conv2d_11/BiasAdd;model/depthwise_conv2d_11/depthwise;model/conv2d_11/Conv2D1:0:0 */;
  %92 = qnn.conv2d(%91, %v_param_47, -128 /* ty=int32 span=model/activation_23/Relu;model/batch_normalization_23/FusedBatchNormV3;model/depthwise_conv2d_11/depthwise;model/depthwise_conv2d_11/BiasAdd;model/depthwise_conv2d_11/BiasAdd/ReadVariableOp/resource1:0:0 */, 0 /* ty=int32 span=model/activation_23/Relu;model/batch_normalization_23/FusedBatchNormV3;model/depthwise_conv2d_11/depthwise;model/depthwise_conv2d_11/BiasAdd;model/depthwise_conv2d_11/BiasAdd/ReadVariableOp/resource1:0:0 */, 0.0188816f /* ty=float32 span=model/activation_23/Relu;model/batch_normalization_23/FusedBatchNormV3;model/depthwise_conv2d_11/depthwise;model/depthwise_conv2d_11/BiasAdd;model/depthwise_conv2d_11/BiasAdd/ReadVariableOp/resource1:0:0 */, meta[relay.Constant][46] /* ty=Tensor[(128), float32] span=model/activation_23/Relu;model/batch_normalization_23/FusedBatchNormV3;model/depthwise_conv2d_11/depthwise;model/depthwise_conv2d_11/BiasAdd;model/depthwise_conv2d_11/BiasAdd/ReadVariableOp/resource1:0:0 */, strides=[2, 2], padding=[0, 0, 1, 1], groups=128, channels=128, kernel_size=[3, 3], data_layout="NHWC", kernel_layout="HWOI", out_dtype="int32") /* ty=Tensor[(1, 3, 3, 128), int32] span=model/activation_23/Relu;model/batch_normalization_23/FusedBatchNormV3;model/depthwise_conv2d_11/depthwise;model/depthwise_conv2d_11/BiasAdd;model/depthwise_conv2d_11/BiasAdd/ReadVariableOp/resource1:0:0 */;
  %93 = nn.bias_add(%92, %v_param_48, axis=3) /* ty=Tensor[(1, 3, 3, 128), int32] span=model/activation_23/Relu;model/batch_normalization_23/FusedBatchNormV3;model/depthwise_conv2d_11/depthwise;model/depthwise_conv2d_11/BiasAdd;model/depthwise_conv2d_11/BiasAdd/ReadVariableOp/resource1:0:0 */;
  %94 = qnn.requantize(%93, meta[relay.Constant][47] /* ty=Tensor[(128), float32] span=model/activation_23/Relu;model/batch_normalization_23/FusedBatchNormV3;model/depthwise_conv2d_11/depthwise;model/depthwise_conv2d_11/BiasAdd;model/depthwise_conv2d_11/BiasAdd/ReadVariableOp/resource1:0:0 */, 0 /* ty=int32 span=model/activation_23/Relu;model/batch_normalization_23/FusedBatchNormV3;model/depthwise_conv2d_11/depthwise;model/depthwise_conv2d_11/BiasAdd;model/depthwise_conv2d_11/BiasAdd/ReadVariableOp/resource1:0:0 */, 0.0252806f /* ty=float32 span=model/activation_23/Relu;model/batch_normalization_23/FusedBatchNormV3;model/depthwise_conv2d_11/depthwise;model/depthwise_conv2d_11/BiasAdd;model/depthwise_conv2d_11/BiasAdd/ReadVariableOp/resource1:0:0 */, -128 /* ty=int32 span=model/activation_23/Relu;model/batch_normalization_23/FusedBatchNormV3;model/depthwise_conv2d_11/depthwise;model/depthwise_conv2d_11/BiasAdd;model/depthwise_conv2d_11/BiasAdd/ReadVariableOp/resource1:0:0 */, axis=3, rounding="UPWARD", compute_dtype="int64", out_dtype="int8") /* ty=Tensor[(1, 3, 3, 128), int8] span=model/activation_23/Relu;model/batch_normalization_23/FusedBatchNormV3;model/depthwise_conv2d_11/depthwise;model/depthwise_conv2d_11/BiasAdd;model/depthwise_conv2d_11/BiasAdd/ReadVariableOp/resource1:0:0 */;
  %95 = clip(%94, a_min=-128f, a_max=127f) /* ty=Tensor[(1, 3, 3, 128), int8] span=model/activation_23/Relu;model/batch_normalization_23/FusedBatchNormV3;model/depthwise_conv2d_11/depthwise;model/depthwise_conv2d_11/BiasAdd;model/depthwise_conv2d_11/BiasAdd/ReadVariableOp/resource1:0:0 */;
  %96 = qnn.conv2d(%95, %v_param_49, -128 /* ty=int32 span=model/activation_24/Relu;model/batch_normalization_24/FusedBatchNormV3;model/conv2d_12/BiasAdd/ReadVariableOp/resource;model/conv2d_12/BiasAdd;model/conv2d_13/Conv2D;model/conv2d_12/Conv2D1:0:0 */, 0 /* ty=int32 span=model/activation_24/Relu;model/batch_normalization_24/FusedBatchNormV3;model/conv2d_12/BiasAdd/ReadVariableOp/resource;model/conv2d_12/BiasAdd;model/conv2d_13/Conv2D;model/conv2d_12/Conv2D1:0:0 */, 0.0252806f /* ty=float32 span=model/activation_24/Relu;model/batch_normalization_24/FusedBatchNormV3;model/conv2d_12/BiasAdd/ReadVariableOp/resource;model/conv2d_12/BiasAdd;model/conv2d_13/Conv2D;model/conv2d_12/Conv2D1:0:0 */, meta[relay.Constant][48] /* ty=Tensor[(256), float32] span=model/activation_24/Relu;model/batch_normalization_24/FusedBatchNormV3;model/conv2d_12/BiasAdd/ReadVariableOp/resource;model/conv2d_12/BiasAdd;model/conv2d_13/Conv2D;model/conv2d_12/Conv2D1:0:0 */, padding=[0, 0, 0, 0], channels=256, kernel_size=[1, 1], data_layout="NHWC", kernel_layout="HWIO", out_dtype="int32") /* ty=Tensor[(1, 3, 3, 256), int32] span=model/activation_24/Relu;model/batch_normalization_24/FusedBatchNormV3;model/conv2d_12/BiasAdd/ReadVariableOp/resource;model/conv2d_12/BiasAdd;model/conv2d_13/Conv2D;model/conv2d_12/Conv2D1:0:0 */;
  %97 = nn.bias_add(%96, %v_param_50, axis=3) /* ty=Tensor[(1, 3, 3, 256), int32] span=model/activation_24/Relu;model/batch_normalization_24/FusedBatchNormV3;model/conv2d_12/BiasAdd/ReadVariableOp/resource;model/conv2d_12/BiasAdd;model/conv2d_13/Conv2D;model/conv2d_12/Conv2D1:0:0 */;
  %98 = qnn.requantize(%97, meta[relay.Constant][49] /* ty=Tensor[(256), float32] span=model/activation_24/Relu;model/batch_normalization_24/FusedBatchNormV3;model/conv2d_12/BiasAdd/ReadVariableOp/resource;model/conv2d_12/BiasAdd;model/conv2d_13/Conv2D;model/conv2d_12/Conv2D1:0:0 */, 0 /* ty=int32 span=model/activation_24/Relu;model/batch_normalization_24/FusedBatchNormV3;model/conv2d_12/BiasAdd/ReadVariableOp/resource;model/conv2d_12/BiasAdd;model/conv2d_13/Conv2D;model/conv2d_12/Conv2D1:0:0 */, 0.021838f /* ty=float32 span=model/activation_24/Relu;model/batch_normalization_24/FusedBatchNormV3;model/conv2d_12/BiasAdd/ReadVariableOp/resource;model/conv2d_12/BiasAdd;model/conv2d_13/Conv2D;model/conv2d_12/Conv2D1:0:0 */, -128 /* ty=int32 span=model/activation_24/Relu;model/batch_normalization_24/FusedBatchNormV3;model/conv2d_12/BiasAdd/ReadVariableOp/resource;model/conv2d_12/BiasAdd;model/conv2d_13/Conv2D;model/conv2d_12/Conv2D1:0:0 */, axis=3, rounding="UPWARD", compute_dtype="int64", out_dtype="int8") /* ty=Tensor[(1, 3, 3, 256), int8] span=model/activation_24/Relu;model/batch_normalization_24/FusedBatchNormV3;model/conv2d_12/BiasAdd/ReadVariableOp/resource;model/conv2d_12/BiasAdd;model/conv2d_13/Conv2D;model/conv2d_12/Conv2D1:0:0 */;
  %99 = clip(%98, a_min=-128f, a_max=127f) /* ty=Tensor[(1, 3, 3, 256), int8] span=model/activation_24/Relu;model/batch_normalization_24/FusedBatchNormV3;model/conv2d_12/BiasAdd/ReadVariableOp/resource;model/conv2d_12/BiasAdd;model/conv2d_13/Conv2D;model/conv2d_12/Conv2D1:0:0 */;
  %100 = qnn.conv2d(%99, %v_param_51, -128 /* ty=int32 span=model/activation_25/Relu;model/batch_normalization_25/FusedBatchNormV3;model/depthwise_conv2d_12/depthwise;model/depthwise_conv2d_12/BiasAdd;model/conv2d_13/Conv2D;model/depthwise_conv2d_12/BiasAdd/ReadVariableOp/resource1:0:0 */, 0 /* ty=int32 span=model/activation_25/Relu;model/batch_normalization_25/FusedBatchNormV3;model/depthwise_conv2d_12/depthwise;model/depthwise_conv2d_12/BiasAdd;model/conv2d_13/Conv2D;model/depthwise_conv2d_12/BiasAdd/ReadVariableOp/resource1:0:0 */, 0.021838f /* ty=float32 span=model/activation_25/Relu;model/batch_normalization_25/FusedBatchNormV3;model/depthwise_conv2d_12/depthwise;model/depthwise_conv2d_12/BiasAdd;model/conv2d_13/Conv2D;model/depthwise_conv2d_12/BiasAdd/ReadVariableOp/resource1:0:0 */, meta[relay.Constant][50] /* ty=Tensor[(256), float32] span=model/activation_25/Relu;model/batch_normalization_25/FusedBatchNormV3;model/depthwise_conv2d_12/depthwise;model/depthwise_conv2d_12/BiasAdd;model/conv2d_13/Conv2D;model/depthwise_conv2d_12/BiasAdd/ReadVariableOp/resource1:0:0 */, padding=[1, 1, 1, 1], groups=256, channels=256, kernel_size=[3, 3], data_layout="NHWC", kernel_layout="HWOI", out_dtype="int32") /* ty=Tensor[(1, 3, 3, 256), int32] span=model/activation_25/Relu;model/batch_normalization_25/FusedBatchNormV3;model/depthwise_conv2d_12/depthwise;model/depthwise_conv2d_12/BiasAdd;model/conv2d_13/Conv2D;model/depthwise_conv2d_12/BiasAdd/ReadVariableOp/resource1:0:0 */;
  %101 = nn.bias_add(%100, %v_param_52, axis=3) /* ty=Tensor[(1, 3, 3, 256), int32] span=model/activation_25/Relu;model/batch_normalization_25/FusedBatchNormV3;model/depthwise_conv2d_12/depthwise;model/depthwise_conv2d_12/BiasAdd;model/conv2d_13/Conv2D;model/depthwise_conv2d_12/BiasAdd/ReadVariableOp/resource1:0:0 */;
  %102 = qnn.requantize(%101, meta[relay.Constant][51] /* ty=Tensor[(256), float32] span=model/activation_25/Relu;model/batch_normalization_25/FusedBatchNormV3;model/depthwise_conv2d_12/depthwise;model/depthwise_conv2d_12/BiasAdd;model/conv2d_13/Conv2D;model/depthwise_conv2d_12/BiasAdd/ReadVariableOp/resource1:0:0 */, 0 /* ty=int32 span=model/activation_25/Relu;model/batch_normalization_25/FusedBatchNormV3;model/depthwise_conv2d_12/depthwise;model/depthwise_conv2d_12/BiasAdd;model/conv2d_13/Conv2D;model/depthwise_conv2d_12/BiasAdd/ReadVariableOp/resource1:0:0 */, 0.0296261f /* ty=float32 span=model/activation_25/Relu;model/batch_normalization_25/FusedBatchNormV3;model/depthwise_conv2d_12/depthwise;model/depthwise_conv2d_12/BiasAdd;model/conv2d_13/Conv2D;model/depthwise_conv2d_12/BiasAdd/ReadVariableOp/resource1:0:0 */, -128 /* ty=int32 span=model/activation_25/Relu;model/batch_normalization_25/FusedBatchNormV3;model/depthwise_conv2d_12/depthwise;model/depthwise_conv2d_12/BiasAdd;model/conv2d_13/Conv2D;model/depthwise_conv2d_12/BiasAdd/ReadVariableOp/resource1:0:0 */, axis=3, rounding="UPWARD", compute_dtype="int64", out_dtype="int8") /* ty=Tensor[(1, 3, 3, 256), int8] span=model/activation_25/Relu;model/batch_normalization_25/FusedBatchNormV3;model/depthwise_conv2d_12/depthwise;model/depthwise_conv2d_12/BiasAdd;model/conv2d_13/Conv2D;model/depthwise_conv2d_12/BiasAdd/ReadVariableOp/resource1:0:0 */;
  %103 = clip(%102, a_min=-128f, a_max=127f) /* ty=Tensor[(1, 3, 3, 256), int8] span=model/activation_25/Relu;model/batch_normalization_25/FusedBatchNormV3;model/depthwise_conv2d_12/depthwise;model/depthwise_conv2d_12/BiasAdd;model/conv2d_13/Conv2D;model/depthwise_conv2d_12/BiasAdd/ReadVariableOp/resource1:0:0 */;
  %104 = qnn.conv2d(%103, %v_param_53, -128 /* ty=int32 span=model/activation_26/Relu;model/batch_normalization_26/FusedBatchNormV3;model/conv2d_13/BiasAdd/ReadVariableOp/resource;model/conv2d_13/BiasAdd;model/conv2d_13/Conv2D1:0:0 */, 0 /* ty=int32 span=model/activation_26/Relu;model/batch_normalization_26/FusedBatchNormV3;model/conv2d_13/BiasAdd/ReadVariableOp/resource;model/conv2d_13/BiasAdd;model/conv2d_13/Conv2D1:0:0 */, 0.0296261f /* ty=float32 span=model/activation_26/Relu;model/batch_normalization_26/FusedBatchNormV3;model/conv2d_13/BiasAdd/ReadVariableOp/resource;model/conv2d_13/BiasAdd;model/conv2d_13/Conv2D1:0:0 */, meta[relay.Constant][52] /* ty=Tensor[(256), float32] span=model/activation_26/Relu;model/batch_normalization_26/FusedBatchNormV3;model/conv2d_13/BiasAdd/ReadVariableOp/resource;model/conv2d_13/BiasAdd;model/conv2d_13/Conv2D1:0:0 */, padding=[0, 0, 0, 0], channels=256, kernel_size=[1, 1], data_layout="NHWC", kernel_layout="HWIO", out_dtype="int32") /* ty=Tensor[(1, 3, 3, 256), int32] span=model/activation_26/Relu;model/batch_normalization_26/FusedBatchNormV3;model/conv2d_13/BiasAdd/ReadVariableOp/resource;model/conv2d_13/BiasAdd;model/conv2d_13/Conv2D1:0:0 */;
  %105 = nn.bias_add(%104, %v_param_54, axis=3) /* ty=Tensor[(1, 3, 3, 256), int32] span=model/activation_26/Relu;model/batch_normalization_26/FusedBatchNormV3;model/conv2d_13/BiasAdd/ReadVariableOp/resource;model/conv2d_13/BiasAdd;model/conv2d_13/Conv2D1:0:0 */;
  %106 = qnn.requantize(%105, meta[relay.Constant][53] /* ty=Tensor[(256), float32] span=model/activation_26/Relu;model/batch_normalization_26/FusedBatchNormV3;model/conv2d_13/BiasAdd/ReadVariableOp/resource;model/conv2d_13/BiasAdd;model/conv2d_13/Conv2D1:0:0 */, 0 /* ty=int32 span=model/activation_26/Relu;model/batch_normalization_26/FusedBatchNormV3;model/conv2d_13/BiasAdd/ReadVariableOp/resource;model/conv2d_13/BiasAdd;model/conv2d_13/Conv2D1:0:0 */, 0.0156569f /* ty=float32 span=model/activation_26/Relu;model/batch_normalization_26/FusedBatchNormV3;model/conv2d_13/BiasAdd/ReadVariableOp/resource;model/conv2d_13/BiasAdd;model/conv2d_13/Conv2D1:0:0 */, -128 /* ty=int32 span=model/activation_26/Relu;model/batch_normalization_26/FusedBatchNormV3;model/conv2d_13/BiasAdd/ReadVariableOp/resource;model/conv2d_13/BiasAdd;model/conv2d_13/Conv2D1:0:0 */, axis=3, rounding="UPWARD", compute_dtype="int64", out_dtype="int8") /* ty=Tensor[(1, 3, 3, 256), int8] span=model/activation_26/Relu;model/batch_normalization_26/FusedBatchNormV3;model/conv2d_13/BiasAdd/ReadVariableOp/resource;model/conv2d_13/BiasAdd;model/conv2d_13/Conv2D1:0:0 */;
  %107 = clip(%106, a_min=-128f, a_max=127f) /* ty=Tensor[(1, 3, 3, 256), int8] span=model/activation_26/Relu;model/batch_normalization_26/FusedBatchNormV3;model/conv2d_13/BiasAdd/ReadVariableOp/resource;model/conv2d_13/BiasAdd;model/conv2d_13/Conv2D1:0:0 */;
  %108 = cast(%107, dtype="int32") /* ty=Tensor[(1, 3, 3, 256), int32] span=model/average_pooling2d/AvgPool:0:0 */;
  %109 = nn.avg_pool2d(%108, pool_size=[3, 3], strides=[3, 3], padding=[0, 0, 0, 0], layout="NHWC") /* ty=Tensor[(1, 1, 1, 256), int32] span=model/average_pooling2d/AvgPool:0:0 */;
  %110 = cast(%109, dtype="int8") /* ty=Tensor[(1, 1, 1, 256), int8] span=model/average_pooling2d/AvgPool:0:0 */;
  %111 = reshape(%110, newshape=[-1, 256]) /* ty=Tensor[(1, 256), int8] span=model/flatten/Reshape:0:0 */;
  %112 = reshape(%111, newshape=[-1, 256]) /* ty=Tensor[(1, 256), int8] span=model/dense/MatMul;model/dense/BiasAdd:0:0 */;
  %113 = qnn.dense(%112, %v_param_55, -128 /* ty=int32 span=model/dense/MatMul;model/dense/BiasAdd:0:0 */, 0 /* ty=int32 span=model/dense/MatMul;model/dense/BiasAdd:0:0 */, 0.0156569f /* ty=float32 span=model/dense/MatMul;model/dense/BiasAdd:0:0 */, 0.00472029f /* ty=float32 span=model/dense/MatMul;model/dense/BiasAdd:0:0 */, units=2, out_dtype="int32") /* ty=Tensor[(1, 2), int32] span=model/dense/MatMul;model/dense/BiasAdd:0:0 */;
  %114 = nn.bias_add(%113, %v_param_56) /* ty=Tensor[(1, 2), int32] span=model/dense/MatMul;model/dense/BiasAdd:0:0 */;
  %115 = qnn.requantize(%114, 7.39052e-05f /* ty=float32 span=model/dense/MatMul;model/dense/BiasAdd:0:0 */, 0 /* ty=int32 span=model/dense/MatMul;model/dense/BiasAdd:0:0 */, 0.0146362f /* ty=float32 span=model/dense/MatMul;model/dense/BiasAdd:0:0 */, -5 /* ty=int32 span=model/dense/MatMul;model/dense/BiasAdd:0:0 */, rounding="UPWARD", compute_dtype="int64", out_dtype="int8") /* ty=Tensor[(1, 2), int8] span=model/dense/MatMul;model/dense/BiasAdd:0:0 */;
  %116 = qnn.dequantize(%115, 0.0146362f /* ty=float32 span=Identity_int8:0:0 */, -5 /* ty=int32 span=Identity_int8:0:0 */, out_dtype="float32") /* ty=Tensor[(1, 2), float32] span=Identity_int8:0:0 */;
  %117 = nn.softmax(%116) /* ty=Tensor[(1, 2), float32] span=Identity_int8:0:0 */;
  qnn.quantize(%117, 0.00390625f /* ty=float32 span=Identity_int8:0:0 */, -128 /* ty=int32 span=Identity_int8:0:0 */, out_dtype="int8") /* ty=Tensor[(1, 2), int8] span=Identity_int8:0:0 */
}

#[metadata]
{
  "root": 1, 
  "nodes": [
    {
      "type_key": ""
    }, 
    {
      "type_key": "Map", 
      "keys": [
        "relay.Constant"
      ], 
      "data": [2]
    }, 
    {
      "type_key": "Array", 
      "data": [
        3, 
        11, 
        15, 
        21, 
        24, 
        30, 
        34, 
        40, 
        43, 
        49, 
        53, 
        59, 
        62, 
        68, 
        72, 
        78, 
        81, 
        87, 
        91, 
        97, 
        100, 
        106, 
        110, 
        116, 
        119, 
        125, 
        129, 
        135, 
        138, 
        144, 
        148, 
        154, 
        157, 
        163, 
        167, 
        173, 
        176, 
        182, 
        186, 
        192, 
        195, 
        201, 
        205, 
        211, 
        214, 
        220, 
        224, 
        230, 
        233, 
        239, 
        243, 
        249, 
        252, 
        258
      ]
    }, 
    {
      "type_key": "relay.Constant", 
      "attrs": {
        "_checked_type_": "8", 
        "data": "0", 
        "span": "6", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "VirtualDevice", 
      "attrs": {
        "device_type_int": "-1", 
        "memory_scope": "5", 
        "target": "0", 
        "virtual_device_id": "-1"
      }
    }, 
    {
      "type_key": "runtime.String"
    }, 
    {
      "type_key": "Span", 
      "attrs": {
        "column": "0", 
        "end_column": "0", 
        "end_line": "0", 
        "line": "0", 
        "source_name": "7"
      }
    }, 
    {
      "type_key": "SourceName", 
      "repr_str": "model/activation/Relu;model/batch_normalization/FusedBatchNormV3;model/conv2d/BiasAdd/ReadVariableOp/resource;model/conv2d/BiasAdd;model/depthwise_conv2d/depthwise;model/conv2d/Conv2D1"
    }, 
    {
      "type_key": "relay.TensorType", 
      "attrs": {
        "dtype": "float32", 
        "shape": "9", 
        "span": "0"
      }
    }, 
    {
      "type_key": "Array", 
      "data": [10]
    }, 
    {
      "type_key": "IntImm", 
      "attrs": {
        "dtype": "int32", 
        "span": "0", 
        "value": "8"
      }
    }, 
    {
      "type_key": "relay.Constant", 
      "attrs": {
        "_checked_type_": "12", 
        "data": "1", 
        "span": "6", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "relay.TensorType", 
      "attrs": {
        "dtype": "float32", 
        "shape": "13", 
        "span": "0"
      }
    }, 
    {
      "type_key": "Array", 
      "data": [14]
    }, 
    {
      "type_key": "IntImm", 
      "attrs": {
        "dtype": "int32", 
        "span": "0", 
        "value": "8"
      }
    }, 
    {
      "type_key": "relay.Constant", 
      "attrs": {
        "_checked_type_": "18", 
        "data": "2", 
        "span": "16", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "Span", 
      "attrs": {
        "column": "0", 
        "end_column": "0", 
        "end_line": "0", 
        "line": "0", 
        "source_name": "17"
      }
    }, 
    {
      "type_key": "SourceName", 
      "repr_str": "model/activation_1/Relu;model/batch_normalization_1/FusedBatchNormV3;model/depthwise_conv2d/depthwise;model/depthwise_conv2d/BiasAdd;model/depthwise_conv2d/BiasAdd/ReadVariableOp/resource1"
    }, 
    {
      "type_key": "relay.TensorType", 
      "attrs": {
        "dtype": "float32", 
        "shape": "19", 
        "span": "0"
      }
    }, 
    {
      "type_key": "Array", 
      "data": [20]
    }, 
    {
      "type_key": "IntImm", 
      "attrs": {
        "dtype": "int32", 
        "span": "0", 
        "value": "8"
      }
    }, 
    {
      "type_key": "relay.Constant", 
      "attrs": {
        "_checked_type_": "22", 
        "data": "3", 
        "span": "16", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "relay.TensorType", 
      "attrs": {
        "dtype": "float32", 
        "shape": "23", 
        "span": "0"
      }
    }, 
    {
      "type_key": "Array", 
      "data": [20]
    }, 
    {
      "type_key": "relay.Constant", 
      "attrs": {
        "_checked_type_": "27", 
        "data": "4", 
        "span": "25", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "Span", 
      "attrs": {
        "column": "0", 
        "end_column": "0", 
        "end_line": "0", 
        "line": "0", 
        "source_name": "26"
      }
    }, 
    {
      "type_key": "SourceName", 
      "repr_str": "model/activation_2/Relu;model/batch_normalization_2/FusedBatchNormV3;model/conv2d_1/BiasAdd/ReadVariableOp/resource;model/conv2d_1/BiasAdd;model/depthwise_conv2d_1/depthwise;model/conv2d_1/Conv2D1"
    }, 
    {
      "type_key": "relay.TensorType", 
      "attrs": {
        "dtype": "float32", 
        "shape": "28", 
        "span": "0"
      }
    }, 
    {
      "type_key": "Array", 
      "data": [29]
    }, 
    {
      "type_key": "IntImm", 
      "attrs": {
        "dtype": "int32", 
        "span": "0", 
        "value": "16"
      }
    }, 
    {
      "type_key": "relay.Constant", 
      "attrs": {
        "_checked_type_": "31", 
        "data": "5", 
        "span": "25", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "relay.TensorType", 
      "attrs": {
        "dtype": "float32", 
        "shape": "32", 
        "span": "0"
      }
    }, 
    {
      "type_key": "Array", 
      "data": [33]
    }, 
    {
      "type_key": "IntImm", 
      "attrs": {
        "dtype": "int32", 
        "span": "0", 
        "value": "16"
      }
    }, 
    {
      "type_key": "relay.Constant", 
      "attrs": {
        "_checked_type_": "37", 
        "data": "6", 
        "span": "35", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "Span", 
      "attrs": {
        "column": "0", 
        "end_column": "0", 
        "end_line": "0", 
        "line": "0", 
        "source_name": "36"
      }
    }, 
    {
      "type_key": "SourceName", 
      "repr_str": "model/activation_3/Relu;model/batch_normalization_3/FusedBatchNormV3;model/depthwise_conv2d_1/depthwise;model/depthwise_conv2d_1/BiasAdd;model/depthwise_conv2d_1/BiasAdd/ReadVariableOp/resource1"
    }, 
    {
      "type_key": "relay.TensorType", 
      "attrs": {
        "dtype": "float32", 
        "shape": "38", 
        "span": "0"
      }
    }, 
    {
      "type_key": "Array", 
      "data": [39]
    }, 
    {
      "type_key": "IntImm", 
      "attrs": {
        "dtype": "int32", 
        "span": "0", 
        "value": "16"
      }
    }, 
    {
      "type_key": "relay.Constant", 
      "attrs": {
        "_checked_type_": "41", 
        "data": "7", 
        "span": "35", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "relay.TensorType", 
      "attrs": {
        "dtype": "float32", 
        "shape": "42", 
        "span": "0"
      }
    }, 
    {
      "type_key": "Array", 
      "data": [39]
    }, 
    {
      "type_key": "relay.Constant", 
      "attrs": {
        "_checked_type_": "46", 
        "data": "8", 
        "span": "44", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "Span", 
      "attrs": {
        "column": "0", 
        "end_column": "0", 
        "end_line": "0", 
        "line": "0", 
        "source_name": "45"
      }
    }, 
    {
      "type_key": "SourceName", 
      "repr_str": "model/activation_4/Relu;model/batch_normalization_4/FusedBatchNormV3;model/conv2d_2/BiasAdd/ReadVariableOp/resource;model/conv2d_2/BiasAdd;model/depthwise_conv2d_3/depthwise;model/conv2d_2/Conv2D1"
    }, 
    {
      "type_key": "relay.TensorType", 
      "attrs": {
        "dtype": "float32", 
        "shape": "47", 
        "span": "0"
      }
    }, 
    {
      "type_key": "Array", 
      "data": [48]
    }, 
    {
      "type_key": "IntImm", 
      "attrs": {
        "dtype": "int32", 
        "span": "0", 
        "value": "32"
      }
    }, 
    {
      "type_key": "relay.Constant", 
      "attrs": {
        "_checked_type_": "50", 
        "data": "9", 
        "span": "44", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "relay.TensorType", 
      "attrs": {
        "dtype": "float32", 
        "shape": "51", 
        "span": "0"
      }
    }, 
    {
      "type_key": "Array", 
      "data": [52]
    }, 
    {
      "type_key": "IntImm", 
      "attrs": {
        "dtype": "int32", 
        "span": "0", 
        "value": "32"
      }
    }, 
    {
      "type_key": "relay.Constant", 
      "attrs": {
        "_checked_type_": "56", 
        "data": "10", 
        "span": "54", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "Span", 
      "attrs": {
        "column": "0", 
        "end_column": "0", 
        "end_line": "0", 
        "line": "0", 
        "source_name": "55"
      }
    }, 
    {
      "type_key": "SourceName", 
      "repr_str": "model/activation_5/Relu;model/batch_normalization_5/FusedBatchNormV3;model/depthwise_conv2d_2/depthwise;model/depthwise_conv2d_2/BiasAdd;model/depthwise_conv2d_3/depthwise;model/depthwise_conv2d_2/BiasAdd/ReadVariableOp/resource1"
    }, 
    {
      "type_key": "relay.TensorType", 
      "attrs": {
        "dtype": "float32", 
        "shape": "57", 
        "span": "0"
      }
    }, 
    {
      "type_key": "Array", 
      "data": [58]
    }, 
    {
      "type_key": "IntImm", 
      "attrs": {
        "dtype": "int32", 
        "span": "0", 
        "value": "32"
      }
    }, 
    {
      "type_key": "relay.Constant", 
      "attrs": {
        "_checked_type_": "60", 
        "data": "11", 
        "span": "54", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "relay.TensorType", 
      "attrs": {
        "dtype": "float32", 
        "shape": "61", 
        "span": "0"
      }
    }, 
    {
      "type_key": "Array", 
      "data": [58]
    }, 
    {
      "type_key": "relay.Constant", 
      "attrs": {
        "_checked_type_": "65", 
        "data": "12", 
        "span": "63", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "Span", 
      "attrs": {
        "column": "0", 
        "end_column": "0", 
        "end_line": "0", 
        "line": "0", 
        "source_name": "64"
      }
    }, 
    {
      "type_key": "SourceName", 
      "repr_str": "model/activation_6/Relu;model/batch_normalization_6/FusedBatchNormV3;model/conv2d_3/BiasAdd/ReadVariableOp/resource;model/conv2d_3/BiasAdd;model/depthwise_conv2d_3/depthwise;model/conv2d_3/Conv2D1"
    }, 
    {
      "type_key": "relay.TensorType", 
      "attrs": {
        "dtype": "float32", 
        "shape": "66", 
        "span": "0"
      }
    }, 
    {
      "type_key": "Array", 
      "data": [67]
    }, 
    {
      "type_key": "IntImm", 
      "attrs": {
        "dtype": "int32", 
        "span": "0", 
        "value": "32"
      }
    }, 
    {
      "type_key": "relay.Constant", 
      "attrs": {
        "_checked_type_": "69", 
        "data": "13", 
        "span": "63", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "relay.TensorType", 
      "attrs": {
        "dtype": "float32", 
        "shape": "70", 
        "span": "0"
      }
    }, 
    {
      "type_key": "Array", 
      "data": [71]
    }, 
    {
      "type_key": "IntImm", 
      "attrs": {
        "dtype": "int32", 
        "span": "0", 
        "value": "32"
      }
    }, 
    {
      "type_key": "relay.Constant", 
      "attrs": {
        "_checked_type_": "75", 
        "data": "14", 
        "span": "73", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "Span", 
      "attrs": {
        "column": "0", 
        "end_column": "0", 
        "end_line": "0", 
        "line": "0", 
        "source_name": "74"
      }
    }, 
    {
      "type_key": "SourceName", 
      "repr_str": "model/activation_7/Relu;model/batch_normalization_7/FusedBatchNormV3;model/depthwise_conv2d_3/depthwise;model/depthwise_conv2d_3/BiasAdd;model/depthwise_conv2d_3/BiasAdd/ReadVariableOp/resource1"
    }, 
    {
      "type_key": "relay.TensorType", 
      "attrs": {
        "dtype": "float32", 
        "shape": "76", 
        "span": "0"
      }
    }, 
    {
      "type_key": "Array", 
      "data": [77]
    }, 
    {
      "type_key": "IntImm", 
      "attrs": {
        "dtype": "int32", 
        "span": "0", 
        "value": "32"
      }
    }, 
    {
      "type_key": "relay.Constant", 
      "attrs": {
        "_checked_type_": "79", 
        "data": "15", 
        "span": "73", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "relay.TensorType", 
      "attrs": {
        "dtype": "float32", 
        "shape": "80", 
        "span": "0"
      }
    }, 
    {
      "type_key": "Array", 
      "data": [77]
    }, 
    {
      "type_key": "relay.Constant", 
      "attrs": {
        "_checked_type_": "84", 
        "data": "16", 
        "span": "82", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "Span", 
      "attrs": {
        "column": "0", 
        "end_column": "0", 
        "end_line": "0", 
        "line": "0", 
        "source_name": "83"
      }
    }, 
    {
      "type_key": "SourceName", 
      "repr_str": "model/activation_8/Relu;model/batch_normalization_8/FusedBatchNormV3;model/conv2d_4/BiasAdd/ReadVariableOp/resource;model/conv2d_4/BiasAdd;model/depthwise_conv2d_5/depthwise;model/conv2d_4/Conv2D1"
    }, 
    {
      "type_key": "relay.TensorType", 
      "attrs": {
        "dtype": "float32", 
        "shape": "85", 
        "span": "0"
      }
    }, 
    {
      "type_key": "Array", 
      "data": [86]
    }, 
    {
      "type_key": "IntImm", 
      "attrs": {
        "dtype": "int32", 
        "span": "0", 
        "value": "64"
      }
    }, 
    {
      "type_key": "relay.Constant", 
      "attrs": {
        "_checked_type_": "88", 
        "data": "17", 
        "span": "82", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "relay.TensorType", 
      "attrs": {
        "dtype": "float32", 
        "shape": "89", 
        "span": "0"
      }
    }, 
    {
      "type_key": "Array", 
      "data": [90]
    }, 
    {
      "type_key": "IntImm", 
      "attrs": {
        "dtype": "int32", 
        "span": "0", 
        "value": "64"
      }
    }, 
    {
      "type_key": "relay.Constant", 
      "attrs": {
        "_checked_type_": "94", 
        "data": "18", 
        "span": "92", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "Span", 
      "attrs": {
        "column": "0", 
        "end_column": "0", 
        "end_line": "0", 
        "line": "0", 
        "source_name": "93"
      }
    }, 
    {
      "type_key": "SourceName", 
      "repr_str": "model/activation_9/Relu;model/batch_normalization_9/FusedBatchNormV3;model/depthwise_conv2d_4/depthwise;model/depthwise_conv2d_4/BiasAdd;model/depthwise_conv2d_5/depthwise;model/depthwise_conv2d_4/BiasAdd/ReadVariableOp/resource1"
    }, 
    {
      "type_key": "relay.TensorType", 
      "attrs": {
        "dtype": "float32", 
        "shape": "95", 
        "span": "0"
      }
    }, 
    {
      "type_key": "Array", 
      "data": [96]
    }, 
    {
      "type_key": "IntImm", 
      "attrs": {
        "dtype": "int32", 
        "span": "0", 
        "value": "64"
      }
    }, 
    {
      "type_key": "relay.Constant", 
      "attrs": {
        "_checked_type_": "98", 
        "data": "19", 
        "span": "92", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "relay.TensorType", 
      "attrs": {
        "dtype": "float32", 
        "shape": "99", 
        "span": "0"
      }
    }, 
    {
      "type_key": "Array", 
      "data": [96]
    }, 
    {
      "type_key": "relay.Constant", 
      "attrs": {
        "_checked_type_": "103", 
        "data": "20", 
        "span": "101", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "Span", 
      "attrs": {
        "column": "0", 
        "end_column": "0", 
        "end_line": "0", 
        "line": "0", 
        "source_name": "102"
      }
    }, 
    {
      "type_key": "SourceName", 
      "repr_str": "model/activation_10/Relu;model/batch_normalization_10/FusedBatchNormV3;model/conv2d_5/BiasAdd/ReadVariableOp/resource;model/conv2d_5/BiasAdd;model/depthwise_conv2d_5/depthwise;model/conv2d_5/Conv2D1"
    }, 
    {
      "type_key": "relay.TensorType", 
      "attrs": {
        "dtype": "float32", 
        "shape": "104", 
        "span": "0"
      }
    }, 
    {
      "type_key": "Array", 
      "data": [105]
    }, 
    {
      "type_key": "IntImm", 
      "attrs": {
        "dtype": "int32", 
        "span": "0", 
        "value": "64"
      }
    }, 
    {
      "type_key": "relay.Constant", 
      "attrs": {
        "_checked_type_": "107", 
        "data": "21", 
        "span": "101", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "relay.TensorType", 
      "attrs": {
        "dtype": "float32", 
        "shape": "108", 
        "span": "0"
      }
    }, 
    {
      "type_key": "Array", 
      "data": [109]
    }, 
    {
      "type_key": "IntImm", 
      "attrs": {
        "dtype": "int32", 
        "span": "0", 
        "value": "64"
      }
    }, 
    {
      "type_key": "relay.Constant", 
      "attrs": {
        "_checked_type_": "113", 
        "data": "22", 
        "span": "111", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "Span", 
      "attrs": {
        "column": "0", 
        "end_column": "0", 
        "end_line": "0", 
        "line": "0", 
        "source_name": "112"
      }
    }, 
    {
      "type_key": "SourceName", 
      "repr_str": "model/activation_11/Relu;model/batch_normalization_11/FusedBatchNormV3;model/depthwise_conv2d_5/depthwise;model/depthwise_conv2d_5/BiasAdd;model/depthwise_conv2d_5/BiasAdd/ReadVariableOp/resource1"
    }, 
    {
      "type_key": "relay.TensorType", 
      "attrs": {
        "dtype": "float32", 
        "shape": "114", 
        "span": "0"
      }
    }, 
    {
      "type_key": "Array", 
      "data": [115]
    }, 
    {
      "type_key": "IntImm", 
      "attrs": {
        "dtype": "int32", 
        "span": "0", 
        "value": "64"
      }
    }, 
    {
      "type_key": "relay.Constant", 
      "attrs": {
        "_checked_type_": "117", 
        "data": "23", 
        "span": "111", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "relay.TensorType", 
      "attrs": {
        "dtype": "float32", 
        "shape": "118", 
        "span": "0"
      }
    }, 
    {
      "type_key": "Array", 
      "data": [115]
    }, 
    {
      "type_key": "relay.Constant", 
      "attrs": {
        "_checked_type_": "122", 
        "data": "24", 
        "span": "120", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "Span", 
      "attrs": {
        "column": "0", 
        "end_column": "0", 
        "end_line": "0", 
        "line": "0", 
        "source_name": "121"
      }
    }, 
    {
      "type_key": "SourceName", 
      "repr_str": "model/activation_12/Relu;model/batch_normalization_12/FusedBatchNormV3;model/conv2d_6/BiasAdd/ReadVariableOp/resource;model/conv2d_6/BiasAdd;model/depthwise_conv2d_11/depthwise;model/conv2d_6/Conv2D1"
    }, 
    {
      "type_key": "relay.TensorType", 
      "attrs": {
        "dtype": "float32", 
        "shape": "123", 
        "span": "0"
      }
    }, 
    {
      "type_key": "Array", 
      "data": [124]
    }, 
    {
      "type_key": "IntImm", 
      "attrs": {
        "dtype": "int32", 
        "span": "0", 
        "value": "128"
      }
    }, 
    {
      "type_key": "relay.Constant", 
      "attrs": {
        "_checked_type_": "126", 
        "data": "25", 
        "span": "120", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "relay.TensorType", 
      "attrs": {
        "dtype": "float32", 
        "shape": "127", 
        "span": "0"
      }
    }, 
    {
      "type_key": "Array", 
      "data": [128]
    }, 
    {
      "type_key": "IntImm", 
      "attrs": {
        "dtype": "int32", 
        "span": "0", 
        "value": "128"
      }
    }, 
    {
      "type_key": "relay.Constant", 
      "attrs": {
        "_checked_type_": "132", 
        "data": "26", 
        "span": "130", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "Span", 
      "attrs": {
        "column": "0", 
        "end_column": "0", 
        "end_line": "0", 
        "line": "0", 
        "source_name": "131"
      }
    }, 
    {
      "type_key": "SourceName", 
      "repr_str": "model/activation_13/Relu;model/batch_normalization_13/FusedBatchNormV3;model/depthwise_conv2d_6/depthwise;model/depthwise_conv2d_6/BiasAdd;model/depthwise_conv2d_11/depthwise;model/depthwise_conv2d_6/BiasAdd/ReadVariableOp/resource1"
    }, 
    {
      "type_key": "relay.TensorType", 
      "attrs": {
        "dtype": "float32", 
        "shape": "133", 
        "span": "0"
      }
    }, 
    {
      "type_key": "Array", 
      "data": [134]
    }, 
    {
      "type_key": "IntImm", 
      "attrs": {
        "dtype": "int32", 
        "span": "0", 
        "value": "128"
      }
    }, 
    {
      "type_key": "relay.Constant", 
      "attrs": {
        "_checked_type_": "136", 
        "data": "27", 
        "span": "130", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "relay.TensorType", 
      "attrs": {
        "dtype": "float32", 
        "shape": "137", 
        "span": "0"
      }
    }, 
    {
      "type_key": "Array", 
      "data": [134]
    }, 
    {
      "type_key": "relay.Constant", 
      "attrs": {
        "_checked_type_": "141", 
        "data": "28", 
        "span": "139", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "Span", 
      "attrs": {
        "column": "0", 
        "end_column": "0", 
        "end_line": "0", 
        "line": "0", 
        "source_name": "140"
      }
    }, 
    {
      "type_key": "SourceName", 
      "repr_str": "model/activation_14/Relu;model/batch_normalization_14/FusedBatchNormV3;model/conv2d_7/BiasAdd/ReadVariableOp/resource;model/conv2d_7/BiasAdd;model/depthwise_conv2d_11/depthwise;model/conv2d_7/Conv2D1"
    }, 
    {
      "type_key": "relay.TensorType", 
      "attrs": {
        "dtype": "float32", 
        "shape": "142", 
        "span": "0"
      }
    }, 
    {
      "type_key": "Array", 
      "data": [143]
    }, 
    {
      "type_key": "IntImm", 
      "attrs": {
        "dtype": "int32", 
        "span": "0", 
        "value": "128"
      }
    }, 
    {
      "type_key": "relay.Constant", 
      "attrs": {
        "_checked_type_": "145", 
        "data": "29", 
        "span": "139", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "relay.TensorType", 
      "attrs": {
        "dtype": "float32", 
        "shape": "146", 
        "span": "0"
      }
    }, 
    {
      "type_key": "Array", 
      "data": [147]
    }, 
    {
      "type_key": "IntImm", 
      "attrs": {
        "dtype": "int32", 
        "span": "0", 
        "value": "128"
      }
    }, 
    {
      "type_key": "relay.Constant", 
      "attrs": {
        "_checked_type_": "151", 
        "data": "30", 
        "span": "149", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "Span", 
      "attrs": {
        "column": "0", 
        "end_column": "0", 
        "end_line": "0", 
        "line": "0", 
        "source_name": "150"
      }
    }, 
    {
      "type_key": "SourceName", 
      "repr_str": "model/activation_15/Relu;model/batch_normalization_15/FusedBatchNormV3;model/depthwise_conv2d_7/depthwise;model/depthwise_conv2d_7/BiasAdd;model/depthwise_conv2d_11/depthwise;model/depthwise_conv2d_7/BiasAdd/ReadVariableOp/resource1"
    }, 
    {
      "type_key": "relay.TensorType", 
      "attrs": {
        "dtype": "float32", 
        "shape": "152", 
        "span": "0"
      }
    }, 
    {
      "type_key": "Array", 
      "data": [153]
    }, 
    {
      "type_key": "IntImm", 
      "attrs": {
        "dtype": "int32", 
        "span": "0", 
        "value": "128"
      }
    }, 
    {
      "type_key": "relay.Constant", 
      "attrs": {
        "_checked_type_": "155", 
        "data": "31", 
        "span": "149", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "relay.TensorType", 
      "attrs": {
        "dtype": "float32", 
        "shape": "156", 
        "span": "0"
      }
    }, 
    {
      "type_key": "Array", 
      "data": [153]
    }, 
    {
      "type_key": "relay.Constant", 
      "attrs": {
        "_checked_type_": "160", 
        "data": "32", 
        "span": "158", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "Span", 
      "attrs": {
        "column": "0", 
        "end_column": "0", 
        "end_line": "0", 
        "line": "0", 
        "source_name": "159"
      }
    }, 
    {
      "type_key": "SourceName", 
      "repr_str": "model/activation_16/Relu;model/batch_normalization_16/FusedBatchNormV3;model/conv2d_8/BiasAdd/ReadVariableOp/resource;model/conv2d_8/BiasAdd;model/depthwise_conv2d_11/depthwise;model/conv2d_8/Conv2D1"
    }, 
    {
      "type_key": "relay.TensorType", 
      "attrs": {
        "dtype": "float32", 
        "shape": "161", 
        "span": "0"
      }
    }, 
    {
      "type_key": "Array", 
      "data": [162]
    }, 
    {
      "type_key": "IntImm", 
      "attrs": {
        "dtype": "int32", 
        "span": "0", 
        "value": "128"
      }
    }, 
    {
      "type_key": "relay.Constant", 
      "attrs": {
        "_checked_type_": "164", 
        "data": "33", 
        "span": "158", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "relay.TensorType", 
      "attrs": {
        "dtype": "float32", 
        "shape": "165", 
        "span": "0"
      }
    }, 
    {
      "type_key": "Array", 
      "data": [166]
    }, 
    {
      "type_key": "IntImm", 
      "attrs": {
        "dtype": "int32", 
        "span": "0", 
        "value": "128"
      }
    }, 
    {
      "type_key": "relay.Constant", 
      "attrs": {
        "_checked_type_": "170", 
        "data": "34", 
        "span": "168", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "Span", 
      "attrs": {
        "column": "0", 
        "end_column": "0", 
        "end_line": "0", 
        "line": "0", 
        "source_name": "169"
      }
    }, 
    {
      "type_key": "SourceName", 
      "repr_str": "model/activation_17/Relu;model/batch_normalization_17/FusedBatchNormV3;model/depthwise_conv2d_8/depthwise;model/depthwise_conv2d_8/BiasAdd;model/depthwise_conv2d_11/depthwise;model/depthwise_conv2d_8/BiasAdd/ReadVariableOp/resource1"
    }, 
    {
      "type_key": "relay.TensorType", 
      "attrs": {
        "dtype": "float32", 
        "shape": "171", 
        "span": "0"
      }
    }, 
    {
      "type_key": "Array", 
      "data": [172]
    }, 
    {
      "type_key": "IntImm", 
      "attrs": {
        "dtype": "int32", 
        "span": "0", 
        "value": "128"
      }
    }, 
    {
      "type_key": "relay.Constant", 
      "attrs": {
        "_checked_type_": "174", 
        "data": "35", 
        "span": "168", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "relay.TensorType", 
      "attrs": {
        "dtype": "float32", 
        "shape": "175", 
        "span": "0"
      }
    }, 
    {
      "type_key": "Array", 
      "data": [172]
    }, 
    {
      "type_key": "relay.Constant", 
      "attrs": {
        "_checked_type_": "179", 
        "data": "36", 
        "span": "177", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "Span", 
      "attrs": {
        "column": "0", 
        "end_column": "0", 
        "end_line": "0", 
        "line": "0", 
        "source_name": "178"
      }
    }, 
    {
      "type_key": "SourceName", 
      "repr_str": "model/activation_18/Relu;model/batch_normalization_18/FusedBatchNormV3;model/conv2d_9/BiasAdd/ReadVariableOp/resource;model/conv2d_9/BiasAdd;model/depthwise_conv2d_11/depthwise;model/conv2d_9/Conv2D1"
    }, 
    {
      "type_key": "relay.TensorType", 
      "attrs": {
        "dtype": "float32", 
        "shape": "180", 
        "span": "0"
      }
    }, 
    {
      "type_key": "Array", 
      "data": [181]
    }, 
    {
      "type_key": "IntImm", 
      "attrs": {
        "dtype": "int32", 
        "span": "0", 
        "value": "128"
      }
    }, 
    {
      "type_key": "relay.Constant", 
      "attrs": {
        "_checked_type_": "183", 
        "data": "37", 
        "span": "177", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "relay.TensorType", 
      "attrs": {
        "dtype": "float32", 
        "shape": "184", 
        "span": "0"
      }
    }, 
    {
      "type_key": "Array", 
      "data": [185]
    }, 
    {
      "type_key": "IntImm", 
      "attrs": {
        "dtype": "int32", 
        "span": "0", 
        "value": "128"
      }
    }, 
    {
      "type_key": "relay.Constant", 
      "attrs": {
        "_checked_type_": "189", 
        "data": "38", 
        "span": "187", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "Span", 
      "attrs": {
        "column": "0", 
        "end_column": "0", 
        "end_line": "0", 
        "line": "0", 
        "source_name": "188"
      }
    }, 
    {
      "type_key": "SourceName", 
      "repr_str": "model/activation_19/Relu;model/batch_normalization_19/FusedBatchNormV3;model/depthwise_conv2d_9/depthwise;model/depthwise_conv2d_9/BiasAdd;model/depthwise_conv2d_11/depthwise;model/depthwise_conv2d_9/BiasAdd/ReadVariableOp/resource1"
    }, 
    {
      "type_key": "relay.TensorType", 
      "attrs": {
        "dtype": "float32", 
        "shape": "190", 
        "span": "0"
      }
    }, 
    {
      "type_key": "Array", 
      "data": [191]
    }, 
    {
      "type_key": "IntImm", 
      "attrs": {
        "dtype": "int32", 
        "span": "0", 
        "value": "128"
      }
    }, 
    {
      "type_key": "relay.Constant", 
      "attrs": {
        "_checked_type_": "193", 
        "data": "39", 
        "span": "187", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "relay.TensorType", 
      "attrs": {
        "dtype": "float32", 
        "shape": "194", 
        "span": "0"
      }
    }, 
    {
      "type_key": "Array", 
      "data": [191]
    }, 
    {
      "type_key": "relay.Constant", 
      "attrs": {
        "_checked_type_": "198", 
        "data": "40", 
        "span": "196", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "Span", 
      "attrs": {
        "column": "0", 
        "end_column": "0", 
        "end_line": "0", 
        "line": "0", 
        "source_name": "197"
      }
    }, 
    {
      "type_key": "SourceName", 
      "repr_str": "model/activation_20/Relu;model/batch_normalization_20/FusedBatchNormV3;model/conv2d_10/BiasAdd/ReadVariableOp/resource;model/conv2d_10/BiasAdd;model/depthwise_conv2d_11/depthwise;model/conv2d_10/Conv2D1"
    }, 
    {
      "type_key": "relay.TensorType", 
      "attrs": {
        "dtype": "float32", 
        "shape": "199", 
        "span": "0"
      }
    }, 
    {
      "type_key": "Array", 
      "data": [200]
    }, 
    {
      "type_key": "IntImm", 
      "attrs": {
        "dtype": "int32", 
        "span": "0", 
        "value": "128"
      }
    }, 
    {
      "type_key": "relay.Constant", 
      "attrs": {
        "_checked_type_": "202", 
        "data": "41", 
        "span": "196", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "relay.TensorType", 
      "attrs": {
        "dtype": "float32", 
        "shape": "203", 
        "span": "0"
      }
    }, 
    {
      "type_key": "Array", 
      "data": [204]
    }, 
    {
      "type_key": "IntImm", 
      "attrs": {
        "dtype": "int32", 
        "span": "0", 
        "value": "128"
      }
    }, 
    {
      "type_key": "relay.Constant", 
      "attrs": {
        "_checked_type_": "208", 
        "data": "42", 
        "span": "206", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "Span", 
      "attrs": {
        "column": "0", 
        "end_column": "0", 
        "end_line": "0", 
        "line": "0", 
        "source_name": "207"
      }
    }, 
    {
      "type_key": "SourceName", 
      "repr_str": "model/activation_21/Relu;model/batch_normalization_21/FusedBatchNormV3;model/depthwise_conv2d_10/depthwise;model/depthwise_conv2d_10/BiasAdd;model/depthwise_conv2d_11/depthwise;model/depthwise_conv2d_10/BiasAdd/ReadVariableOp/resource1"
    }, 
    {
      "type_key": "relay.TensorType", 
      "attrs": {
        "dtype": "float32", 
        "shape": "209", 
        "span": "0"
      }
    }, 
    {
      "type_key": "Array", 
      "data": [210]
    }, 
    {
      "type_key": "IntImm", 
      "attrs": {
        "dtype": "int32", 
        "span": "0", 
        "value": "128"
      }
    }, 
    {
      "type_key": "relay.Constant", 
      "attrs": {
        "_checked_type_": "212", 
        "data": "43", 
        "span": "206", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "relay.TensorType", 
      "attrs": {
        "dtype": "float32", 
        "shape": "213", 
        "span": "0"
      }
    }, 
    {
      "type_key": "Array", 
      "data": [210]
    }, 
    {
      "type_key": "relay.Constant", 
      "attrs": {
        "_checked_type_": "217", 
        "data": "44", 
        "span": "215", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "Span", 
      "attrs": {
        "column": "0", 
        "end_column": "0", 
        "end_line": "0", 
        "line": "0", 
        "source_name": "216"
      }
    }, 
    {
      "type_key": "SourceName", 
      "repr_str": "model/activation_22/Relu;model/batch_normalization_22/FusedBatchNormV3;model/conv2d_11/BiasAdd/ReadVariableOp/resource;model/conv2d_11/BiasAdd;model/depthwise_conv2d_11/depthwise;model/conv2d_11/Conv2D1"
    }, 
    {
      "type_key": "relay.TensorType", 
      "attrs": {
        "dtype": "float32", 
        "shape": "218", 
        "span": "0"
      }
    }, 
    {
      "type_key": "Array", 
      "data": [219]
    }, 
    {
      "type_key": "IntImm", 
      "attrs": {
        "dtype": "int32", 
        "span": "0", 
        "value": "128"
      }
    }, 
    {
      "type_key": "relay.Constant", 
      "attrs": {
        "_checked_type_": "221", 
        "data": "45", 
        "span": "215", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "relay.TensorType", 
      "attrs": {
        "dtype": "float32", 
        "shape": "222", 
        "span": "0"
      }
    }, 
    {
      "type_key": "Array", 
      "data": [223]
    }, 
    {
      "type_key": "IntImm", 
      "attrs": {
        "dtype": "int32", 
        "span": "0", 
        "value": "128"
      }
    }, 
    {
      "type_key": "relay.Constant", 
      "attrs": {
        "_checked_type_": "227", 
        "data": "46", 
        "span": "225", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "Span", 
      "attrs": {
        "column": "0", 
        "end_column": "0", 
        "end_line": "0", 
        "line": "0", 
        "source_name": "226"
      }
    }, 
    {
      "type_key": "SourceName", 
      "repr_str": "model/activation_23/Relu;model/batch_normalization_23/FusedBatchNormV3;model/depthwise_conv2d_11/depthwise;model/depthwise_conv2d_11/BiasAdd;model/depthwise_conv2d_11/BiasAdd/ReadVariableOp/resource1"
    }, 
    {
      "type_key": "relay.TensorType", 
      "attrs": {
        "dtype": "float32", 
        "shape": "228", 
        "span": "0"
      }
    }, 
    {
      "type_key": "Array", 
      "data": [229]
    }, 
    {
      "type_key": "IntImm", 
      "attrs": {
        "dtype": "int32", 
        "span": "0", 
        "value": "128"
      }
    }, 
    {
      "type_key": "relay.Constant", 
      "attrs": {
        "_checked_type_": "231", 
        "data": "47", 
        "span": "225", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "relay.TensorType", 
      "attrs": {
        "dtype": "float32", 
        "shape": "232", 
        "span": "0"
      }
    }, 
    {
      "type_key": "Array", 
      "data": [229]
    }, 
    {
      "type_key": "relay.Constant", 
      "attrs": {
        "_checked_type_": "236", 
        "data": "48", 
        "span": "234", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "Span", 
      "attrs": {
        "column": "0", 
        "end_column": "0", 
        "end_line": "0", 
        "line": "0", 
        "source_name": "235"
      }
    }, 
    {
      "type_key": "SourceName", 
      "repr_str": "model/activation_24/Relu;model/batch_normalization_24/FusedBatchNormV3;model/conv2d_12/BiasAdd/ReadVariableOp/resource;model/conv2d_12/BiasAdd;model/conv2d_13/Conv2D;model/conv2d_12/Conv2D1"
    }, 
    {
      "type_key": "relay.TensorType", 
      "attrs": {
        "dtype": "float32", 
        "shape": "237", 
        "span": "0"
      }
    }, 
    {
      "type_key": "Array", 
      "data": [238]
    }, 
    {
      "type_key": "IntImm", 
      "attrs": {
        "dtype": "int32", 
        "span": "0", 
        "value": "256"
      }
    }, 
    {
      "type_key": "relay.Constant", 
      "attrs": {
        "_checked_type_": "240", 
        "data": "49", 
        "span": "234", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "relay.TensorType", 
      "attrs": {
        "dtype": "float32", 
        "shape": "241", 
        "span": "0"
      }
    }, 
    {
      "type_key": "Array", 
      "data": [242]
    }, 
    {
      "type_key": "IntImm", 
      "attrs": {
        "dtype": "int32", 
        "span": "0", 
        "value": "256"
      }
    }, 
    {
      "type_key": "relay.Constant", 
      "attrs": {
        "_checked_type_": "246", 
        "data": "50", 
        "span": "244", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "Span", 
      "attrs": {
        "column": "0", 
        "end_column": "0", 
        "end_line": "0", 
        "line": "0", 
        "source_name": "245"
      }
    }, 
    {
      "type_key": "SourceName", 
      "repr_str": "model/activation_25/Relu;model/batch_normalization_25/FusedBatchNormV3;model/depthwise_conv2d_12/depthwise;model/depthwise_conv2d_12/BiasAdd;model/conv2d_13/Conv2D;model/depthwise_conv2d_12/BiasAdd/ReadVariableOp/resource1"
    }, 
    {
      "type_key": "relay.TensorType", 
      "attrs": {
        "dtype": "float32", 
        "shape": "247", 
        "span": "0"
      }
    }, 
    {
      "type_key": "Array", 
      "data": [248]
    }, 
    {
      "type_key": "IntImm", 
      "attrs": {
        "dtype": "int32", 
        "span": "0", 
        "value": "256"
      }
    }, 
    {
      "type_key": "relay.Constant", 
      "attrs": {
        "_checked_type_": "250", 
        "data": "51", 
        "span": "244", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "relay.TensorType", 
      "attrs": {
        "dtype": "float32", 
        "shape": "251", 
        "span": "0"
      }
    }, 
    {
      "type_key": "Array", 
      "data": [248]
    }, 
    {
      "type_key": "relay.Constant", 
      "attrs": {
        "_checked_type_": "255", 
        "data": "52", 
        "span": "253", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "Span", 
      "attrs": {
        "column": "0", 
        "end_column": "0", 
        "end_line": "0", 
        "line": "0", 
        "source_name": "254"
      }
    }, 
    {
      "type_key": "SourceName", 
      "repr_str": "model/activation_26/Relu;model/batch_normalization_26/FusedBatchNormV3;model/conv2d_13/BiasAdd/ReadVariableOp/resource;model/conv2d_13/BiasAdd;model/conv2d_13/Conv2D1"
    }, 
    {
      "type_key": "relay.TensorType", 
      "attrs": {
        "dtype": "float32", 
        "shape": "256", 
        "span": "0"
      }
    }, 
    {
      "type_key": "Array", 
      "data": [257]
    }, 
    {
      "type_key": "IntImm", 
      "attrs": {
        "dtype": "int32", 
        "span": "0", 
        "value": "256"
      }
    }, 
    {
      "type_key": "relay.Constant", 
      "attrs": {
        "_checked_type_": "259", 
        "data": "53", 
        "span": "253", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "relay.TensorType", 
      "attrs": {
        "dtype": "float32", 
        "shape": "260", 
        "span": "0"
      }
    }, 
    {
      "type_key": "Array", 
      "data": [261]
    }, 
    {
      "type_key": "IntImm", 
      "attrs": {
        "dtype": "int32", 
        "span": "0", 
        "value": "256"
      }
    }
  ], 
  "b64ndarrays": [
    "P6G0lvBAXt0AAAAAAAAAAAEAAAAAAAAAAQAAAAIgAQAIAAAAAAAAACAAAAAAAAAAkCaGPI9tPjy4Vzk855ZfPIHK4zts8ik7Ws8YPCDddzs=", 
    "P6G0lvBAXt0AAAAAAAAAAAEAAAAAAAAAAQAAAAIgAQAIAAAAAAAAACAAAAAAAAAAPq2GOLwsPzjLETo4X3dgODGv5DcKnSo3w2gZOPfVeDc=", 
    "P6G0lvBAXt0AAAAAAAAAAAEAAAAAAAAAAQAAAAIgAQAIAAAAAAAAACAAAAAAAAAA+/oqPHeMbzzDDPA7NZmePGL1cTyKXGU9vh2kPDYOkzw=", 
    "P6G0lvBAXt0AAAAAAAAAAAEAAAAAAAAAAQAAAAIgAQAIAAAAAAAAACAAAAAAAAAAD9AjOa+BZTma/OU4KvOXOb7QZzkWv1s6fDydOQzkjDk=", 
    "P6G0lvBAXt0AAAAAAAAAAAEAAAAAAAAAAQAAAAIgAQAQAAAAAAAAAEAAAAAAAAAAfVsSPCpFAjxFNaw70uEtO24oBDu8cWE7voLvO6vTGTx5SS47DtZMO1OeezsEi3A7Xz0UPGQCVjv/Cuw71eMLPA==", 
    "P6G0lvBAXt0AAAAAAAAAAAEAAAAAAAAAAQAAAAIgAQAQAAAAAAAAAEAAAAAAAAAAz57iOfq1yTnnUoU5sJ4GOUWizDgXii45/225OaIv7jnw7gY5pZUeObPNQjmZOjo59YjlObyvJTmzvrY5L5vYOQ==", 
    "P6G0lvBAXt0AAAAAAAAAAAEAAAAAAAAAAQAAAAIgAQAQAAAAAAAAAEAAAAAAAAAAMAI2O67CWDuu9bo7Ec3qO/GNWzyTFjU8e6x7O+9eoTuuAw886FfPOytmiTzbaPE7ff9GOyx72Tsh4087rtyAOw==", 
    "P6G0lvBAXt0AAAAAAAAAAAEAAAAAAAAAAQAAAAIgAQAQAAAAAAAAAEAAAAAAAAAA7snGOKK+7DhHMkw5aDmAOdbL7zmYyMU5OnAJOZY/MDkWM5w5mXViOQsRFjpJ1YM5NljZOCKIbTmoDeM4EL4MOQ==", 
    "P6G0lvBAXt0AAAAAAAAAAAEAAAAAAAAAAQAAAAIgAQAgAAAAAAAAAIAAAAAAAAAAXsxfO4BP3zq4NcE7eD29OxqrZTsSmxQ7knmGO8lJvjuesJk7czuzO/u3nzsaxq87sfwjPK6snTvd7/U7IFlcO0j0izvNqxs7a3vGO93BhDutRGA7nk6hO8uYHDsxsow7atcQPC93Bzu2zoE7h20dO3QOujtaXQE8jjv8O2ilmjs=", 
    "P6G0lvBAXt0AAAAAAAAAAAEAAAAAAAAAAQAAAAIgAQAgAAAAAAAAAIAAAAAAAAAAWWTaOIDqWTjeijw5K6s4Ocge4DgPBJE48zkDOQCxOTkq+hU5CucuOT/cGzkUhys5jwagOZbdGTnv/m85cgbXOMaSCDkZ6Zc49q9BOd2MATnA2do4D2kdOV3QmDgZTAk5r1eNOW8xhDjoV/049p+ZONePNTmqenw5sSN2OQrpFjk=", 
    "P6G0lvBAXt0AAAAAAAAAAAEAAAAAAAAAAQAAAAIgAQAgAAAAAAAAAIAAAAAAAAAAb8QSPEgZ3Tz+DNk7j0mlO7dcvTsbT1w8mrRQPGbpMjxHBCA8SuiwOxnYIjxMZwA878sFPJHVMzwlDUc8b1i3O5iSUDxNRyo8SG4lPGzQOzw3v9E8j+/kO2xiSzy8MVY8TLwBPGjeiTxYDOs7f8YHPFx9GjwAwOI7f/QSPOGHujs=", 
    "P6G0lvBAXt0AAAAAAAAAAAEAAAAAAAAAAQAAAAIgAQAgAAAAAAAAAIAAAAAAAAAAlSGYOd8tZTq2+2A5+1MrOWFIRDlPXOQ5PlXYOUpzuTlj3aU5bV83OanLqDmiGIU5u6+KORZoujl2U845zgs+Of4x2DlrgLA5C3qrOZqtwjmZaVk6eU1tOUfR0jm6Bd45GXqGOU3oDjpyo3M5zryMOcIioDl3CWs5Z1OYOQ5ZQTk=", 
    "P6G0lvBAXt0AAAAAAAAAAAEAAAAAAAAAAQAAAAIgAQAgAAAAAAAAAIAAAAAAAAAAojtPO6pt/DvBnQ07s4qBO8bJLDv7+EA7KkFRO6qpCzzgRnw7xQkOO9eRojtonXY7gPyjOy3phju4W/Y7jPsbPBnIgTs6eEA7T6BhOzD7oDt/wW07ZC1AO5Fo3TthGoU7SoBoO0/3lTuuzmY7reS0O4V+oTvNrBE87rMFPGW6ljs=", 
    "P6G0lvBAXt0AAAAAAAAAAAEAAAAAAAAAAQAAAAIgAQAgAAAAAAAAAIAAAAAAAAAAzLsFOUnmojlBx7Y4wTEnOb4C3zjZD/k4xwkHOc9BtDlBzSI5qlK3OHbSUTneJR85iKZTObwfLjl6+545CFLJOQCBJzmrafg4cpoROZ3FTzlRbhk5FQn4OKjhjjlsyis5NwoWORyOQTll8hQ5vHhpOR5vUDlPBLw5m5CsOeaJQjk=", 
    "P6G0lvBAXt0AAAAAAAAAAAEAAAAAAAAAAQAAAAIgAQAgAAAAAAAAAIAAAAAAAAAAzsg5PDSVeDs8izo8YJOMOxyUHjxTqNU7yP+HO1LsezsOSpM7OzRDPNbGYTv81PY7L/VyO8UboDsOp4Q7cvuAO5oZnjtqNRM88J+zO5lLYTvgkGs7W9OiO0fMdjsN6BU7ypiGO3AhmjuXBGU7Pp0gOxypsjs/NPw6b08gOz9u4zs=", 
    "P6G0lvBAXt0AAAAAAAAAAAEAAAAAAAAAAQAAAAIgAQAgAAAAAAAAAIAAAAAAAAAAHr3zOToQIzkzvPQ5bW04OdQL0DlDJ4w5XGwyOSlBJTk9PEE5YwwAOmwaFDk16qE5nV8fOaoNUjliCC45qzcpORtrTzkoIcE5W6hrOZXJEzlQhho5PJ5VOX/kITk8q8Q4YpUwOfQ1Sjm4OhY5hrfSOIhkajlXcKU4clHSOCswlTk=", 
    "P6G0lvBAXt0AAAAAAAAAAAEAAAAAAAAAAQAAAAIgAQBAAAAAAAAAAAABAAAAAAAAOXT+OlacTTv/bzw7Lp6HO3AGJjtNcQc7o9I8O142uTtW8WQ7aUcPO5pY3TtIJXA7eRMgOwM0EDuY/yo7AV+rOzB8gjvZFes7nuByO0bvizsvpz07o5WTO4TgCjuSs1I7FUHCO3AdZDtjwqg7S5aZOwDalDth5XY7wrzWO2ycjDvwqKs7cbtoO4qmvDtcaAw7dQZQO1LaFDupFzs7XH5fO6240zstJzE73yGpOxFdhzsH3NU7dBEPPIO+STvhHLc7gamjOxts1ztig4Q7/ascOxlzaDsXOWw7OCpIO4djXDuF8ME7CCyPO49vMjuxuOU6gcxjO25ydjuC1W87NnuKOw==", 
    "P6G0lvBAXt0AAAAAAAAAAAEAAAAAAAAAAQAAAAIgAQBAAAAAAAAAAAABAAAAAAAA0exoON02vDh+fqw4d0n4OGH6lzhN93c4ydisOLiKKTmAktE4ByiDOE6eSjnL09s4RYiSOJwAhDjRh5w4J98cOdXj7jj2MVc59VPeOFQYADlam604/xgHOfRAfjjW38A4l9ExOYfQ0Dgbexo5o5cMOepBCDmuAeI4m5FEOdO2ADnVIh05hgrVOGuwLDkrh4A4sGy+ODVCiDhKQ6s4jJXMONnOQTkXKqI4g9IaOULS9zjkw0M5o/aCOcqsuDi1nic5oNAVOR4yRTldmvI4hWqPOE3I1DiQPNg4szq3OPe9yTjYhzE59w4DObBWozj9SFI4cYbQOHSY4TjFits4fYf9OA==", 
    "P6G0lvBAXt0AAAAAAAAAAAEAAAAAAAAAAQAAAAIgAQBAAAAAAAAAAAABAAAAAAAALNGVPFHbzDudjPY7o0+nO6WyhzwTy1g8mkgVPCrHeDtFk607tl1CPP48HTy5e+87LGOtO/qgJDxBkDI8iRoQPNbVAjw0NFg7xLkTPNVXIjzliQY8pAr6O1bjNjxenAE8/t/EO/Z46TuzTKw7/CXhO35mnzvd7ys8w7o5O6H0qjsgi747cAUKPLzpqjs70GM8pbkkPGWHODzD1gA8cow3PMJ/zjtvWfo7TpzGO9frbzul+ZU7hQKBO0a0HjzbrEM7z/a3O01/uDsycf077tgFPN/dCDx+Cwg8f2jHOyNBFTyrue07C48ePOAG7DuP2As8LZP3O2btEDyuM0M8WfwGPA==", 
    "P6G0lvBAXt0AAAAAAAAAAAEAAAAAAAAAAQAAAAIgAQBAAAAAAAAAAAABAAAAAAAAZLYVOrK2TDmKYHY5ujEnOWOaBzpRpNg56i2VObGa+Dg9dC059zrCOeIgnTnpUG85LUQtOYyDpDlVcLI5xgCQOXK+gjmNDdg4W5+TOc86ojnYcYY58d15OaTCtjkyhYE5zLxEOTlPaTnmLSw5vP1gOf9JHzkg0as5j5m5OBHWKjkQaT45w+yJOS7LKjmBp+M5MpykOWhmuDm7v4A5omu3OddaTjmuLHo5zHhGOfPA7zjV3hU5desAOeeXnjngicM47NU3OVFeODnjQ305AMGFOWfFiDks84c52URHOXQmlTkrj205snKeOa7cazmPv4s562Z3OX3TkDnIEMM5N+SGOQ==", 
    "P6G0lvBAXt0AAAAAAAAAAAEAAAAAAAAAAQAAAAIgAQBAAAAAAAAAAAABAAAAAAAAGLwyOwnUWjtdGjQ7evWTMcQsWDtcJSY7cRNkOyiQhzufUYI7qnTzOsoY7Dtw1aY7884vMtk2AzINXos7UiE2O3lerjt1pK07uQ+nO8bChDvnbNM6FXWEO2VnWDuW+kM7F2l2O3x2cTt2yTE7lyyBO/13BDsuJ387jLovO7o4ujrnXRI71wKFO3f7oDvFIp47MjgHO9wgNjv/btk6tuueO5DdXjutFUw7/qWFO/8WuzsVn8E7HqC/O8TtOzvTnEIyOXjOOnaZpjoT8TA7ntiIOxatxTtvjl07YBYyO5AbWDvnlx87GLgRO4iYtjvF7SE7AS4DO5jehTtOKig7EOYJOw==", 
    "P6G0lvBAXt0AAAAAAAAAAAEAAAAAAAAAAQAAAAIgAQBAAAAAAAAAAAABAAAAAAAAJ4W0OJ8D3Tjs5rU41m8VL5FV2jg6zqc4rVrmONHqCDnfngM5OuN1OIl0bjkQgCg5hpCxL2OGhC9xwgw5EPO3OF4cMDl+YC857rooOUUWBjmPiVU4zccFOciQ2ji+78U4Nd/4OPPf8zgZkLM46nYCObzKhTjU2QA563uxOO4UPDgx1JM4+VYGOSGXIjkntx85+pGIOJnytzgEm1s4GoIgOXkX4TiPH844wvsGOWz1PDk1jkM5JIpBOVbOvTh8jsQvNIhQOH1DKDiMtbI4jzYKOZWmRzn/xN84x92zODFE2jgDMKE4uiyTOHdrODnai6M4dX2EOOw0BzlW2Kk4skaLOA==", 
    "P6G0lvBAXt0AAAAAAAAAAAEAAAAAAAAAAQAAAAIgAQBAAAAAAAAAAAABAAAAAAAAoGy6O8YKhDsHOXs7bzjqPB+ElztU4JE7Nry5OydRjjsRzdY76Q01PAUaSTvjWHE71Nu/PFIC6jxRDFU7LVKsO/+HVjsEWVM74aoaO2pFdjuMS9A8xynGO9pH1DuQkt87c/iZO4/RozusDYo7w9WZO2VsBDyBX3Q7D1bGO+LcGDww0Rg8sC6dOwXhgjugeFs7m74kPEVMHjxpDLo7VEmUOzvYqjvg98o7Kjh/O4iWkDv+XUk7zbFqOw6GoTv/4aY9JZ0VPOWH4TwuD947kquaO0Xoijuyu8I7DmWqO6KHgTtBnAA8zkLqO9fuBzu7DJU71jPlO8WtWDtkYp47mt/kOw==", 
    "P6G0lvBAXt0AAAAAAAAAAAEAAAAAAAAAAQAAAAIgAQBAAAAAAAAAAAABAAAAAAAAgvAwOfCl+jjvcO44yk1eOqzODzlWdAo5EkkwOYUTBzla30s5vderOb3evjhrEeU47hg2Om4aXjpvNco4wI0jOcydyzhImMg4Y8ySONC96TiSskU6xBQ8Ofd6STmbMlQ5CSMSOeB7GzmSBwM5HAISOT9fezmg8Oc4yz48OeUVkTnLCpE5cC8VObpw+DgWTtA43VycOX4+ljkxlTA58r0MOQknIjlIpEA5BDzyOFI7CTlAH784+8DeOENOGTlnZB47eQCOOW4OVjruwlI5C80SOQzXAzlc0zg5uLkhORnh9ThLInQ5oldeOVsEgThodw05jIpZOZmnzTh9UxY5mjpZOQ==", 
    "P6G0lvBAXt0AAAAAAAAAAAEAAAAAAAAAAQAAAAIgAQCAAAAAAAAAAAACAAAAAAAAu43uOjRxNDsvr8E6TnAqO/rsADsoQAk7jFuAOzHnCDsNZyk7XvF0Owl9SDtz01I7+0X7Og0eHztYB3M77foYOx3DbTusJUIxIKNFO3QEnjGpS5w5XSjWOjF/FjvEQRIwlJRNOzFxaTCn7Hw7HAteO7DWkjvm6oE7y5WSMDcNGTvJtuE7336jO6u6BDvEwgA7SCAsOyBZhzvtEAI7iTNsO0YElzuROhE7NOAhO1QGRjvpfegxDeU4MQ/GJzvf/yg7kCyLO7uilzvsipI7qpYxO926UDum/gAwqttiO3e/XTtoeEo7NO3IMccYPDuelL0xJbPJOiXSzzvyINc6HVIYO9I3NDujc9E6Ifo1O9fz1zDb8+cwHs5bOsm8kzsq8sM6RST8Md77gzoTG0Y7CnRQOwEWmjvbHr46P1PLMI9U+js7Me46z6GIO7oskDrqGEs7RLpyO31V+Tr7hiw7206KMYFXgjtwbUk7FDrTOzQKRzuAVNs6GKNYO0R5GTGIB1A7qNEOOz1NdzG95mgxK+k7O3BrPTsARLI7Y0JHO4iMpzGFRN8xFe80O6cnHTuznkU71XxgO4IsUzuiBewxRnorO5a+WTvWLzI76dRGOytVxTqbKws7lccAOww8lztuvhQ7qTwcO28uDTrYsmI7EKz7OioiFjvlysg69iHOOhkE7zo=", 
    "P6G0lvBAXt0AAAAAAAAAAAEAAAAAAAAAAQAAAAIgAQCAAAAAAAAAAAACAAAAAAAAKol3OH88uzgf+kg4LduwOLPHhTgga444yzAFOc8Ojjjvx684Yyr+OI8J0Diew9o4A16COMsbpTjqLfw4g72eOOu29jgSdckuKhTNOJj3Iy80LiI3pTheONcpnDiMw5ctLlLVOFs78i1OOQM5Z2fmOBNeGDkvzwY5vRoYLn3Qnjh1Nmo50aYpOQ66iTjmm4U4a5uyOMFxDDmk9oY4TBj1OO+zHDlwspY4ifinOBp7zTjqPnEvRNu/Lj4XrjjeXK84EmoQOVtYHTl1Dxg5dEa4ONOW2DgK2oUtXWbrOOgY5jgIGNI4831QL9stwzj/t0QvWEtROFilVzmWOl84WA6eOPQAuziOVlk4ONS8OGwVYC6qr3Au1hTkN9ZMGTnnUks4V9GCLxL0CDihkM04Vk3YOEDjHzlxR0U4HftSLsHggTkvKXc40MYNOXCaFTiVvtI47937OGtcgTj8BbM4BIQPL+E/BzkDA9E4HC5bOcOIzjijlmM4RsvgOJxAny6+3Nc4TDKUOIBOAC+xq/EudPzCOESNxDhR+jg5EMPOOIzbLS+drGcvHr+7OHsSoziSD804r/DoOAcg2ziq6HQvKO+xOHHx4Thk5bg4dlHOOEXDTDgUaZA45qCFOM/tHDkvWJo4pB6iOEp/kjcCPOs4+ZKCOFDJmzhZWlA44+RVOP0DeDg=", 
    "P6G0lvBAXt0AAAAAAAAAAAEAAAAAAAAAAQAAAAIgAQCAAAAAAAAAAAACAAAAAAAAIIHzO9Ikzzul6088QfSnOxb3CTyA++k7H5EAPGUfJDyJH8g78i6sO5CobzwW1kc84XouPCvW2jv0YQU8D3bNO3ibKTz9VeE8wZvzO9DLlj1WG008lNLzOz1ybDzIbyg9gw3uOxLe/TyAfq47qzPJO4uVmTv6hTA8sDJwPXbWDDynttw79ZulO2u5EDxbZQ48DcSNO8ooxjsTgJs7CNvoO7fOpzu3oak70wECPLUfqjuTZIQ9OdFYPUXzEDwreDA88/bUO6ne3zsmxfM73NnfO8HDlTuIFgo9TJPQO/sW3TuYzp47ARhnPaKWFjxxqTw9D4AKPFjF9zsqCgs88L/jOx/9BjwvLzk7bh3TO50+Nz3U3G49Iat9PBdQtjsH4DQ80AecPbFukTxm6b475V0MPC5B1zvGJEk8LW5ePfF1xTuqXAg8+4/YO4oDVDyjrSA8qRs7PH8QIDx9vSw8D4ZXPRWbJjylO7g73oOCO6igvzt0pDI88lVpO4EwQj2TNdg7jU3/O1Aphj0Esho936lePG7XNjyLtIc7Hk+1O3GiFz2oRBM9q/6lOw2P8ztZIx08AiQqPJrYBzwJHno9qXzOO1rDxDvR45w7cecaPH+sLTycA5Y7H6PGO9VkHDzqdws8y5ZZPPUaiTvsqeo7QgYKPHXsFjwYGIM8OU5QPPsfiTs=", 
    "P6G0lvBAXt0AAAAAAAAAAAEAAAAAAAAAAQAAAAIgAQCAAAAAAAAAAAACAAAAAAAAhIxuOaTtSjlrsMs5P4kkOVAohzl/OGU5oOZ7OVnIoDnvDEQ5560oOf3H6jn6xMM53+2qORJiVjkOq4I5pUdJOdknpjkIwFw6mqZuOTK6EzvF7sg5T9xuOWai5zlCAqU6TTVpOXizeDpr8So5chtFOWZ1FjlT7qw5TU/rOrn4iTnHOFg5Kj0iOW/HjTmAf4s5euEKOWsgQjnzVRg55h1kOXhkJDn3LSY5Brl+OWWpJjnVsgE7pWfUOhsAjjnM4Kw5cqFQOVdQWzknz245o0tbOYK3EjkfR4c6qVRMOSWXWDk9kxs5DWTiOhmGkzmN0rg6gK6HOYG6cjnLNYg5aB1fOds9hDlparU4kNFOOfKDszpmAOo6kYH4OUaaMjm0MbE57NoYOwR5DjrJBjs5nIKJOb/fUjnbDMU5W+fZOjVxQTk/loU5uydUOf2yzzmJaJ053Uy3OZfOnDmMOak5OSPTOhk3oznTezQ50bf/OFC6OznDAa85UJbkONA8vjoqz1M5eRt6OVxuAzsVjJc61iHaOdweszmL8QQ5iJ4xOXSMlDprRZA63p0iOSiabjmw8Jk5nK2mOd8UhTn5BvU650hKOUHCQDlzshk5bMCXObAjqjkR9hI5QphCOQ02mTlPoYg5MinVOapQBjle42U5LTeHOSzakzkebQA6/hDMOZZVBjk=", 
    "P6G0lvBAXt0AAAAAAAAAAAEAAAAAAAAAAQAAAAIgAQCAAAAAAAAAAAACAAAAAAAAlKYdMdPzPjs83tI6ow3pOipUYDvPk0ovqGDsOpM4iTvjvlE7qEE1OzFBfzEtDS876otxMcMp4DF0RwoySHJmO3wVaDtN8AMws3o2MS3DYDtWvKMxhsJgOzTNdzEPhsIxy/S5LWr4YzsI8xExvV+4MMyoDDDgR5ExfGcwO/Ajnju5cCY7grg7O8mz6jobcYw7i4bLMCNaVTsfBks7nZerOudZSTAZCMQ6t1aCMVZoFjsumVAxwmogO2z5tTsXEsIxCiAUO678sy+5VBo7SAPfMb7XdTCsBKs7wUkVOwB4BjIGQ6cxG8DHMbhtJzs42J8xAPc1OxBCSTt7+jIy4ZeeMHRpSzuzZEQxJOtIO4B5nTvrzck6mT4DMQmW/zp73tsxcYHlMeswgTFxRCIxGxsVMSz9NDFnqYEx6Qb+OoLc3S/TJC87zrXKL90OijvjJnEw2DPVMXNLpjCtb5gxcjHiMEaSADLvvJMxK2xDMcntjjHp7WQ7gptPO0s9gjsDq3sx9c5hO81RdjtiyQAxiw/jMB+IBzvtvMA6zYBhMQJqejtUMkgxAm0JO6Q+TDG56Iw6b7DqMGMCizBtMxMxo/VnMGPZwDD/GZsxgIn8MVzGVDAKHgI7+a+SMNMwWTBdAyMxvAguMfyvBDtNLhAx+nUSO4chkDsO71Ix8JLgMaukVzs=", 
    "P6G0lvBAXt0AAAAAAAAAAAEAAAAAAAAAAQAAAAIgAQCAAAAAAAAAAAACAAAAAAAAmbuVLqxctTgER0g4LVldOOEP1TgwZ8AsdIFgOEVUAjkaNsc4KyesOEdv8i54QqY4QWrlLpvnVC+LVYMvV9/aOH1t3DjTn3otfVCtLlB51TgfgxsvsnjVOB5b6y79wDgv4Z0wK06F2DiAnoouKx0vLkiYhS3x+wkvYounOKoyFjm7FJ446EqyOB/qXjhjYwU5u01BLvuiyjjD08A4YvkiOAw9vy2kLzo4y5X3LnzajjglH8YuNlyYOLTVLDnYUjgvia+MOIPyKi1tlJI46s9TL9h+6S3SbSI5TMqNOClufy943B4v1bc9LwUFnzgI0RcvZ9OsOGgmvzhI/akvyKAWLhoywTiXh7ou2dO+OMmQFTk9qz84RE55Lty/cjiJ01AvmPpZL7Zn9S4bHpou/p2NLiDmqy6UTPYuyERxOPK3Ui3uWKY4eodALcsfAzlMCuUtnX5KL1XxHS6+xxAvMNVWLlw6dC9oUQwvi5u5LhfABy95btk4Ny7FOIFl9zg3B+8upXfWOMXy6TgKo3QuIqhXLom5gDjRDjc4ai3WLlXW7ThSJL4uEYaCOJX8wS7/1AU48OZeLhYHBC7OzosuPU/cLdkpNy7LTxMvh9pvL6AWyi0jKnc49FELLlFIzi1w05ouG0ulLvALfDiC8Igu3xqLOGDkCDn+VsgugEtVLw7QzDg=", 
    "P6G0lvBAXt0AAAAAAAAAAAEAAAAAAAAAAQAAAAIgAQCAAAAAAAAAAAACAAAAAAAAJeYyPahDnTs/wA88hpn6O/2GFTznhDE9APYIPGb1tzu59Y47RJUVPBoUsz340Ec8Q/lZPfqqjj3kLnk9UcoOPJ7Eljuuzzw9I8BEPVP9KzyKKzM9IYSXO9WYNT0noEY9/DpRPeGupzsRIcg8DwqKPbVwVj16YXE9laEYPMZ+gTvCNts7zl8MPLaG5Dsmj987tIR0PTKIwTs55cU7Kg8UPOR4cz1oTww8rgQHPc4EyDuE3+A8I4c3PDn9lztCuEU9TAEvPI+bWz2qFRk8aBNVPQCtVT2pAnc7xPuuO1cdTD1zroE9+vQ8PYiDHjw5O9g8yNccPN5Etjt3p7A76RYxPdFPuzvNNf48bwqSO+XNwDtvtdU8osxwPbCSxzv75TA9vKykPeDyyTwYf6w93LswPZ38HD3oOrw9IAFCPBlZID04FBg8C1nlPAjqdjvcpDY9JGmVPMggdD2/d1Q9Mee+PJ+dHz0vokk9Ob5pPSQkgj2E4Ko7q+iNOwgoFjwT9jM9WwGPO7mIiTutBfU8+EsePT29GTxjYvo7A2DfPK9Lijv9E3c9R4P2O+N5Rj2I0vM7bgIYPdHIaD2QsoA9tHxhPZYpez1S4UU96V8pPRGOCD2qB7U7yrw9PX2jTT3J6iE9MBz5POAaXjw2I+c8o3YBPI4z3TsUzXc9OQRrPaZ89zs=", 
    "P6G0lvBAXt0AAAAAAAAAAAEAAAAAAAAAAQAAAAIgAQCAAAAAAAAAAAACAAAAAAAAH7mIOrFg8DgAuVs5LYU/OUCNZDkoq4c6GVhROQSXDDlxg9o4E6NkOT/cCDuJtZg5+5WmOjIR2joJcL46GUFaOb5y5jhtTJA6ul2WOk5xgzko7og6eJfnOPrIijqUzJc6YuefOsQmADm/8hg6Df7SOq3iozqEebg6yEtpOczuxTigiCc5tI9WOY6mLjnF2io5Yd+6OgjoEzm4PRc5zk5iObQSujqkdlY58l9OOibdGDnW2ys6wEKMOY9Q6DhaG5c6Sb+FOarVpzo3/Wk5udeiOhxNozrwxrw4DrsFOX3+mzqsN8Y67miQOp5JcjkZQSU6zrtvOXVMCzntAQc5GVeHOg8nDzmOR0I6/DjfOKdZEzmOUyM6wwe4Ou+FGDm0MYc6XrT7Or5WGjp71AM7gxGHOhr0bzq62g87dESUOVkXdTq2c2g5TUcvOh20vDjRlYs6oV/kOQSTujrDYKI6seUROsv4czoTGZo6OKOyOpDrxjqklwI5MujYOGeDZTnyiIk6OZXaOF040jjyQTs6sfRxOln9ajkKWz85vrYqOlxi0zgu1Lw6lmU8OVWvlzo2Vzo5hVhoOqvnsTqqtsQ691OsOkfzvzq8Opc6tXGBOj25UDoJWgo5owGROqkonTpTfXc6vmE+OkK+qTl1pTA6XOJFOXkNKTmiYb06XZyzOiskPTk=", 
    "P6G0lvBAXt0AAAAAAAAAAAEAAAAAAAAAAQAAAAIgAQCAAAAAAAAAAAACAAAAAAAA5se9MOn8qjDpfoUxcpoVMBFJkjGf8yYwjVJqMTWuajsJjroxVgUaMtUlBDFu2b4xXIMJMdqPnzBxQl07SUgvMqQKFzu00nMwU8E6MXhqNDHyp6QxojLoMaZ17TDSVw8y3AzPMTQGgzEbHloxN+z/Ou80zjGY/7MxvaCuMSUZUDu3yI4x2UqbMQy07DqYTB0yOnN0Md6XgjHKElEy3tMPMnEVZi+eqUovtpbkL7ZJqDH28WYwlhJwMcFw2DBils0vqHIhOztEJTtkj147BGSQL1DPqDHmE0cxGc0eMnLoqjEr3xswh30mMZppgjCR3QYxsQUDOiUfkDE2gosvlqBSMQdqWDGVXaUxahtaMWwiNjtQUpIxgzmbLwS+fTAo+D47SIyhMcIp0TEqExoyupMOMkkN5TFvnnMxWBmQO9F9iTBUAL86BFdJOwKlKDGy9Sg7mSX/MRNvKzKYV1g7qwhKO/bniTspWucwKRAvO9rL5TGmxwowzId+MUSmEDHgIdswhoIIMtZ50zBkOZ87qNMQMFMzIjvpD0Y763wKMXin2S90aEAx1sCaMapeFDJDEY4xQo5ROwuCmjtteiwxmw4AMmo8DjAs4HQxKwtUO0R18DqXSzcwon+8MTNxzjE4mls7Dl4qMPuj1jGimPowpcuKMcoCrC9tfOkx/2peO7yFIjs=", 
    "P6G0lvBAXt0AAAAAAAAAAAEAAAAAAAAAAQAAAAIgAQCAAAAAAAAAAAACAAAAAAAAJupdLo/wRy5sGRwvKO+uLfYNKy9QOMMtwP8IL1c1CTlzJFoviBm0L+qFmi7+KV8vAsygLjuUOi6VXAE5FfbML7KdsDi8jQ4ubGDaLsj20i4iiUAvvsGHL0rVii4snacvqxtyL5Y1GS+kDP8uuqCVOC4fcS/QeVIvKjJML2FV8zjW9SYvKJY1Lxlkijjk7rcvlusOL5G0GC9LefQvOS6oL1WFBi09+uwskKWFLVTIRC9CBgcuZFwML5cWfS7JZXAtyMi8OOE/wTg/HwI5yNYoLY1kRS8hyegugLC5L6HYRy+XQ7YtOa7CLnh+GC50s50u/DSZNz+GKC9cISMtckr2LrkO/S6GXUEvfgn/Ljv51DjFGCsv44E1LV5aFC7sTd84v+Y8LyaUdC+zKbQv4bemL+TqhS8sbw4vd38oOYfFIC56V184Tm7rOBUzxS5ukcU4miyVLw52yC8r+fw4CT7sOKVBITkuQ4cudLTMOE5ahi81R6ItWNAULz8kqS4yHoAur5+fL3tIdy4hLzo5U1mpLROqvTgfmec40++hLuqBfi2U/OAux/Q0L+h9rS9SHyYvqwn1OFqrNDmsrskuX72VL8hRpi1IKw8va/L3OBaWjDi3VNYtTWpcL6ZlcS+PZAA5zzbHLcz7ei9+g5Iu4UsiL8giSS2Pgogv9wkCOXAKvjg=", 
    "P6G0lvBAXt0AAAAAAAAAAAEAAAAAAAAAAQAAAAIgAQCAAAAAAAAAAAACAAAAAAAAMoJ2PQuuOT037Ng8LKd8PZxafD3mU9g8tMiXPfrFTDx1JuM8oAoWPT2IVT2WbRI9EpxjPRDnPz0SKQw8wbLDO5oi0DtWyAI9GgUePbqW5zw6NGw9h+VNPS2VLj3/dyw9jdQxPc9wQD045vQ8qQDQO6tSbD2f7R098UARPdojJDyxmyg9ux4/PcIYFjwGTiQ9MDwYPTBkJT3kVXE97BktPcdekj1DC0Y9h0AQPb8Z9TzKICM9a4EDPQx2VT2+5So9aDTLOyiHyzsfubY7oUb8PCIPpT2UIwA9b7qQPVaLAz0gnZk9O3UEPYRpVz0KW189jb48PMhZRD0bqfE8xfQfPSIOvjzP9cM85mUIPcMRMDzppUg9zJZhPfW3VD0Mr6A7m1csPYx3LT2llTY9Z341PW64Kj2j9ZU97m4BPMXM+Dy5aGA7TPjhO3VTjD0/1Lk7hpMzPUp31jtyvcQ7iZGqPAGwtTvIdCY9EePnOz9gmzwY3+g8y78oPclPez2AYCY95BgsPaAsCD2PKJw7qZmEPVlTrjw9jrM797iuPCqDPz3ux0Q9iyNJPdI2iz2gjdo8QkXYOwDHqztzQ5Y9s725PPEoJj1dVw49HgqbO7w0LjyCUkk9OdoDPT9P1zw4yyw812xYPTJkVz39DlI9eO76PKQMaD2jWGw9cHe6O3xUszs=", 
    "P6G0lvBAXt0AAAAAAAAAAAEAAAAAAAAAAQAAAAIgAQCAAAAAAAAAAAACAAAAAAAA//UPO7rf2DqWXX06nYwTO+ZfEzuuq3w6mkgxO9Us7znYp4Q6lT+vOspn+TojB6s6iOwEO18k4DoQtaM5T5NkOQoaczkCwZg6MZG4Om0/hzps8Qk7sHzwOpnpyzqAcck6pLTPOkPF4DpnBY86ZfJyOTMDCjvFdbg6/KepOii3vzkp78Q6YzrfOhdQrzlq6L86fc+xOk8twTqa8Aw7oS7KOtf1KjuzUOc6fnyoOn4jjzqSiL46L5mZOotS+Tqrm8c6zFdtOXO4bTmla1U5O1STOvfJQDuOqpU64QopO8WkmTq4azM79bWaOuyZ+zqKcAI7CHTcOWVW5TozIY06ItS6Ov77XTqh4WQ6FFCfOh+mzTlYW+o6cr4DO4V0+Dq0rTs5q0vJOvubyjo1QtU6DfzTOr5mxzoRJy87ky2XOY5MkToIDgM5YveDOZLmIztZDFk5tb7ROgB/ejnOymU5UDlHOv01VDmza8I6AmyHOaB6NTox/4c6VBnFOhPEEjsCVMI6agLJOi8NnzqXZDY5guAaO7acSzqIuFE5ZhNMOrGv3zoN1+U6Fu7qOh6aIjsfRX86lZp8OcWiSDn0gS87BPJYOh4TwjomQaY6BxY1OfR4yznwJOs66ACaOj17ezq00sk50Mj8OrWT+zomWfU6PouSOkqEBzuwBgo79cpZORN1UTk=", 
    "P6G0lvBAXt0AAAAAAAAAAAEAAAAAAAAAAQAAAAIgAQCAAAAAAAAAAAACAAAAAAAAkTIJMUQX9DBjSWw78UqNMNG7GjEnOVgx4LdWMqERBzGRFiYvczmoMV2ZQzH/gogxcyyHOyvpxTF+iD0xjzZ3MRzqjzv3cMAxvO83MIhrxjD1RSMxPXWJMXRbYDBkF4M7rveAMUMLCjKGlloxxdT0MGuq2DFkupExKDEtMcdgojF3z8Ex5jwrMVE/kDtwi64x8y6zMTrZhjF5pM8xuKmtMV+1yDFP7nMxqnKGLxApkzGtSnwx+DbmMF8SITECS+4w7R3nMKzKMTuQYAwxq1mgMV6KpC+53mc7OUNfMRM+Wzs7tWcxyt80MV/5nTHabI0xpm2kMazEizEKQHIxNdEGMRj/6jBH0uQw9K7OMQn5wzHQx7wxPSLqMfx7BDu8oogxRaFOMf8/5DrhY1Aw59j5Md8wDTx3UUAx5JKjL2R0NDCFbM8xn8B4MSJaqDBeTaYxwbDhOjd/ljF4MbY6y0JmMTKTJzEJCpcxeMQsMfYQPzshsNwws+9kMflpuTHVcV4wUT5KLxCVeDEyaVA7n8ZXMRaLojFk5vkv3NINO38TfC/apVoxHFcNMqNwyi72vt0xSxODMHg5vjGvYqou1zEeMs0NFzHe+gMxE5FWMg0UhjFoUIAxB0ztMOkOgzEVYTU7rx5+MTeZfzEWggI7CiskMdbb3zCH0P8vXU/9OiWkYDA=", 
    "P6G0lvBAXt0AAAAAAAAAAAEAAAAAAAAAAQAAAAIgAQCAAAAAAAAAAAACAAAAAAAA7/+lLq+qky4J8g45ZfQqLp83uy7KzgIvteUBMJhsoy6Y9MgsSYpLL2Op7C6BKyUvDI0jOW51by+FUuUuO44VL3cgLjlI12gv+ozeLSkTcC60jMUumlAmL4K6By6YnB45vgocLx8Gpy8EPQQvVB2ULk8Tgy82UjAv94zRLmp3RC9cf2ovsC/PLo+HLjnxL1MvwMxYL1ooIy++O3sv1h5SL/3Xci/okRMvQqwiLdwNMi/CoBgvqkWLLs7iwi7CKJAuY9GLLq4d1zjQ2KkuUwNCLzgVRy0GRgw5+xAHL2GiBDnsLAwvddjaLlQjPy9tHSsvefJGLzIcKS+cjRIvph6jLjgqji7hbYourhJ6LyUdbS9jaWQvnKSNLw1MoDjoUSUvHwL6LmIVijhUI/wtLyaXL9rUqjkrseguyulFLYNW2i0L+HovoHwWL9SxSy7mNkkv/IiIOFQXNi8HcVw40kwLLyHByi5KvzYvdgnRLmEt5zhAgoUurn8KL59WYC9OkgYubbP0LEZiFi/DKfw4gIkCL5qqRC9YLpct2ZirOGB/GC1KRgQvHgOrL0/wdCwYJoYvo5ceLqYoZi+pJ04sp2e/L9nDti7Ur58uPM4BMMg5Ii9aQBsvgY6PLlaSHi/kdNs447sZL+OgGi/y55044aHGLk5thy5Zwpotdz6ZOHzmBy4=", 
    "P6G0lvBAXt0AAAAAAAAAAAEAAAAAAAAAAQAAAAIgAQCAAAAAAAAAAAACAAAAAAAAU2L9PCIZWj3brqk7a0UsPf+kDj1V7Kk8vcjlO9bQij1UE/k8AhSBPQp8qj0HgeU83nL4Oyq0ET3f7DQ9WQY4PWK7kju5hkY9VkESPSbmKT0G24A9+CtCPVbuEz3QtrQ7YGvSPLHDfT0nItc8Ob33PHpKSj0fGtc8ni63PNsAyTxmHvA8fuj8PLO2ojv+LwE9JOYiPRqwSD3Rq3899v+EPRYqUj37gQ49LrJPPQeyXD3oQZg9ugkWPXQQUz0sh/48fkNPPXlyFTwnfw09HRMOPai8cj25SaQ7FFNwPbH6hzuawvo8iAM8PSE7XT2TKT09EoAEPfFA3jysqu48LTYrPbQPRT16xfs8CdULPSf4LD0jtL88PBOdPfGS5zubeDI9KHePPeamQjwgjy09cU+pO6ZYSTs0z1I9sefDPL7peT1oRT89JdclPXxXHj3YXgM9PeUUPMoZLT0TPTc81e4ePXkkrDz/gi49CEUYPV1ehTsBZoo9pawcPbnxbT3VbHU9d1syPW7pIj3CNo07JKVRPM6DLT21Ilc91tUlPGjrUDvqEII9USMvPQaXlT0HsEk9VFOfPTiCCT1Y4lw9I8HMPRqnEj157Ys9CzsMO6wZgD0u7S09Fc0iPbbhIT3xKfY7gXlfPYh4HD2tn9g7m3xTPVzWtjy3xDM9fqIiPFicGT0=", 
    "P6G0lvBAXt0AAAAAAAAAAAEAAAAAAAAAAQAAAAIgAQCAAAAAAAAAAAACAAAAAAAAFREnOh/Njzodwt840ytjOl4aPDouE+A5nYEXOdkNtzrVOSQ6mTaqOq/Q4DpVUhc6CdAjOR8jQDpOlW46pqtyOjl+wTiN5YI6SN1AOgcLYDp066k6jAaAOv8SQzoFTu44BL0KOkhRpzqy2A06RVgjOv5ghTpm0w06K4/xOamHBDoCUh46wcAmOmCR1jiAWyo6789WOmpShDogk6g6fmKvOviRijoy7Ds6U/GIOoSDkTqIx8g6SNpFOtwpizos0ic6WKiIOtMSRTniljo6/1k7OvALoDrWpNg4vnSeOktQszgwViU6Re53OundkToEcnk62LkuOomKEjrqXB06JMZhOkjugTrgACY6+GQ4OoQXZDrny/w55yHPOrqvGDnSWGs6gS+9OplXgDma3mQ6S0TfOIzBhDjW/oo6HCsBOjTHpDrjOXw66bBaOnzNUDpyPC06lVhEOeBDZDo8onE5EJVROmEA4zkxIGY6p8tIOvverzj4gLY6nppOOvjinDqu0aE6ZTJrOkbUVjprN7o4UDqKOa3PZDoP2Y06L69aOdm/iTgZhKs6mvNmOgZDxToo+4Q6lhnSOphUNTpfo5E60AAHO3pjQToyhbg6fOs4OHvsqDqhWmU65K5WOoN4VTpeTiI5n1iTOuZVTjpA1A45K3GLOska8TnFDm06unZWOV+QSjo=", 
    "P6G0lvBAXt0AAAAAAAAAAAEAAAAAAAAAAQAAAAIgAQCAAAAAAAAAAAACAAAAAAAAW9HvMR6KwzH9Cssw7kutMffgojHtObI7LIrvOuzdpTFsjxsyFhXmMIxDGzGtM5Ux0nCmMeR99TGtNCs7Q+wXMFgnHTKtooUxAXt2MdO+1DGJYswxj4LCMZ2v1zCYC7MwjIf/MM1xEDJoE6Yw69WdMAiGizHppi8wNBStMfpDiDKWpR8t8VvTMHNe4jBpgNYxy5oEMo0UVzHO0Fgxn4DXMOScyS+1/2wxO3iGMe9vADHQCGkvJcuzMXsvJTEC2I4xS9n/MXasDDDJhyAxj5j6MGu0gjEYvM86STeAMeo0qTAqZf8vqMSTMQoKbjBqBdsxPFCIOxrVEjEup+Y6VKesOFowRTH+HRsydsE5MNVjFDE14VgxGAuPOyRXbzspvTQyAfYoMVdk8jEkqZ8xak5DMZGzSTF6V4Mw0PZFO1bnjTFCmbgx+GV9O3YrrjFI20ExwUaiMXh2sTGCWA0yIOMiOySILzhKTAUxiWqwOx5Y6TEBiiI6/DqrMAg5nDFv/6gvLE+RMdmlMjH8EoYx1OpKMUPoNzJztRUxuKgrMJgDsjExmakxswGvL4rhyzv8QjAwri4IO+lWIzD1aAMxWi+gMZY/KTGapxI6k767MeKLli+QSJ8viK7cMWIscjtqiB0wH2IeMZZyDzEhDasxLE6iMAkZLjLpMZ8xvFdAMWfenTE=", 
    "P6G0lvBAXt0AAAAAAAAAAAEAAAAAAAAAAQAAAAIgAQCAAAAAAAAAAAACAAAAAAAAm/t+L5PnTy/q4VcuUEE4L7MtLS8cfz05669+OAdbMC+uZaUvvKF0LgIVpS4Box4vN/cwL/+Bgi82CLY4pIehLWYXpy8DFg4vjggDL9EyYi8vT1kvWc9OLzVTZS4JXj4uEtiHLh6UmS/lkzAuA9EnLq9YFC9swrotEAY4L+PhEDAAvqkqfrlgLvyucC7VEGQvcf2ML1eu5C6whuYuPyFlLqpcVi1S/PsuEvkOLx6PiC5Axfcssyk/L46hry5p4BcvhwOIL7uRlS2BrqoupTiFLk/4Ci/53lw441IILxboMy7LxYctxxwdL38X/S0A32gv7O4QORMenC4RPXU4TZI3NoKo0S4U7aQviYDFLQTGnS4gmOYuuhYYOal5/jgFK8AvM6WzLiHcgC/IwSkvGajPLsZ01i6upQsuhXvSOIXgFi+aRUQvCLYGOfouOS9/Hc4uvYksL0uvPC+pSJYv/y+tOLWhujUpuo0ua5I7OZIZeC890aw36w42LgQaJi85rzMtfH8aL9vxvS5sjQ4vuL/XLmqJwy/8LJ8ul4O2LVhFPS+1UjQvwxI6LQjGWDldaLstPsuQOBqrrS1EuIsuelAqL2/zsy6y7Zs32J1HL/oQIC0YWyktAKNqL2K+ADmbfqctFWaoLsOEmC4q3jUvoJEsLmMbuS8DQykvcYHMLgjaJy8=", 
    "P6G0lvBAXt0AAAAAAAAAAAEAAAAAAAAAAQAAAAIgAQCAAAAAAAAAAAACAAAAAAAATds/PRHzCD1vCrQ8UdK2POujBT0v0sM7PhqPOPtMIj0uURA7FrlcPUNMizzWDI888r7fPFvAAj37P3g8yjU7PSEEjTsPu4k9H60PPX7FUT2XhhI9rFE9Oqk+4Txi+Qk9reAKPWFLBDsIlI88zh3mPFx/zjwtp9g8NbUAPWnBCTuvujc94aYLPYnqEj1Tizk9BfaDPKY9Kz1JegE9/RgpPfdsszyk/x48KHpFPYUyNj2M4Qo9TqcJPZxoyTxHAB89InwuPXKKaz3JEzQ9hxIDPS75Ez1Qe008t8UzPQQODD0oriA909cnPeL2HD1ZnxY9q1bAO9e/oT2gOCI8uXyLNbyrTDwORq87xn1LPeqCFT3wQQU9H4WnOxxKRTtBOvo6nFoEPTB4lTvVOjU9j1oRPdDnHj3T2yY9fTQrPF4UFz0YiRQ9FbLDO8G+5DwL8BM9EvfGPKqFKz1Mje08tPcJO8cz4TSurwk94J8SO1qyUj327gs2Wz9xPbkbRj28l7I8Oj5NPfCSID3tWCA9NuJVPWRfEzrW0g49kD4GPfCuAT0GLyk9jdVqPSOCTzvgbEw9AxT9O22BgTzYxx89PM1zPamqLT0YZgY8e0d6OpyJCz29VP88JU9MPdTdIjwGEf48eQXcPCWYRD3as648luDyPPzJDjrEtvo84C8KPWoWQj0=", 
    "P6G0lvBAXt0AAAAAAAAAAAEAAAAAAAAAAQAAAAIgAQCAAAAAAAAAAAACAAAAAAAA8wRmOsEwJDpm2tc54i/bORk5IDq0xeo4QJGrNZiVQjoKBi04VFCEOokBpzkugas5OSAGOm3CHDqi0JQ51HJgOuUQqTiHIKU6WUEsOmR/ezrqqy86GvpiNz4GBzo/ayU6jIAmOgacHjhEI6w52vEJOouS9zm/3wE6N08aOiQoJTh4Rlw6LW4nOr4jMDqJc146rzWeOYFNTTp/Oxs6trtKOpsd1zkboD45A8JsOk1wWjqYgSY62AglOql48TneoD46LzFROkgyjTqc5Vc68SQdOjhoMTrFWnY5AohXOtTpJzpBpEA6qTpJOsMvPDpJlTQ625jmOGDswTowfUI5ojunMudhdTlFI9I44PdzOkZAMzqgwx86gtfIOGiIbDgfABY4Sa4eOmozszhYR1k6NEQuOomDPjqJDEg6hkJNOZUhNTrDFDI6OJ/qOGkfCTpEXTE6sYruOdijTTrpZg46PGklOLj/BjLiEiU6O8ovOF2bfDqYxCczCJ6QOreDbTr2HdY5iBF2Op+DQDoSPkA6wTaAOtevMDekOys6gPIgOp96Gzoh1ko618WMOsvIeDiKFnU6lLUXOQ5EmzkhkD86ASaSOgs2UDrlISE5DQiWNxZLJzpNDxk65fJ0OkBDQzlATRg6qOQDOguzazr8c9E5JZgROgcxKzfDShY6lKwlOqqxaDo=", 
    "P6G0lvBAXt0AAAAAAAAAAAEAAAAAAAAAAQAAAAIgAQCAAAAAAAAAAAACAAAAAAAAqyQxMVWVUzsvF0Uy5pVSMS/2JDEMcn0wuhsQOllmDjIxIhQyAYfiON8vDzq+Ml4xVXmKMQKf1TGy5hwykFv8MTpOrTAdAfsxbyoJMYIBFTF4jWkxQ5BJMIYNgzLJWMww+XI1MQBr+DAj0/sxgOw3Mm1SrTBeYegwNihRMQL2DzCo8zIy8dDCMTNSei+GH/I6XoDBOrRalzHxLJoxKyc7MiExijEWZOswXdx4Mfo7sjqcPPQxO9k2MenivDGQZE4w6iOkMHYAXDrfUGAv016JMvqeJDrMUjQwiktNMiiUgS6eBokxlcSiMU0IOjCgGlM5JyZpMRAWoDs0PhsxGhKoMNb4YzF5jWky4uGIMCKZRjDXc6swmfb5On11ZzCVbpMwTH4xMj1syjCHrO8xWReZL+FNFTuVxxY7gcr0MaBXhzGYF94xQQAhL9+iIS9wL9YxguERMQ2bRzKSICsxw5H7OufPNjEWO9wwVXCYMMLbJDtadxs7rih1MfJxpjAweX8wkkkmMMXsczj/OI4xufY0MSev8DCDuBw7oL4VMdCNCzJqGOEv4GkXMORp1jpyOCwx0aIiMEYguzp3kaIwlSgqOk0EkTvGFTQxmaSEMZtHpzFioo8xNnRXMYU63jpHeBsx6UHKMFTNyDqCQlMy0cZfOtwFXzDAewAwug8bMdx4ijs=", 
    "P6G0lvBAXt0AAAAAAAAAAAEAAAAAAAAAAQAAAAIgAQCAAAAAAAAAAAACAAAAAAAAlHXBLlES5zhwPtcvW/vlLt0ntC4OZQous2GdNwiEmy8Tx6EvW2R3Nh5gnDcEqvIuczoXLwtMaS9QWqsv/cyJL6ZEPS7PD4kvtMyVLva6oi55EP8u/CDcLagfDzAjK18uainGLkKmhy5+gokvS93ILzxJPS67yH0u/GvkLoE4nS02b8MvkcJUL0ywCC1PNoQ4/lJTOIhLJS9KYCgvGmTML5jrFi84iYAuKeQHL52mQjjFXYUvq7DHLrdITi8oZ+EtOkIzLvJD8DcU+vQs7AUWMJ/Iszey7sQtQDTgL4iDDSyXpRUviMIxL9Aqyy1OjOY2pJ/+LsjULjm5iqkuF403LkH4+C56EP8veX0VLvDj2C2RPjsuR36IOCDH/C3sAiEud9fBLzkRXS7v34IvITEnLV4OozjcqqQ4QKuFL+bOEy9ejHIvi9SvLCOGsCzG6WkvRlGfLpz92S+h47ouy16JOHumxy75g3Auu3omLgALtDgiyak4rd4FL5rGNS6JgAsugpq1LSwyBTaBUhsvuKHFLihtgy7gJ6s4f4mjLmVomC8A1HUtGVylLZwpajhIFbwuqJ2xLZNcTDi1ijEuzNS5N7FfHjkNrMQuOdwQL/GvNi8t3RwvdkzrLoOycjglyqku/+JcLhlMWzjdt+YvT2P0N5SQ8y1MUYwt91epLu85Fzk=", 
    "P6G0lvBAXt0AAAAAAAAAAAEAAAAAAAAAAQAAAAIgAQCAAAAAAAAAAAACAAAAAAAAOVniPFGaZzslDQo6fGxRPeB5rDxQJy895NkROIaqHT3Os0M7iuioN9vWRjb53vs8aM4BPbWPIT13/z07MS+RO+0MljyRjIU7RSkAPQM/ED2A1Cw9oouSPQQn8TkiDwA9w3ivPDiDAj0ZbTA99A1/OgiVFDzYPm09iPVHPXPw2DxC0Ps5I0P8PC2GoDwvjP87q2bkOxAzPT0xe2Q9FaMuOmzMSz2grRs8mk4BPU9vuDsrAxI9gvQNPTt6CT3G5Rw9x8/DPDe1yTj7Itk8YKLMOZLv0TunEAM9jaCqNbMP1DxffAI9riC3PCKEHT0xjCE2l531PGJgxTq3mTI9HkgJPezOEz3z72w4JXYBPTXGFT1Laxw9yQXTO1hoJD0sgGA8Wo5BOtkfET2tNU08HwkfPbXUiTtyeRE8TBxiPJNoFD063wA9cvwFPSSbwDzhSz09QjX8PKbBdjmP48s84kHcOyCeOD3mYkg9MFCkPCcnJDuz8aM78FkYPQ1DUz0yq0A9KqfGPO3smjf7sNI8shi4PE2aAD2zbLU7sWH6PAVWGj2aFGs9qAPVPDBtzzu2FiI9Ssx5Na85Rzil3Rk9lWkZOZ679zpHiho9Sp8jPQPgxjufMTE9UrkePa0XozsDxWM9B7AQPdGk9zvZ4kw0RfKHOK6UIT1Eiy89o2RQPN3MJTo=", 
    "P6G0lvBAXt0AAAAAAAAAAAEAAAAAAAAAAQAAAAIgAQCAAAAAAAAAAAACAAAAAAAAOsMIOvPvizgf0yY3qhJ9OqVs0DnxqFM6CkAwNRSHPjrafWw48hzMNEhIcDMALxg6dNwcOho8QzokmWU4w3GvOCNTtTlRYqE4it8aOoVPLjoo2lA60xaxOhG1ETf0vxo6XgvUOfO2HTqhMlU6bBuaN+aMMznAWI86taJxOtETAzocJhg3hWsYOjr7wTmxZxo5tQAKOSOiZDobDYo6JwlTN3RGdjodIDw5AkIcOijg3jjrcTA6x4orOpYhJjpSmT06qJ/sObO/8zVZMgM6AEn3NhKx/TjdYR46qzDOMk4hADqtrh06yEvdObBYPjraN0MzbGcUOsKD7jdD01c6B+UlOn+dMjoVKY81y3EcOq79NDpQBT06RgH/OJusRjpnpYc54eVpNzhfLzoB+3c5wC5AOuuOpjh+yy85ap6IOSxXMzpsuxs6g+khOvq/6DkgwGQ6ImMYOuQXlTZqYvY5DhUFObsYXzreJnI6ao/GOdNdRjg7HcY46ho4Ok5Lfzph02g6pg7wOUA3uzTLmv45fXfeOSFoGzrvPNs4oEgXOuSAOjrfCY46tbQAOsyo+jg+30M6Wu6WMrW/cDVu7zk6LWM5NuyuFTgLwDo6pblFOlhT8DgdIFY6Uc4/OsQVxTgIn4k6GNguOiahFTnplncx7kekNRxCQzq7IVQ609N7OW5bSDc=", 
    "P6G0lvBAXt0AAAAAAAAAAAEAAAAAAAAAAQAAAAIgAQAAAQAAAAAAAAAEAAAAAAAAvxMEMXCwAzv7XsUx6TVwMdFtODIWyJExdAgfO8O+1y8wm3Uy2yTDMbDgYzHNnhUyHB+CLwqA0TEAmd0wHbvRLjL70zH89UAxr1EyMdCQkjGY72cxwYCFMW3bbDFDL8Qx6Ie9MYI3rS5jK0MxS1BSMSTGrTpvrg0xQ2oDMfafCTIOnMovFlueMPMH2DAgLAoxCtBbMV2GQDGxC5Qwb/KQMaV1ui4qN2c6rV14OO9MrjEsiwk71qHnMeiQJjFoENEuX+hAMnJlrDCyF/swDlBYMrR/ojB2WWQwqOKgMbDHxTFbP0oxw8HnMaLhsDDhpYMxoLBaMcdqKDr0PV46K+bbLlmtgjFsBMQwjyhSO5tytTruzBsxTpWVMZoIeDFYxIo6lay/OihwuTHpDgoyXv2FMagg6TGM4Gkw9bGtMePwbDvUEecw3yGJMSvfZzuS9tIxX1aMMBsYBDGGlz4xc6JnMcnQgTAFZaMxoFHmMVhQPTJW3RMxje16MsNxLDuNaHE6/hjcMGAz8DG4UHw7vhVnOwSfLTEo9QAyEOdHMamEQTu6MJQxvsIdMa4qKDEH048uKXeRMMexODEgWsQxfrJjMta1IDGN/J4vFA3/MW3guDHZybExurhJMTcICDIk2K4uf2gMMI+DAjGGvqoxBqpKLYcYHzBnz6A6sDjUMQEYwjHHPWIyFO+YOk/jjTCa784x/bCwMckBfzIGU4c7BKVqMo2Q7THF2QcwScGmMVIoHjEeI8cxhrGrMfrdcjHyesgwgUE9MoreYjFOrAoxETLuMeDWBDtd0AgyHhP2MNyA2zCGCagx1D8RMB5+qTFQykcyLj4FMYPRHDFmj7Ix7zmELu7vcDEhU1Qy6ylmMbnOqjBd7cwvhnb2MODpNzGfchMx++KVMZwmjDGc/twxpiJJMUUcVDH0nQcyeuCQMTRGvzFy3tQ68EKaMVvWfzGuKSQxWm3eMM+mBDK6RcUx/o8mMLA8HzLKkV0xf0KSMPiP7jHJZkAwPrOuMY31tDGJXww7RY8IMac/mzqvGfEwgiHTMQ8RzzBQhxoyMjgMLqKiozrcMD0yjcOpMq66yDALmEMx40yXMIfG2jBL2JIxbWkRMogCmDr/KR4x9hIMMhBy8THrNj4ymIkvLiATxDFwfLoxZgK4MR2zrTHFUGAx0uPyMfGpITHI1B4x+bjPMJXSXDuuCLAvn3mQMcj8gDDddZQxEXc1MZs7/zBw3q0xHscgMVs94y/8M0cyLLc+MZ0q4zHVroY7tUO5MbwP4DGKF4AxR+r3MKIIrDpgIfIvTXU6MGBdyzCkjPQvLxKHLrIaMTpp+lcxvwStMNHOwzERYaAw+uO+MW5UWjDC4UQxLTbKMA==", 
    "P6G0lvBAXt0AAAAAAAAAAAEAAAAAAAAAAQAAAAIgAQAAAQAAAAAAAAAEAAAAAAAA6LFVLjsRVTg1qx8vNlPCLu4ylS8/3usueaeAOHaILi2isMYv/d0dLxZZuC48FHIv5ofSLCJ7KS+BRDMu7KopLPV8Ky/gGZwulUGQLgMj7S6KobsueQDYLrecvy6CtR4vh1MZL+ogDCxG450umyOqLk2UDDj0O2UusJ9ULsCrXi8b6CMtORsALqvDLi6Ijl8u1dKxLpO/my4FiO8tkYTqLnbXFixXDLs3K+zINVkBDS8eil44o2I7L4y/hi7TICks3Q6cL/t2Cy7ZIEsuAP6uLz11Ay7KurgtGCcCL+r/Hy8enaMudnw7L9YXDy4mANUuUuqwLuY+iDfzybM3vOQxLAlu0y7Zkh4udgOqOIPJEjgMFHwu3wTyLlinyC7QhOA3ZQ8bOOwDFi9DX18vGMrYLlSYPC+QM70t+YMMLxSuvzgj7jouvt/dLkCUuzgeqiovRw/jLfa4VS5DL5ouImO7LiwJ0i3ALgQvplI6L5UmmS8FPW8uwf7KL/GAizhHS8M32g0yLilRQi8UHsw4TfG6OKd0jC7TpVAvfrehLkyNnDjxw+8u9j9/LgwLiC6Os+grUFvrLelplS4u2B4vtzO4L9UCgi7YnQAtp1ROL6aPFS+y0w8vNDCjLgkYXC/2cQ0smixjLWwqUy7YIAovaPOjKnq0gC2EFwI4tK4rL38EHS8zBrcvtnD3N4GR5S0WaCcvfPAOL4VLzi/g8to4gdK9Lz4vQC/kzFstsOYGL0/kfy76GCEvbeUKL195xC4gLyIukxqZL0CIty7rXWAu6LFAL57tVjjeW10vpxFHLseSMS458AcvyQFrLaUdCS88oKEvwpRXLqm5fS6CcxAvse/VK7Lpwi4YxKsvhzK6LvMtCi4VyCUtEmJHLjLIlC5ckG4ujILyLgDC4i6bxzIvy7aiLreXqy4cbFsvg2fqLpO8Gi/MNCw4lpb5Lnv3zi7YzYQuS/AzLtmfVi/Hlh8vz76GLbvRgC+sPrMuTaTsLd/9QC8IppstHVQNL1hkEi8aHmM4jfJcLngv+zd5C0Mu28wqLyeDJy43BXovdN5iK5hgBDgcDZkv0FUJMK9iIi4sO54uGMz0LQr8MC6qlu0uF0VrL/3x9TcF538uNqJiL/lSQy8c4ZkvhQGOK76eHi/13BYvCNwUL+mEDC9ed7UuGX5EL0/Igi6sfYAu/gooLv2jsjhUaA4tGcHpLimy0C3NM/AuH82SLkt6Ti71pwwv0BCCLvXUNy2fJqEv3UiaLsvFNy856dk4998VL8FCNS9CP88u0I5ILuUrCzjM4EMtL9eWLYCEJC7E1UUt+InaKwBGjze3uK4u2vcLLnxnHi9CvgEuHG0aL72fsC3oRZ8usJUjLg==", 
    "P6G0lvBAXt0AAAAAAAAAAAEAAAAAAAAAAQAAAAIgAQAAAQAAAAAAAAAEAAAAAAAAql5YPYEUTDzEnkU9Z2dKPQMikj3jMD09ThpGOz/+SD3fp5g92GIKPZA6Lz1n1RE9/ugGPXHbxzxW3+Y8W6qxPdzgtDyYK8Q8gDIaPRHMdj0bAgk9ZQ6vPDoeID3FSVo9OYWLPJVuUD3kMzw9+7ClPGiQNjxulRg9JedhPbV7BT2j0yE9m+rKPAfhMT27PTs9uB8PPUgiNj1P8xs9KXoBPZZBQT2bMhM8+lKMN9IXWD04cik8XGTJO/2bHD1KtCE9B1MtPRmR3D0amQg9w0ZJPcpxMz1Q5ww9Tzc2PXWvfTy5DU09xCUkPR+ITz3EEFY9IFcHPO+zyTsJy0080MtLPVh+gj1H59Y8/S0IO1hWWjy4JgY9CSdIPU2W5TxBSZ879N4yOxuqAD3j0+o8ztxcPX9ASz1jnpM8g4oAPSiaPzzRkBo9BbOBPSqlWjvNIkA9Ou/NPQvuiT0NmSA9nWHyPGzMKT3ftS89DJedPBxesjy2pTI9VcKHOz9JUjth6QY8QWudPKC93jyFYSk8huZUO7Ac1TyD/Jo9NKBqPfmAYDwk89c8j78dPWIuJz0FEjA9zsxEPezaBD2Zbe085BfwPakcID0IqQg9nxtQPLiMhj1X7wY9KHUfPQvuljevSSs9t/AiPckQFz0i4ds8XNUgPXH7RT3S83M8CkLnPDPkFT2ueY89WCo0PArQOz3zpfs9WLGzPVZyHDx8f347WYgtPeJ/kTt2Zqo8H/FdPXqdgT0FXoA9zrrtPAuECj0F5LY8BiQxPAk6Bz1kyBY9VMJiPf0mxDwuWiY9xpb9PP588DxR8g093QnoPY7+Gj2lyM09ZVDmPKMgkD2S+ms9kpmnPUo3jzxmCLQ6rK3tPHYfMz3kFSg9SlOYPMupHj0QUCU9zaOFPUcZkT1J4SY9wnwOPbkbKD1NUqQ8PrOOPV1wFz2HwRU8ocdLPZ9e1Dw9iRo9HyNCPQgmeTyOxos9fI77PDqgCD0/Jvo8geZ8PWhmNj3McOw8YaE8PZDw3zzMlkg8Mr4ePZpPozuwrNI8d7XMPMMETT0ympo8okadPfPxEDxRMyA8CE3RPcwp4TyDiGw9xvjzPIym9TzqBPw81WwcPWPP4jvKgxc9pp0DPU33HD3RMtY9/Yc2PX4ZnT2jXE89/sX9PPjtqTyc8js9aGsRPevS6zxNPBU9MSokPWfLHTzwbjs9hTEBPd6/Pz0WfVE92TgaPaaQ8jz1kOA8J77xPDD4FD0RFq09lWOtPWL8iTyFaG87PJM0PaDRtT01RAY9w+krPZTWTztX1HQ9+uuFPQoE9jwZ6T499PJTPdm/0TtMCS49Mm9LPZ8NqD067Vk96Fs6PT4uBz1BwJ89ygVoPQ==", 
    "P6G0lvBAXt0AAAAAAAAAAAEAAAAAAAAAAQAAAAIgAQAAAQAAAAAAAAAEAAAAAAAA1TOXOkCdjjmXGYo6Y3GNOl09zDqiNYQ67G+KOAF1jDo1W9U6oWlBOq/ndDpL0ks68o08OsmpCzpOViE6hE/4OhLN/Dk2Fgk6wYJXOi93rDqhfD869Kn0OS7JXzoGi5g6eP/COcmnkTrWhIM6QZPnOTcofzlvQVU6R92dOmmPOjqELGI6E80NOu2beDrR2II6xwhIOk2OfjoG9lk6E/Y0OuQMhzpZuk05Ch/ENFMClzq20mw5XbwMOcbhWjq0AGI6Sj5yOqoiGjvf6T46rqeMOgvMejpb7kQ6sKt+OnhHsTloS4865GplOrwGkTqal5U63ic9OfjzDDmzz485c2qOOrdhtjqCLRY6K1Q+ONCTmDlsfjs6nd6LOl9wIDqGn9440v55OEvTMzrkGSQ6kleaOhgJjjr8UM45I6czOv3khTmTBlg6i0W1OuXKmDh7RIY6/ugPO2LGwDrYdGA6NWEpOshQbToGlHU6qUDcOb5K+TnRrnk6tL29OHzzkjh8jjw5dAPcOZOnGzpfu2w5MMeUOArtFDoXndg6xvWjOvvinDmy6BY6SHlcOlCoaTrQFHY63oaJOrGuOToZ6yU65ccnO/3GXzojAD86z22ROfsMvDrRljw64txeOrLx0jSlZW8687pjOkEiUzqypxk6IslgOltaijpHeqo5R5shOiV+UTqDhsg6+817OQ8/gzoI2y873iT7Oo+nWjnX2LE40IhyOsRayzgSKO45qhibOm8ntTr0aLM6DSEmOgeYQToTnf85xZN3OTb/PDoSvVI6cnaeOv4SCTq7f2g6ODYxOowOKDqHY0Y66yYiO/KfWDoIzg87avIgOttvyTrS56Q6Hz7qOrgpyDmKnvs34BcmOvpYejrg62o6/+TUOajAXTrMC2c6cse6Ol3LyjqPPGk6BSVHOgf0ajoiqeU5K3HHOtanUzqwTVE5h2eOOjdoFDr7+1c6f6qHOtkbrjnIWsM6osovOtXzPjrlzi46CruwOoPtfjpwOiU6WdGDOhF+HDq2LIw5K91dOpE/5Dj6OBM6uw0POiVFjzquE9g5RtDbOmWUSjmo5l85PEMSO/VYHToDS6U6vX0qOhKqKzplHTA63p9aOpJ/Hjn8wlM6Q/M3OmVhWzpmrxU7cxx/Oi+R2zpZ6JA6OFcxOqp/7Tk3V4M6Jj5LOhzMJDp8k1A6E3FlOtaJXDk0+4I6jZA0Olj/hTrRZJI6oItXOhOCKTon7hw6+u4oOko0UDoW6fE6bVXyOm3awDlYTac4lGB8OpId/jqjpzs6X0VwOpA9kTgsF6s6Uiy7OmfrKzpCaYU6+hyUOniTEjkJPXM6uimOOlHg6jpbSpg6ATuCOrvuPDrXRd86EySiOg==", 
    "P6G0lvBAXt0AAAAAAAAAAAEAAAAAAAAAAQAAAAIgAQAAAQAAAAAAAAAEAAAAAAAAsZoWMlqqZTJdYmEy0vxLMleOKzJzJFUyCE8ZMpqVTTIzRzcyuMVHMrX4EDIK8FEyCY0LMonz8DpZmEQy1dU6MilEMTKfG1cy6p4XMqXjKDIU0xky+0CmMt4gXjJYCGIyfl0xMrX5FTLYJiAyHrwlMszq+DFYMjYyh9AeMunpUzJbkPwxvtM6MnOa9jpkImUy1PEhMt/V1zrdoSsyziLBMuqsFjKs1Vkybx8nMqgWwjpzPfcxcGpRMjzKDzLUqA4y83UfMmBhhDJnKcQ6F7cPMs7NLTKiSEgyHYvaMpIgEzJTak878RMyMq0NVDKT4TUyMjMaMi3uVDLCPREyOOsuMnU7VjKZ4T4y1nwjMqCQMDL06zUyL5YrMl2EPjLlOksyRponMhk5Jjv1rS4ya0ubMuVXHzJQhWYyVBZQMubpMzIXREIyaPHCMp40EDJk3zQyiX4ZMulDPzIZi0UyGEYwOw5r8jL5540yOl53MnBRVTJ8QSUy9Vc/Mqb8EzLdIys7d89CMuinQzKogpQyJ2ytOlWlLzKDfAsyat4lMqqYNzIpRd8xU0J8MveETTKoBv8xpnsgMr58kzJg6iEyrolJMr61OTLVADEybkgvMu3yGzJ8bzAy3gk9Ms9UPTKgpCYyF8ZKMpWwKDJY7TsyFTJAMsnpTTLaOSMyhcwiMoG7DTIjskwy7pE+Mr/9KTL8fVAy98VBMhbHYjKiZi0yupxBMo9ZizLolSIy+26tMklQEDIDQjQy74JQMgxANDKTWEM8UMEhMl9oEDJCQScyPXatMk79TDJeouU6BiYhMkHWdjJwJ0syXbhRMuiBKjKUYQkyGlhZMoxuVzLdqhsyzbQ4MhfOGDKMfDUyOfI3MpyJVTJJJzQyFY0/MmrUcDJQ/TQyNLMkMsE5gjIiciYyuembMszhDTIntkQy5EUfMg6cFDKmGwoy5+MoPHtITDLkkTcy/JQnMiGLQTIsrD8yk99bMgXBBjJlHEUyZlQtMj3qRjIbO20ySGDAOlK2MTLt+AYyksMfMpuFITJVdxcy2chOMv1FFjL0pSkyDt1HMvlzJTK2r/s7j7W4O8cTWjJb2EIy0qsqMuvjFjKye/wxrL4HO3xhiDJxkhIyG5g6MhvaMjI3kBgyf+xyMqDjtDpPNS4yGJUwMuwjDjI88hwy6F0RMsJvFTL6/yky9aA+O/OvGTLkMyIyvcQoMrMg+THUiRcy7Y5MMqYCRjIiAjMyFYhdMoEaqzJgIWMy90VzMoriKzK+90AyfeYuMoG1RzJSd188X5wqMu18HDIa71wyGkILMq0wFzL05hcyD94nMizfJjKDloAy6khxO/FdIzJBdTYyjhJIMoor2zoceWMyqLpDMg==", 
    "P6G0lvBAXt0AAAAAAAAAAAEAAAAAAAAAAQAAAAIgAQAAAQAAAAAAAAAEAAAAAAAAPMeOLym72S8frNUvN2PBLyqkoi8PEcovmVeRL8Hmwi8Wwa0vMGS9Ly5wiS9IB8cvnkyELzZuZDgVYbovZyCxLwYOqC8W7ssv772PL/IcoC/I1JEvV50dMPCV0i96SdYvCiaoL50uji9h1JcvYR+dL4H7ay+euqwv2o+WL97myC+NcG8vax6xL/DJaThDOtkvg4eZL6ieTDittqIvjhk3MILYji/dg84vPHCeL70AODh3ZGovn4jGL21RiC8PP4cvrSyXL7EA+y/n9zk4Rz+IL7rFpC9N4L0v4C9PMF57iy8fo8Q4AtOoL8YIyS8Mbqwv6C+SL5vdyS+lsYkvT9SlL5IZyy9Y9rQv/v2aL9Fjpy/jd6wvmquiL/SdtC9eq8AvseSeL96VnTg7mqUvkTkTMC8Qly++itovMEbFL4uQqi/PK7gvH9A4MEi2iC9HeasvooSRL4xTtS84R7svKR2nODfSZTA5iAYwioPqL7Y7yi8fq5wvjWa1LwJMjC85P6I48a+4LyN9uS8OywwwJmkkOMCEpi/0PIQv5T+dL1IOri8Lq1MvkybvL/vWwi8ZxnEvxySYL8DSCzBygJkvqhC/L0gPsC8yzqcvrSymL17Yky9mRKcvIDezLyx+sy/O+50vojzAL4nsny9jKbIvWDW2L5A2wy99vpov11aaLxFehi8cD8Iv0aq0L2MooS91qMUvPbS3L0/+1i/qY6QvJY23L9EbBDAQI5ov1GskMIPQiC8U5KovJq3FLzfiqi/tMbk5hFmZL1jniC9NkJ4vtnIkMF9Wwi+Xs1k4TMaYL6IC6i/smMAvgNLGL66loS8GPoIv0QzOL7Q8zC8NlJMvsRuvL1vdkC9FDqwvOWOuL/dwyi++yqov65i1L7VQ5C+llasvPCScL8fq9i/wy50vpc8TMF+Chi9XfbovHf+WLyLjjC9t7oIvMR2gOfKqwS/mB64vrd+eL3Z8ty9ktrUvpXLQL9SAfy9F3rovoVKkLx2UvC9G5+AvJGE2OEB6qC/V6n8vQ3aXL+ogmS9pmI8vCQrEL+92ji8o1aAvUHq9L/zanC+Um245aRwvOb2+zi9fuLgva82hL6gMjy/3XG8v47CAOD1LATCg9Iov4uWwL+COqS+yopAv7kzmL0t9KzjaJ6UvDminLw/Bhi9pypQvH9CJL9WrjS+BKqEvELm0OHqzkS8kxpkvpf+fL5subC/yqY8vu+3BL4+4uy/StKkvGAXSL1k2IjDoU9cvwKHmL/3zoi+78LYv08+lL9FUvS+Z2tM5xb6hLzNblC8QdNEvlAWEL21Vjy87ApAv9CSfL1Azni/ez/MvJ7/kOLTgmi8N+qwvCK29L/fHTzgVp9cv6Y65Lw=="
  ], 
  "attrs": {"tvm_version": "0.17.0"}
}