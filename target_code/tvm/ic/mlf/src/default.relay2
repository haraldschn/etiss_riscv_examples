#[version = "0.0.5"]
def @main(%input_1_int8: Tensor[(1, 32, 32, 3), int8] /* ty=Tensor[(1, 32, 32, 3), int8] span=input_1_int8:0:0 */, %v_param_1: Tensor[(3, 3, 3, 16), int8] /* ty=Tensor[(3, 3, 3, 16), int8] span=model/conv2d/Conv2D:0:0 */, %v_param_2: Tensor[(16), int32] /* ty=Tensor[(16), int32] span=model/activation/Relu;model/batch_normalization/FusedBatchNormV3;model/conv2d/BiasAdd/ReadVariableOp/resource;model/conv2d/BiasAdd;model/conv2d_2/Conv2D;model/conv2d/Conv2D:0:0 */, %v_param_3: Tensor[(3, 3, 16, 16), int8] /* ty=Tensor[(3, 3, 16, 16), int8] span=model/conv2d_1/Conv2D:0:0 */, %v_param_4: Tensor[(16), int32] /* ty=Tensor[(16), int32] span=model/activation_1/Relu;model/batch_normalization_1/FusedBatchNormV3;model/conv2d_1/BiasAdd/ReadVariableOp/resource;model/conv2d_1/BiasAdd;model/conv2d_2/Conv2D;model/conv2d_1/Conv2D:0:0 */, %v_param_5: Tensor[(3, 3, 16, 16), int8] /* ty=Tensor[(3, 3, 16, 16), int8] span=model/conv2d_2/Conv2D:0:0 */, %v_param_6: Tensor[(16), int32] /* ty=Tensor[(16), int32] span=model/batch_normalization_2/FusedBatchNormV3;model/conv2d_2/BiasAdd/ReadVariableOp/resource;model/conv2d_2/BiasAdd:0:0 */, %v_param_11: Tensor[(1, 1, 16, 32), int8] /* ty=Tensor[(1, 1, 16, 32), int8] span=model/conv2d_5/Conv2D:0:0 */, %v_param_12: Tensor[(32), int32] /* ty=Tensor[(32), int32] span=model/conv2d_5/BiasAdd;model/conv2d_5/Conv2D;model/conv2d_5/BiasAdd/ReadVariableOp/resource:0:0 */, %v_param_7: Tensor[(3, 3, 16, 32), int8] /* ty=Tensor[(3, 3, 16, 32), int8] span=model/conv2d_3/Conv2D:0:0 */, %v_param_8: Tensor[(32), int32] /* ty=Tensor[(32), int32] span=model/activation_3/Relu;model/batch_normalization_3/FusedBatchNormV3;model/conv2d_3/BiasAdd/ReadVariableOp/resource;model/conv2d_3/BiasAdd;model/conv2d_5/Conv2D;model/conv2d_3/Conv2D:0:0 */, %v_param_9: Tensor[(3, 3, 32, 32), int8] /* ty=Tensor[(3, 3, 32, 32), int8] span=model/conv2d_4/Conv2D:0:0 */, %v_param_10: Tensor[(32), int32] /* ty=Tensor[(32), int32] span=model/batch_normalization_4/FusedBatchNormV3;model/conv2d_4/BiasAdd/ReadVariableOp/resource;model/conv2d_4/BiasAdd:0:0 */, %v_param_17: Tensor[(1, 1, 32, 64), int8] /* ty=Tensor[(1, 1, 32, 64), int8] span=model/conv2d_8/Conv2D:0:0 */, %v_param_18: Tensor[(64), int32] /* ty=Tensor[(64), int32] span=model/conv2d_8/BiasAdd;model/conv2d_8/Conv2D;model/conv2d_8/BiasAdd/ReadVariableOp/resource:0:0 */, %v_param_13: Tensor[(3, 3, 32, 64), int8] /* ty=Tensor[(3, 3, 32, 64), int8] span=model/conv2d_6/Conv2D:0:0 */, %v_param_14: Tensor[(64), int32] /* ty=Tensor[(64), int32] span=model/activation_5/Relu;model/batch_normalization_5/FusedBatchNormV3;model/conv2d_6/BiasAdd/ReadVariableOp/resource;model/conv2d_6/BiasAdd;model/conv2d_8/Conv2D;model/conv2d_6/Conv2D:0:0 */, %v_param_15: Tensor[(3, 3, 64, 64), int8] /* ty=Tensor[(3, 3, 64, 64), int8] span=model/conv2d_7/Conv2D:0:0 */, %v_param_16: Tensor[(64), int32] /* ty=Tensor[(64), int32] span=model/batch_normalization_6/FusedBatchNormV3;model/conv2d_7/BiasAdd/ReadVariableOp/resource;model/conv2d_7/BiasAdd:0:0 */, %v_param_19: Tensor[(10, 64), int8] /* ty=Tensor[(10, 64), int8] span=model/dense/MatMul:0:0 */, %v_param_20: Tensor[(10), int32] /* ty=Tensor[(10), int32] span=model/dense/BiasAdd/ReadVariableOp/resource:0:0 */, output_tensor_names=["Identity_int8"]) -> Tensor[(1, 10), int8] {
  %0 = qnn.conv2d(%input_1_int8, %v_param_1, -128 /* ty=int32 span=model/activation/Relu;model/batch_normalization/FusedBatchNormV3;model/conv2d/BiasAdd/ReadVariableOp/resource;model/conv2d/BiasAdd;model/conv2d_2/Conv2D;model/conv2d/Conv2D1:0:0 */, 0 /* ty=int32 span=model/activation/Relu;model/batch_normalization/FusedBatchNormV3;model/conv2d/BiasAdd/ReadVariableOp/resource;model/conv2d/BiasAdd;model/conv2d_2/Conv2D;model/conv2d/Conv2D1:0:0 */, 1f /* ty=float32 span=model/activation/Relu;model/batch_normalization/FusedBatchNormV3;model/conv2d/BiasAdd/ReadVariableOp/resource;model/conv2d/BiasAdd;model/conv2d_2/Conv2D;model/conv2d/Conv2D1:0:0 */, meta[relay.Constant][0] /* ty=Tensor[(16), float32] span=model/activation/Relu;model/batch_normalization/FusedBatchNormV3;model/conv2d/BiasAdd/ReadVariableOp/resource;model/conv2d/BiasAdd;model/conv2d_2/Conv2D;model/conv2d/Conv2D1:0:0 */, padding=[1, 1, 1, 1], channels=16, kernel_size=[3, 3], data_layout="NHWC", kernel_layout="HWIO", out_dtype="int32") /* ty=Tensor[(1, 32, 32, 16), int32] span=model/activation/Relu;model/batch_normalization/FusedBatchNormV3;model/conv2d/BiasAdd/ReadVariableOp/resource;model/conv2d/BiasAdd;model/conv2d_2/Conv2D;model/conv2d/Conv2D1:0:0 */;
  %1 = nn.bias_add(%0, %v_param_2, axis=3) /* ty=Tensor[(1, 32, 32, 16), int32] span=model/activation/Relu;model/batch_normalization/FusedBatchNormV3;model/conv2d/BiasAdd/ReadVariableOp/resource;model/conv2d/BiasAdd;model/conv2d_2/Conv2D;model/conv2d/Conv2D1:0:0 */;
  %2 = qnn.requantize(%1, meta[relay.Constant][1] /* ty=Tensor[(16), float32] span=model/activation/Relu;model/batch_normalization/FusedBatchNormV3;model/conv2d/BiasAdd/ReadVariableOp/resource;model/conv2d/BiasAdd;model/conv2d_2/Conv2D;model/conv2d/Conv2D1:0:0 */, 0 /* ty=int32 span=model/activation/Relu;model/batch_normalization/FusedBatchNormV3;model/conv2d/BiasAdd/ReadVariableOp/resource;model/conv2d/BiasAdd;model/conv2d_2/Conv2D;model/conv2d/Conv2D1:0:0 */, 0.0393936f /* ty=float32 span=model/activation/Relu;model/batch_normalization/FusedBatchNormV3;model/conv2d/BiasAdd/ReadVariableOp/resource;model/conv2d/BiasAdd;model/conv2d_2/Conv2D;model/conv2d/Conv2D1:0:0 */, -128 /* ty=int32 span=model/activation/Relu;model/batch_normalization/FusedBatchNormV3;model/conv2d/BiasAdd/ReadVariableOp/resource;model/conv2d/BiasAdd;model/conv2d_2/Conv2D;model/conv2d/Conv2D1:0:0 */, axis=3, rounding="UPWARD", compute_dtype="int64", out_dtype="int8") /* ty=Tensor[(1, 32, 32, 16), int8] span=model/activation/Relu;model/batch_normalization/FusedBatchNormV3;model/conv2d/BiasAdd/ReadVariableOp/resource;model/conv2d/BiasAdd;model/conv2d_2/Conv2D;model/conv2d/Conv2D1:0:0 */;
  %3 = clip(%2, a_min=-128f, a_max=127f) /* ty=Tensor[(1, 32, 32, 16), int8] span=model/activation/Relu;model/batch_normalization/FusedBatchNormV3;model/conv2d/BiasAdd/ReadVariableOp/resource;model/conv2d/BiasAdd;model/conv2d_2/Conv2D;model/conv2d/Conv2D1:0:0 */;
  %4 = qnn.conv2d(%3, %v_param_3, -128 /* ty=int32 span=model/activation_1/Relu;model/batch_normalization_1/FusedBatchNormV3;model/conv2d_1/BiasAdd/ReadVariableOp/resource;model/conv2d_1/BiasAdd;model/conv2d_2/Conv2D;model/conv2d_1/Conv2D1:0:0 */, 0 /* ty=int32 span=model/activation_1/Relu;model/batch_normalization_1/FusedBatchNormV3;model/conv2d_1/BiasAdd/ReadVariableOp/resource;model/conv2d_1/BiasAdd;model/conv2d_2/Conv2D;model/conv2d_1/Conv2D1:0:0 */, 0.0393936f /* ty=float32 span=model/activation_1/Relu;model/batch_normalization_1/FusedBatchNormV3;model/conv2d_1/BiasAdd/ReadVariableOp/resource;model/conv2d_1/BiasAdd;model/conv2d_2/Conv2D;model/conv2d_1/Conv2D1:0:0 */, meta[relay.Constant][2] /* ty=Tensor[(16), float32] span=model/activation_1/Relu;model/batch_normalization_1/FusedBatchNormV3;model/conv2d_1/BiasAdd/ReadVariableOp/resource;model/conv2d_1/BiasAdd;model/conv2d_2/Conv2D;model/conv2d_1/Conv2D1:0:0 */, padding=[1, 1, 1, 1], channels=16, kernel_size=[3, 3], data_layout="NHWC", kernel_layout="HWIO", out_dtype="int32") /* ty=Tensor[(1, 32, 32, 16), int32] span=model/activation_1/Relu;model/batch_normalization_1/FusedBatchNormV3;model/conv2d_1/BiasAdd/ReadVariableOp/resource;model/conv2d_1/BiasAdd;model/conv2d_2/Conv2D;model/conv2d_1/Conv2D1:0:0 */;
  %5 = nn.bias_add(%4, %v_param_4, axis=3) /* ty=Tensor[(1, 32, 32, 16), int32] span=model/activation_1/Relu;model/batch_normalization_1/FusedBatchNormV3;model/conv2d_1/BiasAdd/ReadVariableOp/resource;model/conv2d_1/BiasAdd;model/conv2d_2/Conv2D;model/conv2d_1/Conv2D1:0:0 */;
  %6 = qnn.requantize(%5, meta[relay.Constant][3] /* ty=Tensor[(16), float32] span=model/activation_1/Relu;model/batch_normalization_1/FusedBatchNormV3;model/conv2d_1/BiasAdd/ReadVariableOp/resource;model/conv2d_1/BiasAdd;model/conv2d_2/Conv2D;model/conv2d_1/Conv2D1:0:0 */, 0 /* ty=int32 span=model/activation_1/Relu;model/batch_normalization_1/FusedBatchNormV3;model/conv2d_1/BiasAdd/ReadVariableOp/resource;model/conv2d_1/BiasAdd;model/conv2d_2/Conv2D;model/conv2d_1/Conv2D1:0:0 */, 0.0762932f /* ty=float32 span=model/activation_1/Relu;model/batch_normalization_1/FusedBatchNormV3;model/conv2d_1/BiasAdd/ReadVariableOp/resource;model/conv2d_1/BiasAdd;model/conv2d_2/Conv2D;model/conv2d_1/Conv2D1:0:0 */, -128 /* ty=int32 span=model/activation_1/Relu;model/batch_normalization_1/FusedBatchNormV3;model/conv2d_1/BiasAdd/ReadVariableOp/resource;model/conv2d_1/BiasAdd;model/conv2d_2/Conv2D;model/conv2d_1/Conv2D1:0:0 */, axis=3, rounding="UPWARD", compute_dtype="int64", out_dtype="int8") /* ty=Tensor[(1, 32, 32, 16), int8] span=model/activation_1/Relu;model/batch_normalization_1/FusedBatchNormV3;model/conv2d_1/BiasAdd/ReadVariableOp/resource;model/conv2d_1/BiasAdd;model/conv2d_2/Conv2D;model/conv2d_1/Conv2D1:0:0 */;
  %7 = clip(%6, a_min=-128f, a_max=127f) /* ty=Tensor[(1, 32, 32, 16), int8] span=model/activation_1/Relu;model/batch_normalization_1/FusedBatchNormV3;model/conv2d_1/BiasAdd/ReadVariableOp/resource;model/conv2d_1/BiasAdd;model/conv2d_2/Conv2D;model/conv2d_1/Conv2D1:0:0 */;
  %8 = qnn.conv2d(%7, %v_param_5, -128 /* ty=int32 span=model/batch_normalization_2/FusedBatchNormV3;model/conv2d_2/BiasAdd/ReadVariableOp/resource;model/conv2d_2/BiasAdd;model/conv2d_2/Conv2D:0:0 */, 0 /* ty=int32 span=model/batch_normalization_2/FusedBatchNormV3;model/conv2d_2/BiasAdd/ReadVariableOp/resource;model/conv2d_2/BiasAdd;model/conv2d_2/Conv2D:0:0 */, 0.0762932f /* ty=float32 span=model/batch_normalization_2/FusedBatchNormV3;model/conv2d_2/BiasAdd/ReadVariableOp/resource;model/conv2d_2/BiasAdd;model/conv2d_2/Conv2D:0:0 */, meta[relay.Constant][4] /* ty=Tensor[(16), float32] span=model/batch_normalization_2/FusedBatchNormV3;model/conv2d_2/BiasAdd/ReadVariableOp/resource;model/conv2d_2/BiasAdd;model/conv2d_2/Conv2D:0:0 */, padding=[1, 1, 1, 1], channels=16, kernel_size=[3, 3], data_layout="NHWC", kernel_layout="HWIO", out_dtype="int32") /* ty=Tensor[(1, 32, 32, 16), int32] span=model/batch_normalization_2/FusedBatchNormV3;model/conv2d_2/BiasAdd/ReadVariableOp/resource;model/conv2d_2/BiasAdd;model/conv2d_2/Conv2D:0:0 */;
  %9 = nn.bias_add(%8, %v_param_6, axis=3) /* ty=Tensor[(1, 32, 32, 16), int32] span=model/batch_normalization_2/FusedBatchNormV3;model/conv2d_2/BiasAdd/ReadVariableOp/resource;model/conv2d_2/BiasAdd;model/conv2d_2/Conv2D:0:0 */;
  %10 = qnn.requantize(%9, meta[relay.Constant][5] /* ty=Tensor[(16), float32] span=model/batch_normalization_2/FusedBatchNormV3;model/conv2d_2/BiasAdd/ReadVariableOp/resource;model/conv2d_2/BiasAdd;model/conv2d_2/Conv2D:0:0 */, 0 /* ty=int32 span=model/batch_normalization_2/FusedBatchNormV3;model/conv2d_2/BiasAdd/ReadVariableOp/resource;model/conv2d_2/BiasAdd;model/conv2d_2/Conv2D:0:0 */, 0.104195f /* ty=float32 span=model/batch_normalization_2/FusedBatchNormV3;model/conv2d_2/BiasAdd/ReadVariableOp/resource;model/conv2d_2/BiasAdd;model/conv2d_2/Conv2D:0:0 */, 4 /* ty=int32 span=model/batch_normalization_2/FusedBatchNormV3;model/conv2d_2/BiasAdd/ReadVariableOp/resource;model/conv2d_2/BiasAdd;model/conv2d_2/Conv2D:0:0 */, axis=3, rounding="UPWARD", compute_dtype="int64", out_dtype="int8") /* ty=Tensor[(1, 32, 32, 16), int8] span=model/batch_normalization_2/FusedBatchNormV3;model/conv2d_2/BiasAdd/ReadVariableOp/resource;model/conv2d_2/BiasAdd;model/conv2d_2/Conv2D:0:0 */;
  %11 = qnn.add(%3, %10, 0.0393936f /* ty=float32 span=model/activation_2/Relu;model/add/add:0:0 */, -128 /* ty=int32 span=model/activation_2/Relu;model/add/add:0:0 */, 0.104195f /* ty=float32 span=model/activation_2/Relu;model/add/add:0:0 */, 4 /* ty=int32 span=model/activation_2/Relu;model/add/add:0:0 */, 0.0509457f /* ty=float32 span=model/activation_2/Relu;model/add/add:0:0 */, -128 /* ty=int32 span=model/activation_2/Relu;model/add/add:0:0 */) /* ty=Tensor[(1, 32, 32, 16), int8] span=model/activation_2/Relu;model/add/add:0:0 */;
  %12 = clip(%11, a_min=-128f, a_max=127f) /* ty=Tensor[(1, 32, 32, 16), int8] span=model/activation_2/Relu;model/add/add:0:0 */;
  %13 = qnn.conv2d(%12, %v_param_11, -128 /* ty=int32 span=model/conv2d_5/BiasAdd;model/conv2d_5/Conv2D;model/conv2d_5/BiasAdd/ReadVariableOp/resource1:0:0 */, 0 /* ty=int32 span=model/conv2d_5/BiasAdd;model/conv2d_5/Conv2D;model/conv2d_5/BiasAdd/ReadVariableOp/resource1:0:0 */, 0.0509457f /* ty=float32 span=model/conv2d_5/BiasAdd;model/conv2d_5/Conv2D;model/conv2d_5/BiasAdd/ReadVariableOp/resource1:0:0 */, meta[relay.Constant][6] /* ty=Tensor[(32), float32] span=model/conv2d_5/BiasAdd;model/conv2d_5/Conv2D;model/conv2d_5/BiasAdd/ReadVariableOp/resource1:0:0 */, strides=[2, 2], padding=[0, 0, 0, 0], channels=32, kernel_size=[1, 1], data_layout="NHWC", kernel_layout="HWIO", out_dtype="int32") /* ty=Tensor[(1, 16, 16, 32), int32] span=model/conv2d_5/BiasAdd;model/conv2d_5/Conv2D;model/conv2d_5/BiasAdd/ReadVariableOp/resource1:0:0 */;
  %14 = nn.bias_add(%13, %v_param_12, axis=3) /* ty=Tensor[(1, 16, 16, 32), int32] span=model/conv2d_5/BiasAdd;model/conv2d_5/Conv2D;model/conv2d_5/BiasAdd/ReadVariableOp/resource1:0:0 */;
  %15 = qnn.conv2d(%12, %v_param_7, -128 /* ty=int32 span=model/activation_3/Relu;model/batch_normalization_3/FusedBatchNormV3;model/conv2d_3/BiasAdd/ReadVariableOp/resource;model/conv2d_3/BiasAdd;model/conv2d_5/Conv2D;model/conv2d_3/Conv2D1:0:0 */, 0 /* ty=int32 span=model/activation_3/Relu;model/batch_normalization_3/FusedBatchNormV3;model/conv2d_3/BiasAdd/ReadVariableOp/resource;model/conv2d_3/BiasAdd;model/conv2d_5/Conv2D;model/conv2d_3/Conv2D1:0:0 */, 0.0509457f /* ty=float32 span=model/activation_3/Relu;model/batch_normalization_3/FusedBatchNormV3;model/conv2d_3/BiasAdd/ReadVariableOp/resource;model/conv2d_3/BiasAdd;model/conv2d_5/Conv2D;model/conv2d_3/Conv2D1:0:0 */, meta[relay.Constant][8] /* ty=Tensor[(32), float32] span=model/activation_3/Relu;model/batch_normalization_3/FusedBatchNormV3;model/conv2d_3/BiasAdd/ReadVariableOp/resource;model/conv2d_3/BiasAdd;model/conv2d_5/Conv2D;model/conv2d_3/Conv2D1:0:0 */, strides=[2, 2], padding=[0, 0, 1, 1], channels=32, kernel_size=[3, 3], data_layout="NHWC", kernel_layout="HWIO", out_dtype="int32") /* ty=Tensor[(1, 16, 16, 32), int32] span=model/activation_3/Relu;model/batch_normalization_3/FusedBatchNormV3;model/conv2d_3/BiasAdd/ReadVariableOp/resource;model/conv2d_3/BiasAdd;model/conv2d_5/Conv2D;model/conv2d_3/Conv2D1:0:0 */;
  %16 = nn.bias_add(%15, %v_param_8, axis=3) /* ty=Tensor[(1, 16, 16, 32), int32] span=model/activation_3/Relu;model/batch_normalization_3/FusedBatchNormV3;model/conv2d_3/BiasAdd/ReadVariableOp/resource;model/conv2d_3/BiasAdd;model/conv2d_5/Conv2D;model/conv2d_3/Conv2D1:0:0 */;
  %17 = qnn.requantize(%16, meta[relay.Constant][9] /* ty=Tensor[(32), float32] span=model/activation_3/Relu;model/batch_normalization_3/FusedBatchNormV3;model/conv2d_3/BiasAdd/ReadVariableOp/resource;model/conv2d_3/BiasAdd;model/conv2d_5/Conv2D;model/conv2d_3/Conv2D1:0:0 */, 0 /* ty=int32 span=model/activation_3/Relu;model/batch_normalization_3/FusedBatchNormV3;model/conv2d_3/BiasAdd/ReadVariableOp/resource;model/conv2d_3/BiasAdd;model/conv2d_5/Conv2D;model/conv2d_3/Conv2D1:0:0 */, 0.0456728f /* ty=float32 span=model/activation_3/Relu;model/batch_normalization_3/FusedBatchNormV3;model/conv2d_3/BiasAdd/ReadVariableOp/resource;model/conv2d_3/BiasAdd;model/conv2d_5/Conv2D;model/conv2d_3/Conv2D1:0:0 */, -128 /* ty=int32 span=model/activation_3/Relu;model/batch_normalization_3/FusedBatchNormV3;model/conv2d_3/BiasAdd/ReadVariableOp/resource;model/conv2d_3/BiasAdd;model/conv2d_5/Conv2D;model/conv2d_3/Conv2D1:0:0 */, axis=3, rounding="UPWARD", compute_dtype="int64", out_dtype="int8") /* ty=Tensor[(1, 16, 16, 32), int8] span=model/activation_3/Relu;model/batch_normalization_3/FusedBatchNormV3;model/conv2d_3/BiasAdd/ReadVariableOp/resource;model/conv2d_3/BiasAdd;model/conv2d_5/Conv2D;model/conv2d_3/Conv2D1:0:0 */;
  %18 = clip(%17, a_min=-128f, a_max=127f) /* ty=Tensor[(1, 16, 16, 32), int8] span=model/activation_3/Relu;model/batch_normalization_3/FusedBatchNormV3;model/conv2d_3/BiasAdd/ReadVariableOp/resource;model/conv2d_3/BiasAdd;model/conv2d_5/Conv2D;model/conv2d_3/Conv2D1:0:0 */;
  %19 = qnn.conv2d(%18, %v_param_9, -128 /* ty=int32 span=model/batch_normalization_4/FusedBatchNormV3;model/conv2d_4/BiasAdd/ReadVariableOp/resource;model/conv2d_4/BiasAdd;model/conv2d_5/Conv2D;model/conv2d_4/Conv2D:0:0 */, 0 /* ty=int32 span=model/batch_normalization_4/FusedBatchNormV3;model/conv2d_4/BiasAdd/ReadVariableOp/resource;model/conv2d_4/BiasAdd;model/conv2d_5/Conv2D;model/conv2d_4/Conv2D:0:0 */, 0.0456728f /* ty=float32 span=model/batch_normalization_4/FusedBatchNormV3;model/conv2d_4/BiasAdd/ReadVariableOp/resource;model/conv2d_4/BiasAdd;model/conv2d_5/Conv2D;model/conv2d_4/Conv2D:0:0 */, meta[relay.Constant][10] /* ty=Tensor[(32), float32] span=model/batch_normalization_4/FusedBatchNormV3;model/conv2d_4/BiasAdd/ReadVariableOp/resource;model/conv2d_4/BiasAdd;model/conv2d_5/Conv2D;model/conv2d_4/Conv2D:0:0 */, padding=[1, 1, 1, 1], channels=32, kernel_size=[3, 3], data_layout="NHWC", kernel_layout="HWIO", out_dtype="int32") /* ty=Tensor[(1, 16, 16, 32), int32] span=model/batch_normalization_4/FusedBatchNormV3;model/conv2d_4/BiasAdd/ReadVariableOp/resource;model/conv2d_4/BiasAdd;model/conv2d_5/Conv2D;model/conv2d_4/Conv2D:0:0 */;
  %20 = nn.bias_add(%19, %v_param_10, axis=3) /* ty=Tensor[(1, 16, 16, 32), int32] span=model/batch_normalization_4/FusedBatchNormV3;model/conv2d_4/BiasAdd/ReadVariableOp/resource;model/conv2d_4/BiasAdd;model/conv2d_5/Conv2D;model/conv2d_4/Conv2D:0:0 */;
  %21 = qnn.requantize(%14, meta[relay.Constant][7] /* ty=Tensor[(32), float32] span=model/conv2d_5/BiasAdd;model/conv2d_5/Conv2D;model/conv2d_5/BiasAdd/ReadVariableOp/resource1:0:0 */, 0 /* ty=int32 span=model/conv2d_5/BiasAdd;model/conv2d_5/Conv2D;model/conv2d_5/BiasAdd/ReadVariableOp/resource1:0:0 */, 0.0447614f /* ty=float32 span=model/conv2d_5/BiasAdd;model/conv2d_5/Conv2D;model/conv2d_5/BiasAdd/ReadVariableOp/resource1:0:0 */, -17 /* ty=int32 span=model/conv2d_5/BiasAdd;model/conv2d_5/Conv2D;model/conv2d_5/BiasAdd/ReadVariableOp/resource1:0:0 */, axis=3, rounding="UPWARD", compute_dtype="int64", out_dtype="int8") /* ty=Tensor[(1, 16, 16, 32), int8] span=model/conv2d_5/BiasAdd;model/conv2d_5/Conv2D;model/conv2d_5/BiasAdd/ReadVariableOp/resource1:0:0 */;
  %22 = qnn.requantize(%20, meta[relay.Constant][11] /* ty=Tensor[(32), float32] span=model/batch_normalization_4/FusedBatchNormV3;model/conv2d_4/BiasAdd/ReadVariableOp/resource;model/conv2d_4/BiasAdd;model/conv2d_5/Conv2D;model/conv2d_4/Conv2D:0:0 */, 0 /* ty=int32 span=model/batch_normalization_4/FusedBatchNormV3;model/conv2d_4/BiasAdd/ReadVariableOp/resource;model/conv2d_4/BiasAdd;model/conv2d_5/Conv2D;model/conv2d_4/Conv2D:0:0 */, 0.113119f /* ty=float32 span=model/batch_normalization_4/FusedBatchNormV3;model/conv2d_4/BiasAdd/ReadVariableOp/resource;model/conv2d_4/BiasAdd;model/conv2d_5/Conv2D;model/conv2d_4/Conv2D:0:0 */, 4 /* ty=int32 span=model/batch_normalization_4/FusedBatchNormV3;model/conv2d_4/BiasAdd/ReadVariableOp/resource;model/conv2d_4/BiasAdd;model/conv2d_5/Conv2D;model/conv2d_4/Conv2D:0:0 */, axis=3, rounding="UPWARD", compute_dtype="int64", out_dtype="int8") /* ty=Tensor[(1, 16, 16, 32), int8] span=model/batch_normalization_4/FusedBatchNormV3;model/conv2d_4/BiasAdd/ReadVariableOp/resource;model/conv2d_4/BiasAdd;model/conv2d_5/Conv2D;model/conv2d_4/Conv2D:0:0 */;
  %23 = qnn.add(%21, %22, 0.0447614f /* ty=float32 span=model/activation_4/Relu;model/add_1/add:0:0 */, -17 /* ty=int32 span=model/activation_4/Relu;model/add_1/add:0:0 */, 0.113119f /* ty=float32 span=model/activation_4/Relu;model/add_1/add:0:0 */, 4 /* ty=int32 span=model/activation_4/Relu;model/add_1/add:0:0 */, 0.0532362f /* ty=float32 span=model/activation_4/Relu;model/add_1/add:0:0 */, -128 /* ty=int32 span=model/activation_4/Relu;model/add_1/add:0:0 */) /* ty=Tensor[(1, 16, 16, 32), int8] span=model/activation_4/Relu;model/add_1/add:0:0 */;
  %24 = clip(%23, a_min=-128f, a_max=127f) /* ty=Tensor[(1, 16, 16, 32), int8] span=model/activation_4/Relu;model/add_1/add:0:0 */;
  %25 = qnn.conv2d(%24, %v_param_17, -128 /* ty=int32 span=model/conv2d_8/BiasAdd;model/conv2d_8/Conv2D;model/conv2d_8/BiasAdd/ReadVariableOp/resource1:0:0 */, 0 /* ty=int32 span=model/conv2d_8/BiasAdd;model/conv2d_8/Conv2D;model/conv2d_8/BiasAdd/ReadVariableOp/resource1:0:0 */, 0.0532362f /* ty=float32 span=model/conv2d_8/BiasAdd;model/conv2d_8/Conv2D;model/conv2d_8/BiasAdd/ReadVariableOp/resource1:0:0 */, meta[relay.Constant][12] /* ty=Tensor[(64), float32] span=model/conv2d_8/BiasAdd;model/conv2d_8/Conv2D;model/conv2d_8/BiasAdd/ReadVariableOp/resource1:0:0 */, strides=[2, 2], padding=[0, 0, 0, 0], channels=64, kernel_size=[1, 1], data_layout="NHWC", kernel_layout="HWIO", out_dtype="int32") /* ty=Tensor[(1, 8, 8, 64), int32] span=model/conv2d_8/BiasAdd;model/conv2d_8/Conv2D;model/conv2d_8/BiasAdd/ReadVariableOp/resource1:0:0 */;
  %26 = nn.bias_add(%25, %v_param_18, axis=3) /* ty=Tensor[(1, 8, 8, 64), int32] span=model/conv2d_8/BiasAdd;model/conv2d_8/Conv2D;model/conv2d_8/BiasAdd/ReadVariableOp/resource1:0:0 */;
  %27 = qnn.conv2d(%24, %v_param_13, -128 /* ty=int32 span=model/activation_5/Relu;model/batch_normalization_5/FusedBatchNormV3;model/conv2d_6/BiasAdd/ReadVariableOp/resource;model/conv2d_6/BiasAdd;model/conv2d_8/Conv2D;model/conv2d_6/Conv2D1:0:0 */, 0 /* ty=int32 span=model/activation_5/Relu;model/batch_normalization_5/FusedBatchNormV3;model/conv2d_6/BiasAdd/ReadVariableOp/resource;model/conv2d_6/BiasAdd;model/conv2d_8/Conv2D;model/conv2d_6/Conv2D1:0:0 */, 0.0532362f /* ty=float32 span=model/activation_5/Relu;model/batch_normalization_5/FusedBatchNormV3;model/conv2d_6/BiasAdd/ReadVariableOp/resource;model/conv2d_6/BiasAdd;model/conv2d_8/Conv2D;model/conv2d_6/Conv2D1:0:0 */, meta[relay.Constant][14] /* ty=Tensor[(64), float32] span=model/activation_5/Relu;model/batch_normalization_5/FusedBatchNormV3;model/conv2d_6/BiasAdd/ReadVariableOp/resource;model/conv2d_6/BiasAdd;model/conv2d_8/Conv2D;model/conv2d_6/Conv2D1:0:0 */, strides=[2, 2], padding=[0, 0, 1, 1], channels=64, kernel_size=[3, 3], data_layout="NHWC", kernel_layout="HWIO", out_dtype="int32") /* ty=Tensor[(1, 8, 8, 64), int32] span=model/activation_5/Relu;model/batch_normalization_5/FusedBatchNormV3;model/conv2d_6/BiasAdd/ReadVariableOp/resource;model/conv2d_6/BiasAdd;model/conv2d_8/Conv2D;model/conv2d_6/Conv2D1:0:0 */;
  %28 = nn.bias_add(%27, %v_param_14, axis=3) /* ty=Tensor[(1, 8, 8, 64), int32] span=model/activation_5/Relu;model/batch_normalization_5/FusedBatchNormV3;model/conv2d_6/BiasAdd/ReadVariableOp/resource;model/conv2d_6/BiasAdd;model/conv2d_8/Conv2D;model/conv2d_6/Conv2D1:0:0 */;
  %29 = qnn.requantize(%28, meta[relay.Constant][15] /* ty=Tensor[(64), float32] span=model/activation_5/Relu;model/batch_normalization_5/FusedBatchNormV3;model/conv2d_6/BiasAdd/ReadVariableOp/resource;model/conv2d_6/BiasAdd;model/conv2d_8/Conv2D;model/conv2d_6/Conv2D1:0:0 */, 0 /* ty=int32 span=model/activation_5/Relu;model/batch_normalization_5/FusedBatchNormV3;model/conv2d_6/BiasAdd/ReadVariableOp/resource;model/conv2d_6/BiasAdd;model/conv2d_8/Conv2D;model/conv2d_6/Conv2D1:0:0 */, 0.0284502f /* ty=float32 span=model/activation_5/Relu;model/batch_normalization_5/FusedBatchNormV3;model/conv2d_6/BiasAdd/ReadVariableOp/resource;model/conv2d_6/BiasAdd;model/conv2d_8/Conv2D;model/conv2d_6/Conv2D1:0:0 */, -128 /* ty=int32 span=model/activation_5/Relu;model/batch_normalization_5/FusedBatchNormV3;model/conv2d_6/BiasAdd/ReadVariableOp/resource;model/conv2d_6/BiasAdd;model/conv2d_8/Conv2D;model/conv2d_6/Conv2D1:0:0 */, axis=3, rounding="UPWARD", compute_dtype="int64", out_dtype="int8") /* ty=Tensor[(1, 8, 8, 64), int8] span=model/activation_5/Relu;model/batch_normalization_5/FusedBatchNormV3;model/conv2d_6/BiasAdd/ReadVariableOp/resource;model/conv2d_6/BiasAdd;model/conv2d_8/Conv2D;model/conv2d_6/Conv2D1:0:0 */;
  %30 = clip(%29, a_min=-128f, a_max=127f) /* ty=Tensor[(1, 8, 8, 64), int8] span=model/activation_5/Relu;model/batch_normalization_5/FusedBatchNormV3;model/conv2d_6/BiasAdd/ReadVariableOp/resource;model/conv2d_6/BiasAdd;model/conv2d_8/Conv2D;model/conv2d_6/Conv2D1:0:0 */;
  %31 = qnn.conv2d(%30, %v_param_15, -128 /* ty=int32 span=model/batch_normalization_6/FusedBatchNormV3;model/conv2d_7/BiasAdd/ReadVariableOp/resource;model/conv2d_7/BiasAdd;model/conv2d_8/Conv2D;model/conv2d_7/Conv2D:0:0 */, 0 /* ty=int32 span=model/batch_normalization_6/FusedBatchNormV3;model/conv2d_7/BiasAdd/ReadVariableOp/resource;model/conv2d_7/BiasAdd;model/conv2d_8/Conv2D;model/conv2d_7/Conv2D:0:0 */, 0.0284502f /* ty=float32 span=model/batch_normalization_6/FusedBatchNormV3;model/conv2d_7/BiasAdd/ReadVariableOp/resource;model/conv2d_7/BiasAdd;model/conv2d_8/Conv2D;model/conv2d_7/Conv2D:0:0 */, meta[relay.Constant][16] /* ty=Tensor[(64), float32] span=model/batch_normalization_6/FusedBatchNormV3;model/conv2d_7/BiasAdd/ReadVariableOp/resource;model/conv2d_7/BiasAdd;model/conv2d_8/Conv2D;model/conv2d_7/Conv2D:0:0 */, padding=[1, 1, 1, 1], channels=64, kernel_size=[3, 3], data_layout="NHWC", kernel_layout="HWIO", out_dtype="int32") /* ty=Tensor[(1, 8, 8, 64), int32] span=model/batch_normalization_6/FusedBatchNormV3;model/conv2d_7/BiasAdd/ReadVariableOp/resource;model/conv2d_7/BiasAdd;model/conv2d_8/Conv2D;model/conv2d_7/Conv2D:0:0 */;
  %32 = nn.bias_add(%31, %v_param_16, axis=3) /* ty=Tensor[(1, 8, 8, 64), int32] span=model/batch_normalization_6/FusedBatchNormV3;model/conv2d_7/BiasAdd/ReadVariableOp/resource;model/conv2d_7/BiasAdd;model/conv2d_8/Conv2D;model/conv2d_7/Conv2D:0:0 */;
  %33 = qnn.requantize(%26, meta[relay.Constant][13] /* ty=Tensor[(64), float32] span=model/conv2d_8/BiasAdd;model/conv2d_8/Conv2D;model/conv2d_8/BiasAdd/ReadVariableOp/resource1:0:0 */, 0 /* ty=int32 span=model/conv2d_8/BiasAdd;model/conv2d_8/Conv2D;model/conv2d_8/BiasAdd/ReadVariableOp/resource1:0:0 */, 0.0838583f /* ty=float32 span=model/conv2d_8/BiasAdd;model/conv2d_8/Conv2D;model/conv2d_8/BiasAdd/ReadVariableOp/resource1:0:0 */, 38 /* ty=int32 span=model/conv2d_8/BiasAdd;model/conv2d_8/Conv2D;model/conv2d_8/BiasAdd/ReadVariableOp/resource1:0:0 */, axis=3, rounding="UPWARD", compute_dtype="int64", out_dtype="int8") /* ty=Tensor[(1, 8, 8, 64), int8] span=model/conv2d_8/BiasAdd;model/conv2d_8/Conv2D;model/conv2d_8/BiasAdd/ReadVariableOp/resource1:0:0 */;
  %34 = qnn.requantize(%32, meta[relay.Constant][17] /* ty=Tensor[(64), float32] span=model/batch_normalization_6/FusedBatchNormV3;model/conv2d_7/BiasAdd/ReadVariableOp/resource;model/conv2d_7/BiasAdd;model/conv2d_8/Conv2D;model/conv2d_7/Conv2D:0:0 */, 0 /* ty=int32 span=model/batch_normalization_6/FusedBatchNormV3;model/conv2d_7/BiasAdd/ReadVariableOp/resource;model/conv2d_7/BiasAdd;model/conv2d_8/Conv2D;model/conv2d_7/Conv2D:0:0 */, 0.217244f /* ty=float32 span=model/batch_normalization_6/FusedBatchNormV3;model/conv2d_7/BiasAdd/ReadVariableOp/resource;model/conv2d_7/BiasAdd;model/conv2d_8/Conv2D;model/conv2d_7/Conv2D:0:0 */, -2 /* ty=int32 span=model/batch_normalization_6/FusedBatchNormV3;model/conv2d_7/BiasAdd/ReadVariableOp/resource;model/conv2d_7/BiasAdd;model/conv2d_8/Conv2D;model/conv2d_7/Conv2D:0:0 */, axis=3, rounding="UPWARD", compute_dtype="int64", out_dtype="int8") /* ty=Tensor[(1, 8, 8, 64), int8] span=model/batch_normalization_6/FusedBatchNormV3;model/conv2d_7/BiasAdd/ReadVariableOp/resource;model/conv2d_7/BiasAdd;model/conv2d_8/Conv2D;model/conv2d_7/Conv2D:0:0 */;
  %35 = qnn.add(%33, %34, 0.0838583f /* ty=float32 span=model/activation_6/Relu;model/add_2/add:0:0 */, 38 /* ty=int32 span=model/activation_6/Relu;model/add_2/add:0:0 */, 0.217244f /* ty=float32 span=model/activation_6/Relu;model/add_2/add:0:0 */, -2 /* ty=int32 span=model/activation_6/Relu;model/add_2/add:0:0 */, 0.127069f /* ty=float32 span=model/activation_6/Relu;model/add_2/add:0:0 */, -128 /* ty=int32 span=model/activation_6/Relu;model/add_2/add:0:0 */) /* ty=Tensor[(1, 8, 8, 64), int8] span=model/activation_6/Relu;model/add_2/add:0:0 */;
  %36 = clip(%35, a_min=-128f, a_max=127f) /* ty=Tensor[(1, 8, 8, 64), int8] span=model/activation_6/Relu;model/add_2/add:0:0 */;
  %37 = cast(%36, dtype="int32") /* ty=Tensor[(1, 8, 8, 64), int32] span=model/average_pooling2d/AvgPool:0:0 */;
  %38 = nn.avg_pool2d(%37, pool_size=[8, 8], strides=[8, 8], padding=[0, 0, 0, 0], layout="NHWC") /* ty=Tensor[(1, 1, 1, 64), int32] span=model/average_pooling2d/AvgPool:0:0 */;
  %39 = cast(%38, dtype="int8") /* ty=Tensor[(1, 1, 1, 64), int8] span=model/average_pooling2d/AvgPool:0:0 */;
  %40 = reshape(%39, newshape=[-1, 64]) /* ty=Tensor[(1, 64), int8] span=model/flatten/Reshape:0:0 */;
  %41 = reshape(%40, newshape=[-1, 64]) /* ty=Tensor[(1, 64), int8] span=model/dense/MatMul;model/dense/BiasAdd:0:0 */;
  %42 = qnn.dense(%41, %v_param_19, -128 /* ty=int32 span=model/dense/MatMul;model/dense/BiasAdd:0:0 */, 0 /* ty=int32 span=model/dense/MatMul;model/dense/BiasAdd:0:0 */, 0.127069f /* ty=float32 span=model/dense/MatMul;model/dense/BiasAdd:0:0 */, 0.0305544f /* ty=float32 span=model/dense/MatMul;model/dense/BiasAdd:0:0 */, units=10, out_dtype="int32") /* ty=Tensor[(1, 10), int32] span=model/dense/MatMul;model/dense/BiasAdd:0:0 */;
  %43 = nn.bias_add(%42, %v_param_20) /* ty=Tensor[(1, 10), int32] span=model/dense/MatMul;model/dense/BiasAdd:0:0 */;
  %44 = qnn.requantize(%43, 0.00388252f /* ty=float32 span=model/dense/MatMul;model/dense/BiasAdd:0:0 */, 0 /* ty=int32 span=model/dense/MatMul;model/dense/BiasAdd:0:0 */, 0.171854f /* ty=float32 span=model/dense/MatMul;model/dense/BiasAdd:0:0 */, 24 /* ty=int32 span=model/dense/MatMul;model/dense/BiasAdd:0:0 */, rounding="UPWARD", compute_dtype="int64", out_dtype="int8") /* ty=Tensor[(1, 10), int8] span=model/dense/MatMul;model/dense/BiasAdd:0:0 */;
  %45 = qnn.dequantize(%44, 0.171854f /* ty=float32 span=Identity_int8:0:0 */, 24 /* ty=int32 span=Identity_int8:0:0 */, out_dtype="float32") /* ty=Tensor[(1, 10), float32] span=Identity_int8:0:0 */;
  %46 = nn.softmax(%45) /* ty=Tensor[(1, 10), float32] span=Identity_int8:0:0 */;
  qnn.quantize(%46, 0.00390625f /* ty=float32 span=Identity_int8:0:0 */, -128 /* ty=int32 span=Identity_int8:0:0 */, out_dtype="int8") /* ty=Tensor[(1, 10), int8] span=Identity_int8:0:0 */
}

#[metadata]
{
  "root": 1, 
  "nodes": [
    {
      "type_key": ""
    }, 
    {
      "type_key": "Map", 
      "keys": [
        "relay.Constant"
      ], 
      "data": [2]
    }, 
    {
      "type_key": "Array", 
      "data": [
        3, 
        11, 
        15, 
        21, 
        25, 
        31, 
        35, 
        41, 
        45, 
        51, 
        55, 
        61, 
        65, 
        71, 
        75, 
        81, 
        85, 
        91
      ]
    }, 
    {
      "type_key": "relay.Constant", 
      "attrs": {
        "_checked_type_": "8", 
        "data": "0", 
        "span": "6", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "VirtualDevice", 
      "attrs": {
        "device_type_int": "-1", 
        "memory_scope": "5", 
        "target": "0", 
        "virtual_device_id": "-1"
      }
    }, 
    {
      "type_key": "runtime.String"
    }, 
    {
      "type_key": "Span", 
      "attrs": {
        "column": "0", 
        "end_column": "0", 
        "end_line": "0", 
        "line": "0", 
        "source_name": "7"
      }
    }, 
    {
      "type_key": "SourceName", 
      "repr_str": "model/activation/Relu;model/batch_normalization/FusedBatchNormV3;model/conv2d/BiasAdd/ReadVariableOp/resource;model/conv2d/BiasAdd;model/conv2d_2/Conv2D;model/conv2d/Conv2D1"
    }, 
    {
      "type_key": "relay.TensorType", 
      "attrs": {
        "dtype": "float32", 
        "shape": "9", 
        "span": "0"
      }
    }, 
    {
      "type_key": "Array", 
      "data": [10]
    }, 
    {
      "type_key": "IntImm", 
      "attrs": {
        "dtype": "int32", 
        "span": "0", 
        "value": "16"
      }
    }, 
    {
      "type_key": "relay.Constant", 
      "attrs": {
        "_checked_type_": "12", 
        "data": "1", 
        "span": "6", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "relay.TensorType", 
      "attrs": {
        "dtype": "float32", 
        "shape": "13", 
        "span": "0"
      }
    }, 
    {
      "type_key": "Array", 
      "data": [14]
    }, 
    {
      "type_key": "IntImm", 
      "attrs": {
        "dtype": "int32", 
        "span": "0", 
        "value": "16"
      }
    }, 
    {
      "type_key": "relay.Constant", 
      "attrs": {
        "_checked_type_": "18", 
        "data": "2", 
        "span": "16", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "Span", 
      "attrs": {
        "column": "0", 
        "end_column": "0", 
        "end_line": "0", 
        "line": "0", 
        "source_name": "17"
      }
    }, 
    {
      "type_key": "SourceName", 
      "repr_str": "model/activation_1/Relu;model/batch_normalization_1/FusedBatchNormV3;model/conv2d_1/BiasAdd/ReadVariableOp/resource;model/conv2d_1/BiasAdd;model/conv2d_2/Conv2D;model/conv2d_1/Conv2D1"
    }, 
    {
      "type_key": "relay.TensorType", 
      "attrs": {
        "dtype": "float32", 
        "shape": "19", 
        "span": "0"
      }
    }, 
    {
      "type_key": "Array", 
      "data": [20]
    }, 
    {
      "type_key": "IntImm", 
      "attrs": {
        "dtype": "int32", 
        "span": "0", 
        "value": "16"
      }
    }, 
    {
      "type_key": "relay.Constant", 
      "attrs": {
        "_checked_type_": "22", 
        "data": "3", 
        "span": "16", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "relay.TensorType", 
      "attrs": {
        "dtype": "float32", 
        "shape": "23", 
        "span": "0"
      }
    }, 
    {
      "type_key": "Array", 
      "data": [24]
    }, 
    {
      "type_key": "IntImm", 
      "attrs": {
        "dtype": "int32", 
        "span": "0", 
        "value": "16"
      }
    }, 
    {
      "type_key": "relay.Constant", 
      "attrs": {
        "_checked_type_": "28", 
        "data": "4", 
        "span": "26", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "Span", 
      "attrs": {
        "column": "0", 
        "end_column": "0", 
        "end_line": "0", 
        "line": "0", 
        "source_name": "27"
      }
    }, 
    {
      "type_key": "SourceName", 
      "repr_str": "model/batch_normalization_2/FusedBatchNormV3;model/conv2d_2/BiasAdd/ReadVariableOp/resource;model/conv2d_2/BiasAdd;model/conv2d_2/Conv2D"
    }, 
    {
      "type_key": "relay.TensorType", 
      "attrs": {
        "dtype": "float32", 
        "shape": "29", 
        "span": "0"
      }
    }, 
    {
      "type_key": "Array", 
      "data": [30]
    }, 
    {
      "type_key": "IntImm", 
      "attrs": {
        "dtype": "int32", 
        "span": "0", 
        "value": "16"
      }
    }, 
    {
      "type_key": "relay.Constant", 
      "attrs": {
        "_checked_type_": "32", 
        "data": "5", 
        "span": "26", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "relay.TensorType", 
      "attrs": {
        "dtype": "float32", 
        "shape": "33", 
        "span": "0"
      }
    }, 
    {
      "type_key": "Array", 
      "data": [34]
    }, 
    {
      "type_key": "IntImm", 
      "attrs": {
        "dtype": "int32", 
        "span": "0", 
        "value": "16"
      }
    }, 
    {
      "type_key": "relay.Constant", 
      "attrs": {
        "_checked_type_": "38", 
        "data": "6", 
        "span": "36", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "Span", 
      "attrs": {
        "column": "0", 
        "end_column": "0", 
        "end_line": "0", 
        "line": "0", 
        "source_name": "37"
      }
    }, 
    {
      "type_key": "SourceName", 
      "repr_str": "model/conv2d_5/BiasAdd;model/conv2d_5/Conv2D;model/conv2d_5/BiasAdd/ReadVariableOp/resource1"
    }, 
    {
      "type_key": "relay.TensorType", 
      "attrs": {
        "dtype": "float32", 
        "shape": "39", 
        "span": "0"
      }
    }, 
    {
      "type_key": "Array", 
      "data": [40]
    }, 
    {
      "type_key": "IntImm", 
      "attrs": {
        "dtype": "int32", 
        "span": "0", 
        "value": "32"
      }
    }, 
    {
      "type_key": "relay.Constant", 
      "attrs": {
        "_checked_type_": "42", 
        "data": "7", 
        "span": "36", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "relay.TensorType", 
      "attrs": {
        "dtype": "float32", 
        "shape": "43", 
        "span": "0"
      }
    }, 
    {
      "type_key": "Array", 
      "data": [44]
    }, 
    {
      "type_key": "IntImm", 
      "attrs": {
        "dtype": "int32", 
        "span": "0", 
        "value": "32"
      }
    }, 
    {
      "type_key": "relay.Constant", 
      "attrs": {
        "_checked_type_": "48", 
        "data": "8", 
        "span": "46", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "Span", 
      "attrs": {
        "column": "0", 
        "end_column": "0", 
        "end_line": "0", 
        "line": "0", 
        "source_name": "47"
      }
    }, 
    {
      "type_key": "SourceName", 
      "repr_str": "model/activation_3/Relu;model/batch_normalization_3/FusedBatchNormV3;model/conv2d_3/BiasAdd/ReadVariableOp/resource;model/conv2d_3/BiasAdd;model/conv2d_5/Conv2D;model/conv2d_3/Conv2D1"
    }, 
    {
      "type_key": "relay.TensorType", 
      "attrs": {
        "dtype": "float32", 
        "shape": "49", 
        "span": "0"
      }
    }, 
    {
      "type_key": "Array", 
      "data": [50]
    }, 
    {
      "type_key": "IntImm", 
      "attrs": {
        "dtype": "int32", 
        "span": "0", 
        "value": "32"
      }
    }, 
    {
      "type_key": "relay.Constant", 
      "attrs": {
        "_checked_type_": "52", 
        "data": "9", 
        "span": "46", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "relay.TensorType", 
      "attrs": {
        "dtype": "float32", 
        "shape": "53", 
        "span": "0"
      }
    }, 
    {
      "type_key": "Array", 
      "data": [54]
    }, 
    {
      "type_key": "IntImm", 
      "attrs": {
        "dtype": "int32", 
        "span": "0", 
        "value": "32"
      }
    }, 
    {
      "type_key": "relay.Constant", 
      "attrs": {
        "_checked_type_": "58", 
        "data": "10", 
        "span": "56", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "Span", 
      "attrs": {
        "column": "0", 
        "end_column": "0", 
        "end_line": "0", 
        "line": "0", 
        "source_name": "57"
      }
    }, 
    {
      "type_key": "SourceName", 
      "repr_str": "model/batch_normalization_4/FusedBatchNormV3;model/conv2d_4/BiasAdd/ReadVariableOp/resource;model/conv2d_4/BiasAdd;model/conv2d_5/Conv2D;model/conv2d_4/Conv2D"
    }, 
    {
      "type_key": "relay.TensorType", 
      "attrs": {
        "dtype": "float32", 
        "shape": "59", 
        "span": "0"
      }
    }, 
    {
      "type_key": "Array", 
      "data": [60]
    }, 
    {
      "type_key": "IntImm", 
      "attrs": {
        "dtype": "int32", 
        "span": "0", 
        "value": "32"
      }
    }, 
    {
      "type_key": "relay.Constant", 
      "attrs": {
        "_checked_type_": "62", 
        "data": "11", 
        "span": "56", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "relay.TensorType", 
      "attrs": {
        "dtype": "float32", 
        "shape": "63", 
        "span": "0"
      }
    }, 
    {
      "type_key": "Array", 
      "data": [64]
    }, 
    {
      "type_key": "IntImm", 
      "attrs": {
        "dtype": "int32", 
        "span": "0", 
        "value": "32"
      }
    }, 
    {
      "type_key": "relay.Constant", 
      "attrs": {
        "_checked_type_": "68", 
        "data": "12", 
        "span": "66", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "Span", 
      "attrs": {
        "column": "0", 
        "end_column": "0", 
        "end_line": "0", 
        "line": "0", 
        "source_name": "67"
      }
    }, 
    {
      "type_key": "SourceName", 
      "repr_str": "model/conv2d_8/BiasAdd;model/conv2d_8/Conv2D;model/conv2d_8/BiasAdd/ReadVariableOp/resource1"
    }, 
    {
      "type_key": "relay.TensorType", 
      "attrs": {
        "dtype": "float32", 
        "shape": "69", 
        "span": "0"
      }
    }, 
    {
      "type_key": "Array", 
      "data": [70]
    }, 
    {
      "type_key": "IntImm", 
      "attrs": {
        "dtype": "int32", 
        "span": "0", 
        "value": "64"
      }
    }, 
    {
      "type_key": "relay.Constant", 
      "attrs": {
        "_checked_type_": "72", 
        "data": "13", 
        "span": "66", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "relay.TensorType", 
      "attrs": {
        "dtype": "float32", 
        "shape": "73", 
        "span": "0"
      }
    }, 
    {
      "type_key": "Array", 
      "data": [74]
    }, 
    {
      "type_key": "IntImm", 
      "attrs": {
        "dtype": "int32", 
        "span": "0", 
        "value": "64"
      }
    }, 
    {
      "type_key": "relay.Constant", 
      "attrs": {
        "_checked_type_": "78", 
        "data": "14", 
        "span": "76", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "Span", 
      "attrs": {
        "column": "0", 
        "end_column": "0", 
        "end_line": "0", 
        "line": "0", 
        "source_name": "77"
      }
    }, 
    {
      "type_key": "SourceName", 
      "repr_str": "model/activation_5/Relu;model/batch_normalization_5/FusedBatchNormV3;model/conv2d_6/BiasAdd/ReadVariableOp/resource;model/conv2d_6/BiasAdd;model/conv2d_8/Conv2D;model/conv2d_6/Conv2D1"
    }, 
    {
      "type_key": "relay.TensorType", 
      "attrs": {
        "dtype": "float32", 
        "shape": "79", 
        "span": "0"
      }
    }, 
    {
      "type_key": "Array", 
      "data": [80]
    }, 
    {
      "type_key": "IntImm", 
      "attrs": {
        "dtype": "int32", 
        "span": "0", 
        "value": "64"
      }
    }, 
    {
      "type_key": "relay.Constant", 
      "attrs": {
        "_checked_type_": "82", 
        "data": "15", 
        "span": "76", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "relay.TensorType", 
      "attrs": {
        "dtype": "float32", 
        "shape": "83", 
        "span": "0"
      }
    }, 
    {
      "type_key": "Array", 
      "data": [84]
    }, 
    {
      "type_key": "IntImm", 
      "attrs": {
        "dtype": "int32", 
        "span": "0", 
        "value": "64"
      }
    }, 
    {
      "type_key": "relay.Constant", 
      "attrs": {
        "_checked_type_": "88", 
        "data": "16", 
        "span": "86", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "Span", 
      "attrs": {
        "column": "0", 
        "end_column": "0", 
        "end_line": "0", 
        "line": "0", 
        "source_name": "87"
      }
    }, 
    {
      "type_key": "SourceName", 
      "repr_str": "model/batch_normalization_6/FusedBatchNormV3;model/conv2d_7/BiasAdd/ReadVariableOp/resource;model/conv2d_7/BiasAdd;model/conv2d_8/Conv2D;model/conv2d_7/Conv2D"
    }, 
    {
      "type_key": "relay.TensorType", 
      "attrs": {
        "dtype": "float32", 
        "shape": "89", 
        "span": "0"
      }
    }, 
    {
      "type_key": "Array", 
      "data": [90]
    }, 
    {
      "type_key": "IntImm", 
      "attrs": {
        "dtype": "int32", 
        "span": "0", 
        "value": "64"
      }
    }, 
    {
      "type_key": "relay.Constant", 
      "attrs": {
        "_checked_type_": "92", 
        "data": "17", 
        "span": "86", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "relay.TensorType", 
      "attrs": {
        "dtype": "float32", 
        "shape": "93", 
        "span": "0"
      }
    }, 
    {
      "type_key": "Array", 
      "data": [94]
    }, 
    {
      "type_key": "IntImm", 
      "attrs": {
        "dtype": "int32", 
        "span": "0", 
        "value": "64"
      }
    }
  ], 
  "b64ndarrays": [
    "P6G0lvBAXt0AAAAAAAAAAAEAAAAAAAAAAQAAAAIgAQAQAAAAAAAAAEAAAAAAAAAAqrO6OLJK7Dd7MJM4mivDOAc0njjMpl84scedOMwx9jitj1o4eg1cOBKx0je09k04g3SlOFEccjd9k+A3VAUvOQ==", 
    "P6G0lvBAXt0AAAAAAAAAAAEAAAAAAAAAAQAAAAIgAQAQAAAAAAAAAEAAAAAAAAAAqrO6OLJK7Dd7MJM4mivDOAc0njjMpl84scedOMwx9jitj1o4eg1cOBKx0je09k04g3SlOFEccjd9k+A3VAUvOQ==", 
    "P6G0lvBAXt0AAAAAAAAAAAEAAAAAAAAAAQAAAAIgAQAQAAAAAAAAAEAAAAAAAAAAzHOoO126CjvB9m07grh0Owh0iDtcbbs7lH95O7CcuTtoI1U7zff9Ox5ChDul0LM7kmC8O2VMrjt0QoU72tGEOw==", 
    "P6G0lvBAXt0AAAAAAAAAAAEAAAAAAAAAAQAAAAIgAQAQAAAAAAAAAEAAAAAAAAAAlllUOS7hrjjm/BU5KD8aORkDLDn/RGw5DkIdOTz7aTkkVwY5QROgOVS5Jjl2rGI5lndtOTC4Wzl3/Cc5hW4nOQ==", 
    "P6G0lvBAXt0AAAAAAAAAAAEAAAAAAAAAAQAAAAIgAQAQAAAAAAAAAEAAAAAAAAAAdzC5OiqdDzswz00733+FO5doGDv/xuw6H6kXO/CZCjt/C6g61rgWO6m3DTsdxn874X2xOqnWbTsxvkQ7JNIAOw==", 
    "P6G0lvBAXt0AAAAAAAAAAAEAAAAAAAAAAQAAAAIgAQAQAAAAAAAAAEAAAAAAAAAAEA/iOONOLznAOns5KfaiOS4LOjkThBA5dSE5OXcwKTl9Ic04JPw3OTz+LDlBHJw5lqnYOOIpkTmIKXA5GkAdOQ==", 
    "P6G0lvBAXt0AAAAAAAAAAAEAAAAAAAAAAQAAAAIgAQAgAAAAAAAAAIAAAAAAAAAASM8HO9a2rTouxx872f0POwOtjzvd8JE6yT4xO4MUGjtI+oM6kb7bOijP/DpmxHM7KlJAO+6E+Dq+tf86xjeHOy9dzDrMnhY70F9uO07BADuBki07/oiTOugiFjvcHtE6NDsNO8UuFzvYJ+Y6WH0dOw96mTsvTrk6haOROjn9Gjs=", 
    "P6G0lvBAXt0AAAAAAAAAAAEAAAAAAAAAAQAAAAIgAQAgAAAAAAAAAIAAAAAAAAAAw2fdOIyZjThxPQI5dL7qOKs6ajn76204YnoQOd8w+zh6KFc41B6zOJMSzji/s0Y5SMQcOWGTyjjhb9A4xHBcOVmVpjjsjPU4Y05COYzn0Tjuew05VoVwOPPC9Djpdao4cD7mOKN39jhhm7s46F8AORI1ejlTDJc4421tOECs/Dg=", 
    "P6G0lvBAXt0AAAAAAAAAAAEAAAAAAAAAAQAAAAIgAQAgAAAAAAAAAIAAAAAAAAAAPY8hOzd4WTvGzQ87kvf4OiMrCDv6VS87e0ATOxFv4jp99zE7yPP9Op69CTvvgV87jxHbOmmw1zrB8AU7rO0CO7MWCDvw+tM6aq0RO9GhqzqF8Po62FHZOmwc4TrLlxA7YEktO4OCLjtopQg7+7M8O7GpJTsXggw7eZnhOjnoLDs=", 
    "P6G0lvBAXt0AAAAAAAAAAAEAAAAAAAAAAQAAAAIgAQAgAAAAAAAAAIAAAAAAAAAAMLEDOSNEMTkUcOo40/DKOIP93Tjx6w45Hw/wOL2SuDjxEBE5GgHPOKmN4DgZMDY5zpGyOJjQrzijW9o4knLVODHc3Tinyqw4BX7tOBHnizhtjMw43CSxOLN+tzhsues4UkANOZI/DjnXxN44UtEZOXIJBzmnEOU4ouS3OCHxDDk=", 
    "P6G0lvBAXt0AAAAAAAAAAAEAAAAAAAAAAQAAAAIgAQAgAAAAAAAAAIAAAAAAAAAAu/NtOwjWgDs0Gg07t9slO0eHYzskvEk7fqeAO9pqZTvUlzc7HtcsOw+dkDsTGjw7Kp/FO2YIezvZBVY7qnBYOznZJzsI40M7Us1CO1lGQzsKPHg7bMo8O99wNztzOXo7gZk2O9jZcDvbd3U7k1NkOx3Nbjt6oFM7j8xPO9RUSjs=", 
    "P6G0lvBAXt0AAAAAAAAAAAEAAAAAAAAAAQAAAAIgAQAgAAAAAAAAAIAAAAAAAAAAGuMtOT9MPDm0Oc44LGjyOBdFJjm/axM5Owg8OXimJznYKQY5hJz8OGlbUzlTdQk5RGqQOTFyNzmFZhw5uioeOdVQ9Ti2JQ85xVoOOTazDjmzZjU5MvYJOWANBjn22jY5/m8FOWkBMDkvYTM5YtomOfWBLjlKpho5M9oXOVPbEzk=", 
    "P6G0lvBAXt0AAAAAAAAAAAEAAAAAAAAAAQAAAAIgAQBAAAAAAAAAAAABAAAAAAAAFGQqO+J5EzvgyRg7zjhJO9BZKjudJUo7u7GIOygcBjtg6VE798MdO06qGDtnQ04771EyO1TIzjp/6Es7PohFO5KnTzvlbWU7+jpTO474aztq6Ss7GlLtOj3mCDvZFBE7Fr8cO09SKju3qrI7VY0UO2+oRDv8YsE6GL0tO0lBQDuUV2A7NHEcO/DI+TrTboI7A4ImOx8YKztlDAc7edR+OxWSczuOPzQ7zPAtO4sazTq2zUE7cldQO43W8zqsdwY73eQ1O+1FIzsuuhQ7EX4QO0E/ADuV/VM7E90vO9r6TztuzHc717bIOh5oLTsyBFU7tfhKO8/VzDo64yA7xakhOw==", 
    "P6G0lvBAXt0AAAAAAAAAAAEAAAAAAAAAAQAAAAIgAQBAAAAAAAAAAAABAAAAAAAAsCIROfc7+zhlJAI5jWUrOfEZETlCLyw54t1oOdp25DhkzDI5pGEGOYEJAjnbsC85reMXORQisDhPry05/UAoOTvgMDlTbEM59OszOcT+SDlRbhI5GSXKOFU36TifJ/c4bYMFOY0TETlML5g5NRH9OFuCJzkIuaQ4rfwTOUbCIzkKFz85F0EFOfzC1Dg9M1459tMNOQu8ETkcEOY4Fg9ZOe13TzkiiBk5tygUOf+zrjjxEyU5CXYxOT+yzzjBEuU4/+4aOZ0SCzmcXf04wib2OPp52ji3kTQ5B8wVOSsnMTnZEVM52faqOEu0EzlncTU5EOMsOXN5rjhvCgk5jLMJOQ==", 
    "P6G0lvBAXt0AAAAAAAAAAAEAAAAAAAAAAQAAAAIgAQBAAAAAAAAAAAABAAAAAAAANCAmOqgjNDpS9Zs6lxazOqEWmTqXLkE6ckN7OgJqPTrlq4I6FuZ3Oh0yhToTeVg6RXl0Or8DgDr9bm862uIwOhEXgzq/9WU66hxmOt6eSjqn7Gg6uzdzOkGvIjqxl8E6ANaPOqp5ezqA+ZU6IUFSOgujZzp8dXU6/LlfOiriRDo8sIM6pNZFOp7cTzo6HTc6dDKDOmNflTr+EIE6DJ9mOl+1QDrWtFM69vypOsK+eDr6jJU6ck99OhaloDoVPJU631GzOkW0vDpoxhc6PMcjOvOtbTpjak46d8SaOsfxZzoq9n46gKN2OhskUTr02k06gNBVOtlcQzrnbmE6Ju5TOg==", 
    "P6G0lvBAXt0AAAAAAAAAAAEAAAAAAAAAAQAAAAIgAQBAAAAAAAAAAAABAAAAAAAApoANOF5wGTiR14Q4L4uYOMZlgjhnjCQ4ZAVWOMtWIThGm144tCdTOCXoYjggYzg42TxQOJoUWjjQ8Us4AasWONlRXzgK4EM4ZwFEOIqWLDh2ZkY49ypPOEeSCjjt5aQ4cgh1OJIzVjiXfX84JBczOLVNRTiuE1E4zpA+OIezJzjHVmA4xYMoOGoNMTgP+Rs4gIBfOAx3fjhH31s4P3BEOCclJDjAUzQ428qQOELgUzi3xH44ucNXOIHViDjoOn44rr2YOP67oDhjRwE4woALOFRzSjgP0i845tODOMWQRTjJK1k47hRSOF0kMjjjVy84bR82OOtnJjj2BEA4koQ0OA==", 
    "P6G0lvBAXt0AAAAAAAAAAAEAAAAAAAAAAQAAAAIgAQBAAAAAAAAAAAABAAAAAAAAa+UhPAQnEjx7rDI8lGzvOzYvHTwy4Ts8WWcYPM4RZTzWCxI88HctPDdALzy1DUA8HY4WPM07DjwuNTE89D4YPMUsLDz5JG08ah4dPF5VFTzUAxU8zbYYPJPgHDyEaR08woc3PBbdQzxGqlI8RSAfPBP6VTxzuBA8R+IePFoqHzxyUzE8UUJFPFTL8Tsjf2c8tdhPPM23HjwRyQw8XHUxPChtJDxCviU8xR1EPAAbGDx6elE8pX4kPEMcADxnsAQ8CTIfPNhGFTy0oiQ8o6MvPL5RAjxdYTQ89nUnPFWLHjza4h48txlOPDrkEDwhtzs8TN4RPAssCzyZSBs8Q91DPA==", 
    "P6G0lvBAXt0AAAAAAAAAAAEAAAAAAAAAAQAAAAIgAQBAAAAAAAAAAAABAAAAAAAAJmSTOdgOhTlmqqI5HvlZOQIajzn3C6s5zL+KOdaL0Dka9oQ5Pu2dOaSMnzm+2K459hCJOYN9gTm4VKE5BpuKOb+/nDnM5dc5uAqPOTz0hzkBqoc5IgiLOWvSjjkXT485SRanObxQsjluyr85id6QOUbOwjkfwYM5GaaQObfnkDlGcKE59ZWzOYEhXDmAwdI5gzm9OW1/kDn/K4A5Jo+hOdqxlTnA5JY5n4uyOUp6ijnatb45xsGVOdBDaTkPmnE5te6QOQTnhzma4pU5J+efOXJJbTkjOKQ5D3WYOfFWkDmeppA5kqK7Ofrogzmq5ao5pMyEOfNnfTn+Xo055VCyOQ=="
  ], 
  "attrs": {"tvm_version": "0.17.0"}
}